{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBH6YVjViZbx"
   },
   "source": [
    "# Bài tập về nhà 2: Logistic Regression\n",
    "\n",
    "Trong bài tập này, các bạn sẽ sử dụng kiến thức đã học về logistic regression để giải quyết bài toán phân lớp, cụ thể là phân loại phương tiện giao thông (xe hơi và xe máy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hitFu8V0lNsy"
   },
   "source": [
    "## Giới thiệu\n",
    "Để có thể hoàn tấp bài tập này, các bạn cần nắm rõ những kiến thức sau:\n",
    "* Logistic regression và nguyên tắc hoạt động.\n",
    "* Cách lấy đạo hàm cho các tham số trong mô hình trên.\n",
    "* Giải thuật gradient descent.\n",
    "\n",
    "Bạn có thể tham khảo lại bài giảng để nắm vững các nội dung này. Ngoài ra, các bạn có thể đặt câu hỏi cho đội ngũ giảng viên nếu có thắc mắc.\n",
    "\n",
    "Bạn cần giải quyết bài tập này bằng cả **numpy** và **Tensorflow**.\n",
    "\n",
    "*Lưu ý: để tiện cho việc phân biệt giữa lớp python và lớp trong bài toán phân loại, người viết quy ước rằng khi viết **class** nghiiax là đang nói về python class, khi viết **lớp** nghĩa là đang nói đến lớp của dữ liệu cần phân loại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3V56TgbYmnTb"
   },
   "source": [
    "## Hướng dẫn nộp bài\n",
    "Ở mỗi bài tập, các bạn sẽ được yêu cầu điền phần còn thiếu vào trong hàm, các cell để thực hiện phần bài làm sẽ có dòng đầu tiên như sau:\n",
    "```python\n",
    "# GRADED FUNCTION: <tên hàm>\n",
    "...\n",
    "```\n",
    "Trong cell đó, các bạn sẽ code phần đáp án của mình giữa 2 phần:\n",
    "```python\n",
    "### START CODE HERE ###\n",
    "<phần bài làm>\n",
    "### END CODE HERE ###\n",
    "```\n",
    "Sau khi thực hiện xong bạn từ terminal, bạn chạy file `submit.py` để nộp bài tập.\n",
    "```\n",
    "python submit.py -filepath <PATH_ĐẾN_FILE_BÀI_LÀM_CỦA_BẠN>\n",
    "```\n",
    "Mặc định `-filepath` là `2_Logistic_Regression.ipynb`. Nếu bạn không thay đổi tên hoặc vị trí file bài tập. Bạn có thể đơn giản gọi dòng lệnh sau để nộp bài:\n",
    "```\n",
    "python submit.py\n",
    "```\n",
    "Sau khi chạy dòng lệnh trên, vui lòng điền `username` và `password`, bạn sẽ nhận được kết quả trả về cho bài làm của bạn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-EHEHUzqMH0"
   },
   "source": [
    "## IMPORT CÁC THƯ VIỆN CẦN THIẾT\n",
    "Nếu chạy trên máy tính cá nhân, trước hết bạn cần install các thư viện cần thiết bằng cách chạy dòng lệnh sau trong terminal:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Nếu bạn chạy trên nền tảng Google Colab, bạn có thể bổ qua bước trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_2-XKqbqVZH"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c69b0efb67dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# IMPORT\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X0oUh2V9qkwy",
    "outputId": "6d74f626-0400-4711-aec5-6b931844bd4f"
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kt5Vcxv3quAd",
    "outputId": "ef1a96a5-ec4f-4ce5-897c-5433a0c266ec"
   },
   "outputs": [],
   "source": [
    "print(\"Tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZCOnnIbp9Te"
   },
   "source": [
    "## Tải dữ liệu\n",
    "Các bạn chạy cell bên dưới để tải bộ dữ liệu cũng như các hàm dùng để test cách cài đặt của các bạn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3C-zKu1Tmll0",
    "outputId": "65233272-c9d3-464e-8753-57eb3621f975"
   },
   "outputs": [],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "gdd.download_file_from_google_drive(file_id='115H--hHJ1uBASZmCi80WdfN_YtrP7Dzh', dest_path='./assignment2.zip', unzip=True)\n",
    "!rm assignment2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtY6lisEsJAz"
   },
   "source": [
    "Dữ liệu tải xuống của bạn bao gồm:\n",
    "* File `vehicle.data`: dữ liệu cho bài tập\n",
    "* File `logistic_unittest.npy`: được dungf để kiểm tra một số hàm mà bạn cài đặt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qPadKNm_lLoW",
    "outputId": "269bac68-269a-4e82-9f6e-66f40ee60ee9"
   },
   "outputs": [],
   "source": [
    "!ls assignment2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGlQpwFRsmiJ"
   },
   "source": [
    "## Các hàm bổ trợ dùng để đọc dữ liệu\n",
    "Nhóm TA sẽ giúp bạn định nghĩa các hàm bổ trợ trong việc đọc dữ liệu, các bạn không cần chỉnh sửa những hàm này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkK1HXJxsPHE"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These functions help you read data from data files.\n",
    "Author: Kien Huynh\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_npy(file_name):\n",
    "    \"\"\"load_npy\n",
    "    Load numpy data file. This is needed as python 2.7 pickle uses ascii as default encoding method but python 3.x uses utf-8.abs.\n",
    "\n",
    "    :param file_name: npy file path\n",
    "    \n",
    "    :return obj: loaded numpy object\n",
    "    \"\"\"\n",
    "    \n",
    "    if (sys.version_info[0] >= 3):\n",
    "        obj = np.load(file_name, encoding='latin1')\n",
    "    elif (sys.version_info[0] >=2):\n",
    "        obj = np.load(file_name)\n",
    "    \n",
    "    return obj\n",
    "\n",
    "\n",
    "def load_list(file_name):\n",
    "    \"\"\"load_list\n",
    "    Load a list object to file_name.\n",
    "\n",
    "    :param file_name: string, file name\n",
    "    \"\"\"\n",
    "    end_of_file = False\n",
    "    list_obj = [] \n",
    "    f = open(file_name, 'rb')\n",
    "    python_version = sys.version_info[0]\n",
    "    while (not end_of_file):\n",
    "        try:\n",
    "            if (python_version >= 3):\n",
    "                list_obj.append(pickle.load(f, encoding='latin1'))\n",
    "            elif (python_version >=2):\n",
    "                list_obj.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            end_of_file = True\n",
    "            print(\"EOF Reached\")\n",
    "\n",
    "    f.close()\n",
    "    return list_obj \n",
    "\n",
    "\n",
    "def save_list(list_obj, file_name):\n",
    "    \"\"\"save_list\n",
    "    Save a list object to file_name\n",
    "    \n",
    "    :param list_obj: List of objects to be saved\n",
    "    :param file_name: file name.\n",
    "    \"\"\"\n",
    "\n",
    "    f = open(file_name, 'wb')\n",
    "    for obj in list_obj:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close() \n",
    "\n",
    "\n",
    "def get_vehicle_data():\n",
    "    \"\"\"\n",
    "    Load vehicle data and return it as a list: [train_x, train_y, test_x, test_y].\n",
    "    \"\"\"\n",
    "    print('Reading vehicle data...')\n",
    "    train_x, train_y, test_x, test_y = load_list('./assignment2/vehicles.dat')\n",
    "    train_x = np.transpose(train_x, (2,0,1))\n",
    "    test_x = np.transpose(test_x, (2,0,1)) \n",
    "\n",
    "    print('Done reading')\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6KQe1EotN5f"
   },
   "source": [
    "## Dữ liệu\n",
    "Tập dữ liệu Vehicles là tập gồm có 2 lớp: xe hơi và xe máy, được gán nhãn lớp 0 (xe hơi) và 1 (xe máy). Ta có thể đọc tập dữ liệu này bằng hàm `get_vehicle_data()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "in8dLecatE8W",
    "outputId": "8873533a-2d5b-470d-c851-4c65763e7364"
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = get_vehicle_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0FI9Kamtj1D"
   },
   "source": [
    "Ở đây, `train_x` là một numpy tensor có kích thước `2400 × 64 × 64` (ý nghĩa: tập dữ liệu huấn luyện `train_x` có 2400 mẫu, mỗi mẫu là 1 ảnh có chiều cao (height) và rộng (width) bằng 64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yDtBjaM4ti0n",
    "outputId": "2d9c239d-9d37-49f0-84c0-211f3d9a500e"
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOqT8XDgtqRq"
   },
   "source": [
    "`train_y` là ma trận chứa nhãn ứng với mẫu dữ liệu trong `train_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ywBAe70VtgJ9",
    "outputId": "3929ecd8-5903-44b9-d363-ced10dc4b619"
   },
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b12urMtOuDBL"
   },
   "source": [
    "Tương tự, test_x có kích thước 600 × 64 × 64, mỗi hàng trong test_y biểu diễn cho nhãn của mỗi mẫu trong test_x.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KvR0_z3_uCps",
    "outputId": "ecb5a9fc-0b60-464a-c2f7-89b060061be9"
   },
   "outputs": [],
   "source": [
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBTGz_AIuIrL"
   },
   "source": [
    "Hai tensor `train_x` và `train_y` được dùng cho việc huấn luyện mô hình phân loại; hai tensor `test_x` và `test_y` được dùng cho quá trình đánh giá (test).\n",
    "\n",
    "Tập dữ liệu này gồm các ảnh xám (gray images), mỗi ảnh chứa một trong hai loại phương tiện di chuyển: xe máy và xe hơi. Mỗi ảnh có thể chứa trọn vẹn hoặc một phần phương tiện. Cần lưu ý là dữ liệu ảnh ở đây chưa được chuẩn hóa, nên các giá trị vẫn nằm trong khoảng từ 0 đến 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "Sn7_eWbptsxU",
    "outputId": "44997ea0-d6c7-4918-d610-368b1b3a38ab"
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(train_x[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "biwrg-a9uPLG",
    "outputId": "dd97e456-de58-47f0-e972-aa2b07bc569c"
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(train_x[2399])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ax76O_auWAR"
   },
   "source": [
    "## Chuẩn hóa dữ liệu ảnh\n",
    "Như đã kể trên, ảnh đầu vào có giá trị từ 0 đến 255. Nếu ta đưa trực tiếp bộ ảnh vào quá trình huấn luyện sẽ làm cho gradient lớn. Vì vậy, trước khi huấn luyện, ta có thể sử dụng phương pháp chuẩn hóa dữ liệu để đưa trung bình (mean) của tập train về 0 và độ lệch chuẩn (standard deviation - std) của nó về 1.\n",
    "\n",
    "Đối với việc xử lý hình ảnh, ta có hai cách chuẩn hóa khác nhau:\n",
    "*   (a) Xem mỗi pixel trong ảnh là một đặc trưng riêng rẽ. Ví dụ, pixel [1, 3] và pixel [4, 2] là hai đặc trưng khác nhau, được tính mean và std riêng.\n",
    "*   (b) Xem các pixel khác nhau trong ảnh là cùng 1 loại đặc trưng. Lúc này, pixel [1, 3] và pixel [4, 2] được xem là cùng 1 loại đặc trưng, được tính mean và std chung.\n",
    "\n",
    "Trong mục này, bạn cần hiện thực cách chuẩn hóa (a) trong hàm ```normalize_per_pixel``` và cách (b) trong hàm ```normalize_all_pixel```. Giả sử ta có ```m``` ảnh train ```x_0..xm−1```, mỗi ảnh train có R hàng và C cột, thì mean và std tính theo cách (a) sẽ là:\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{x}_{rc}=\\frac{1}{m}\\sum_{i=0}^{m-1}x_{rc}^{(i)}, 0 \\le r \\le R-1,0 \\le c \\le C-1 \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{rc}=\\sqrt{\\frac{1}{m}\\sum_{i=0}^{m-1}{(x_{rc}^{(i)}-\\overline{x}_{rc})^2}} \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Đối với cách (b) ta sẽ có:\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{x} = \\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{x_{rc}^{(i)}}}} \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma=\\sqrt{\\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{(x_{rc}^{(i)}-\\overline{x})^2}}}} \\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "Sau khi có được mean và std trên toàn bộ data huấn luyện, ta chuẩn hóa các mẫu trong tập huấn luyện theo cách sau:\n",
    "\n",
    "\\begin{equation}\n",
    "x^{(i)} = \\frac{x^{(i)}-\\overline{x}}{\\sigma} \\tag{5}\n",
    "\\end{equation} \n",
    "\n",
    "Đối với cách (a), việc này sẽ được áp dụng riêng cho từng pixel trong số $R\\times{C}$. Với cách (b), thì ta dùng chung $\\overline{x}$ và $\\sigma$ trong công thức (3) và (4) cho toàn bộ tất cả các pixel.\n",
    "\n",
    "Cần lưu ý rằng $\\overline{x}$ và $\\sigma$ chỉ được tính trên $m$ mẫu dữ liệu huấn luyện. Sau đó, hai giá trị này sẽ được dùng lại để chuẩn hóa các mẫu dữ liệu test (và validation nếu có). Việc tính $\\overline{x}$ và $\\sigma$ mà có sử dụng các dữ liệu trong tập test là vi phạm nguyên tắc đánh giá các mô hình học máy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFcAf-yGvakI"
   },
   "source": [
    "### TODO 1: normalize_per_pixel (1đ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHmFIxrluSQb"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "def normalize_per_pixel(train_x, test_x):\n",
    "    \"\"\"TODO 1: normalize_per_pixel\n",
    "    This function computes the mean and standard deviation of the pixels located at the same coordinates across and training images\n",
    "    and performs data scaling on train_x and test_x using these computed values.\n",
    "\n",
    "    :param train_x: training images, shape=(num_train, image_height, image_width)\n",
    "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
    "    \"\"\"\n",
    "    # The shape of train_mean and train_std should be (1, image_height, image_width)\n",
    "    ### START CODE HERE ### (≈4 lines)\n",
    "    train_mean = np.mean(train_x, axis=0)\n",
    "    train_std = np.std(train_x, axis=0)\n",
    "    train_x = (train_x - train_mean) / train_std\n",
    "    test_x = (test_x - train_mean) / train_std    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTv9Jkbu9xnk"
   },
   "outputs": [],
   "source": [
    "### SANITY CHECK\n",
    "train_x = np.arange(2*2*3).reshape(2,2,3)\n",
    "assert np.sum(normalize_per_pixel(train_x, train_x)) == 0, \"Wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HYardfWwSgk"
   },
   "source": [
    "### TODO 2: normalize_all_pixel (1đ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UG8ed3buvDSo"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "def normalize_all_pixels(train_x, test_x):\n",
    "    \"\"\"TODO 2: normalize_all_pixels\n",
    "    This function computes the mean and standard deviation of all pixels and performs data scaling on train_x and test_x using these computed values.\n",
    "\n",
    "    :param train_x: training images, shape=(num_train, image_height, image_width)\n",
    "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
    "    \"\"\"\n",
    "    # The shape of train_mean and train_std should be (1, 1, 1).\n",
    "    ### START CODE HERE ### (≈4 lines)\n",
    "    train_mean = np.mean(train_x)\n",
    "    train_std = np.std(train_x)\n",
    "    train_x = (train_x - train_mean) / train_std\n",
    "    test_x = (test_x - train_mean) / train_std    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wwjizm090Nc"
   },
   "outputs": [],
   "source": [
    "### SANITY CHECK\n",
    "train_x = np.arange(2*2*3).reshape(2,2,3)\n",
    "assert np.sum(normalize_all_pixels(train_x, train_x)) > 0, \"Wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF0YHtNGwhrD"
   },
   "source": [
    "## Duỗi dữ liệu\n",
    "\n",
    "Dữ liệu ở bước trên vẫn còn ở dạng tensor 3D ($2400 \\times 64 \\times 64$). Để có thể thực hiện các phép nhân ma trận trong bài toán logistic regression, ta cần chuẩn chúng về dạng tensor 2D ($2400 \\times 4096$). Các bạn cần thực hiện bước này trong hàm `reshape2D`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVJpl6PWwoWD"
   },
   "source": [
    "### TODO 3: reshape2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoTuzdE2wl2V"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "def reshape2D(tensor):\n",
    "    \"\"\"TODO 3: reshape_2D\n",
    "    Reshape our 3D tensors to 2D. A 3D tensor of shape (num_samples, image_height, image_width) must be reshaped into (num_samples, image_height*image_width).\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    ### START CODE HERE ### (≈1 line)\n",
    "    result = tensor.reshape(tensor.shape[0], tensor.shape[1] * tensor.shape[2])\n",
    "    ### END CODE HERE ###\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMl11WsWxdxQ"
   },
   "outputs": [],
   "source": [
    "### SANITY CHECK\n",
    "tensor = np.arange(2*3*4).reshape(2,3,4)\n",
    "assert sum(reshape2D(tensor).shape)==14, \"Wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9kqWYy9wzpc"
   },
   "source": [
    "## Thêm đặc trưng 1 vào dữ liệu\n",
    "Để tính tích vô hướng dễ dàng, nối thêm một cột có giá trị bằng 1 vào `train_x` và `test_x` (concatenate có axis=1). Trong file có sẵn hàm `add_one` và ta nên thực hiện code trong hàm này. Sau bước này, dữ liệu huấn luyện sẽ có kích thước $2400 \\times 4097$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dd6kcfXw6g6"
   },
   "source": [
    "### TODO 4: add_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-OxDdlIw4H-"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "def add_one(x):\n",
    "    \"\"\"TODO 4: add_one\n",
    "    This function add ones as an additional feature for x.\n",
    "\n",
    "    :param x: input data\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (≈1 line)\n",
    "    x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "    ### END CODE HERE ###\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDLPC_nYxap8"
   },
   "outputs": [],
   "source": [
    "### SANITY CHECK\n",
    "x = np.arange(2*3).reshape(2,3)\n",
    "assert add_one(x).sum() == 17, \"Wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1qEL0Ziw_y1"
   },
   "source": [
    "## Class LogisticClassifier: Logistic Regression với numpy\n",
    "\n",
    "Nhằm hỗ trợ cho việc lập trình, đội ngũ TA cung cấp sẵn cho các bạn class **LogisticClassifier**. Một trong các thành phần chính của class LogisticClassifier là `w`, tham số mà ta cần tìm khi huấn luyện. Tham số này là một mảng có số hàng bằng số đặc trưng của dữ liệu đầu vào, số cột bằng 1. Cụ thể trong bài toán phân loại ảnh xe này, `w` sẽ là một ma trận $4097\\times{1}$. `w` được khởi tạo ngẫu nhiên trong hàm `__init__(w_shape)`. Để truy xuất `w` từ bên trong class, ta dùng `self.w`, ví dụ:\n",
    "```python\n",
    "class logistic_classifier(object):\n",
    "    def feed_forward(self, x):\n",
    "        print(self.w)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Veto4H-SxGGB"
   },
   "source": [
    "Để truy xuất w từ bên ngoài class, ta cần có một thực thể của class và gọi thông qua thực thể này, ví dụ:\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    num_feature = train_x.shape[1]\n",
    "    bin_classifier = LogisticClassifier((num_feature, 1))\n",
    "    print(bin_classifier.w)\n",
    "```\n",
    "\n",
    "Đối với các hàm thuộc class **LogisticClassifier**, việc truy xuất cũng hoàn toàn giống với `w`. Chúng sẽ được mô tả chi tiết trong mục tiếp theo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfClTzjqxDPH"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "class LogisticClassifier(object):\n",
    "    def __init__(self, w_shape):\n",
    "        \"\"\"__init__\n",
    "        \n",
    "        :param w_shape: create w with shape w_shape using normal distribution\n",
    "        \"\"\"\n",
    "\n",
    "        mean = 0\n",
    "        std = 1\n",
    "        self.w = np.random.normal(0, np.sqrt(2./np.sum(w_shape)), w_shape)\n",
    "\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        \"\"\"TODO 5: feed_forward\n",
    "        This function computes the output of your logistic classification model.\n",
    "        \n",
    "        :param x: input\n",
    "        \"\"\"\n",
    "        result = None\n",
    "        \n",
    "        ### START CODE HERE ### (≈2 lines)\n",
    "        z = np.dot(x, self.w)\n",
    "        result = 1 / (1 + np.exp(-z))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "    def compute_loss(self, y, y_hat):\n",
    "        \"\"\"TODO 6: compute_loss\n",
    "        Compute the loss using y (label) and y_hat (predicted class).\n",
    "\n",
    "        :param y:  the label, the actual class of the sample\n",
    "        :param y_hat: the probabilities that the given sample belong to class 1\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        \n",
    "        ### START CODE HERE ### (≈2 lines)\n",
    "        m = y_hat.shape[0]\n",
    "        loss = - 1 / m * (np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def get_grad(self, x, y, y_hat):\n",
    "        \"\"\"TODO 7: get_grad\n",
    "        Compute and return the gradient of w.\n",
    "\n",
    "        :param x: input\n",
    "        :param y: the label, the actual class of the sample data\n",
    "        :param y_hat: predicted y\n",
    "        \"\"\" \n",
    "        w_grad = None\n",
    "        \n",
    "        ### START CODE HERE ### (≈2 lines)\n",
    "        m = y_hat.shape[0]\n",
    "        w_grad = 1 / m * np.dot(x.T, (y_hat - y))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return w_grad\n",
    "\n",
    "\n",
    "    def update_weight(self, grad, learning_rate):\n",
    "        \"\"\"TODO 8: update_weight\n",
    "        Update w using the computed gradient.\n",
    "\n",
    "        :param grad: gradient computed from the loss\n",
    "        :param learning_rate: float, learning rate\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (≈1 line)\n",
    "        self.w = self.w - learning_rate * grad\n",
    "        ### END CODE HERE ###\n",
    "        return self.w\n",
    "\n",
    "\n",
    "    def update_weight_momentum(self, grad, learning_rate, momentum, momentum_rate):\n",
    "        \"\"\"TODO 9: update_weight using momentum\n",
    "        BONUS:[YC1.8]\n",
    "        Update w using the algorithm with momentum\n",
    "\n",
    "        :param grad: gradient computed from the loss\n",
    "        :param learning_rate: float, learning rate\n",
    "        :param momentum: the array storing momentum for training w, should have the same shape as that of w\n",
    "        :param momentum_rate: float, how much momentum to reuse after each loop (denoted as gamma in the following section)\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (≈3 lines)\n",
    "        momentum = momentum_rate * momentum + learning_rate * grad\n",
    "        self.w = self.w - momentum\n",
    "        ### END CODE HERE ###\n",
    "        return self.w\n",
    "\n",
    "\n",
    "    def numerical_check(self, x, y, grad):\n",
    "        eps = 0.000005\n",
    "        w_test0 = np.copy(self.w)\n",
    "        w_test1 = np.copy(self.w)\n",
    "        w_test0[2] = w_test0[2] - eps\n",
    "        w_test1[2] = w_test1[2] + eps\n",
    "\n",
    "        y_hat0 = np.dot(x, w_test0)\n",
    "        y_hat0 = 1. / (1. + np.exp(-y_hat0))\n",
    "        loss0 = self.compute_loss(y, y_hat0) \n",
    "\n",
    "        y_hat1 = np.dot(x, w_test1)\n",
    "        y_hat1 = 1. / (1. + np.exp(-y_hat1))\n",
    "        loss1 = self.compute_loss(y, y_hat1) \n",
    "\n",
    "        numerical_grad = (loss1 - loss0)/(2*eps)\n",
    "        print(numerical_grad)\n",
    "        print(grad[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcypA56gxWkK"
   },
   "outputs": [],
   "source": [
    "### SANITY CHECK\n",
    "eps = 0.001        \n",
    "classifer = LogisticClassifier((3,1))\n",
    "classifer.w = np.arange(3*1).reshape(3,1)\n",
    "x = np.ones(2*3).reshape(2,3)\n",
    "y = np.ones(2).reshape(2,1)\n",
    "y_hat = classifer.feed_forward(x)\n",
    "assert abs(sum(y_hat) - 1.905) < eps, \"Wrong\"\n",
    "loss = classifer.compute_loss(y, y_hat)\n",
    "assert abs(loss - 0.048) < eps, \"Wrong\"\n",
    "grad = classifer.get_grad(x, y, y_hat)\n",
    "assert abs(sum(grad) + 0.142) < eps, \"Wrong\"\n",
    "updateweight = classifer.update_weight(grad, 0.1)\n",
    "assert abs(sum(updateweight) - 3.014) < eps, \"Wrong\"\n",
    "updatemomen = classifer.update_weight_momentum(grad, 0.1, 0.1, 0.1)\n",
    "assert abs(sum(updatemomen) - 2.998) < eps, \"Wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pK1l0tDWxg-Z"
   },
   "source": [
    "### Tính các giá trị phân loại\n",
    "\n",
    "Các giá trị phân loại, $\\hat{y}$, sẽ được tính trong hàm `feed_forward` của class `LogisticClassifier`. Công thức tính như sau:\n",
    "\n",
    "\\begin{equation}\n",
    "z = xw  \\tag{6}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\hat{y} = \\frac{1}{1+e^{-z}} \\tag{7}\n",
    "\\end{equation}\n",
    "\n",
    "Ở đây, $w = [w_0, w_1,.., w_{4096}]^T$ là các tham số cần học (lưu trong biến `self.w` trong class `LogisticClassifier`). Lẽ ra công thức (6) được viết là $z=xw+w_{4096}$, tuy nhiên ở bước trên ta đã thêm 1 vào làm đặc trưng cuối cho tất cả các mẫu. Việc này giúp cho quá trình nhân ma trận và quản lý các biến gọn hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIlk1OZ6x8pt"
   },
   "source": [
    "#### TODO 5: feed_forward\n",
    "Các bạn hoàn thành hàm `feed_forward()` trong class `LogisticClassifier` ở trên"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bcsY9dYnyZpt"
   },
   "source": [
    "### Tính độ lỗi\n",
    "\n",
    "Việc tính độ lỗi được thực hiện trong hàm `compute_loss` của class `LogisticClassifier`. Công thức tính độ lỗi như sau:\n",
    "\n",
    "\\begin{equation}\n",
    "J(w) = -\\frac{1}{m}\\sum_{i=0}^{m-1}(y^{(i)}\\log{\\hat{y}^{(i)}} + (1-y^{(i)})\\log(1-\\hat{y}^{(i)})) \\tag{8}\n",
    "\\end{equation}\n",
    "\n",
    "Trong đó:\n",
    "-  $y^{(i)}$ là nhãn của mẫu thứ $i$, mẫu thuộc lớp 0 sẽ có $y^{(i)}=0$, mẫu thuộc lớp 1 sẽ có $y^{(i)}=1$. Ta có thể truy cập các nhãn này thông qua biến `train_y` và `test_y`.\n",
    "- $\\hat{y}^{(i)} \\in (0, 1)$ là phần tử thứ $i$ trong vector $\\hat{y}$.\n",
    "- $m=2400$ là tổng số mẫu huấn luyện.\n",
    "\n",
    "\n",
    "Để tính trung bình trên ma trận theo hàng hoặc cột, ta có thể sử dụng hàm `np.mean()` với tham số axis tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sh0hbNAryb4D"
   },
   "source": [
    "#### TODO 6: compute_loss\n",
    "Các bạn hoàn thành hàm `compute_loss()` trong class `LogisticClassifier` ở trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQJjH3D2ytLu"
   },
   "source": [
    "### Tính đạo hàm\n",
    "Để tính đạo hàm riêng cho thành phần $w_j$ trong $w$ trong hàm `get_grad`, ta dùng công thức sau:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial  J(w_j)}{\\partial w_j} = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})x^{(i)}_j \\tag{9}\n",
    "\\end{equation}\n",
    "\n",
    "Trong trường hợp này, sau khi thêm 1 vào `train_x` thì ta sẽ có $0 \\le j \\le 4096$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4HOnxOXyxLR"
   },
   "source": [
    "#### TODO 7: get_grad\n",
    "Các bạn hoàn thành hàm `get_grad()` trong class `LogisticClassifier` ở trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8E3zBWJy-JG"
   },
   "source": [
    "### Cập nhật $w$\n",
    "Để huấn luyện được mô hình phân loại trong hàm `update_weight`, ta cần cập nhật $w$ theo công thức sau:\n",
    "\\begin{equation}\n",
    "w = w - \\alpha\\times\\frac{\\partial  J(w)}{\\partial w} \\tag{10}\n",
    "\\end{equation}\n",
    "\n",
    "Với $\\alpha$ là hệ số học (`learning_rate`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SORwzFWzB5R"
   },
   "source": [
    "#### TODO 8: update_weight\n",
    "Các bạn hoàn thành hàm `update_weight()` trong class `LogisticClassifier` ở trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koyotO_gzQ63"
   },
   "source": [
    "### Cập nhật $w$ dùng momentum\n",
    "\n",
    "Giải thuật cập nhật trình bày trong phần trước có điểm yếu là chậm và dễ rơi vào tối ưu cục bộ. Tuy trong bài này, giải thuật đó cũng đủ để giải quyết, nhưng ta vẫn có thể sử dụng giải thuật có quán tính để việc huấn luyện diễn ra nhanh hơn.\n",
    "\n",
    "Khởi tạo ma trận quán tính trước khi vào vòng lặp chính:\n",
    "\\begin{equation}\n",
    "\\Delta w = 0 \\tag{11}\n",
    "\\end{equation}\n",
    "\n",
    "Ở đây, $\\Delta w$ là ma trận có kích thước bằng chính kích thước của $w$. Quá trình cập nhật $w$ sẽ được diễn ra như sau:\n",
    "\\begin{equation}\n",
    "\\Delta w = \\gamma\\Delta w + \\alpha\\frac{\\partial  J(w)}{\\partial w} \\tag{12}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "w = w - \\Delta w \\tag{13}\n",
    "\\end{equation}\n",
    "\n",
    "Với $\\gamma$ là hệ số quán tính (thường được đặt là 0.9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CW1a7JUZzTl8"
   },
   "source": [
    "#### TODO 9: update_weight_momentum\n",
    "Các bạn hoàn thành hàm `update_weight_momentum` vào class `LogisticClassifier` ở trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBTNnbtPzh3h"
   },
   "source": [
    "### Đánh giá mô hình phân loại\n",
    "Để đánh giá mô hình phân loại trên tập kiểm thử (`test_x` và `test_y`), trước tiên, ta cần thực hiện tính các giá trị phân loại trên`test_x`. Sau khi đã có các giá trị này, ta sử dụng các tiêu chí sau để đánh giá mô hình:\n",
    "\n",
    "\\begin{equation}\n",
    "Precision = \\frac{TP}{TP+FP} \\tag{14}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Recall = \\frac{TP}{P} \\tag{15}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "F_1-score = 2\\times\\frac{Precision\\times Recall}{Precision+Recall} \\tag{16}\n",
    "\\end{equation}\n",
    "\n",
    "Trong đó:\n",
    "- Lớp positive là lớp có giá trị y = 1.\n",
    "- TP (true positive) là tổng số các mẫu mà mô hình dự đoán là positive. ($\\hat{y}=1$) và thực sự có nhãn là positive ($y=1$).\n",
    "- FP (false positive) là tổng số các mẫu mô hình dự đoán là positive($\\hat{y}=1$) nhưng thực chất có nhãn là negative ($y=0$).\n",
    "- P là tổng số mẫu positive trong tập test.\n",
    "\n",
    "Nhiệm vụ của bạn trong bước này là tính các thông số trên trong hàm `test`. Khi tiến hành kiểm thử, người ra đề đã tính được các giá trị $Precision=0.766$, $Recall=0.830$ và $F_1-score=0.797$. Bạn hãy cố gắng hoàn thiện bài làm của mình để đạt kết quả tương tự hoặc tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZS0GVBkzpu8"
   },
   "source": [
    "#### TODO 10: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxKX-D5hzSq0"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "def test(y_hat, test_y, thres=0.5):\n",
    "    \"\"\"TODO 10: test\n",
    "    Compute precision, recall and F1-score based on predicted test values\n",
    "\n",
    "    :param y_hat: predicted values, output of classifier.feed_forward\n",
    "    :param test_y: test labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute test scores using test_y and y_hat\n",
    "\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    ### START CODE HERE ### (≈7 lines)\n",
    "    predicted_y = np.array([1 if i > thres else 0 for i in y_hat])\n",
    "\n",
    "    TP = np.sum(np.logical_and(predicted_y == 1, test_y == 1))\n",
    "    FP = np.sum(np.logical_and(predicted_y == 1, test_y == 0))\n",
    "    FN = np.sum(np.logical_and(predicted_y == 0, test_y == 1))\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4ju9atbya4B"
   },
   "outputs": [],
   "source": [
    "### SANITY CHECK\n",
    "y_hat = np.array([0.4, 0.7, 0.8, 0.3, 0.2])\n",
    "test_y = np.array([0, 1, 1, 0, 0])\n",
    "assert sum(test(y_hat, test_y)) == 3, \"Wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZZJPjbx-9m1"
   },
   "source": [
    "### Vòng lặp huấn luyện\n",
    "\n",
    "Vòng lặp của quá trình huấn luyện được xây dựng trong đoạn code sau đây. Tất cả khung sườn cho việc thực thi đã được lập trình sẵn. Ta có thể thay đổi hai tham số tác động đến quá trình huấn luyện như sau:\n",
    "\n",
    "- `num_epoch`: số lượng vòng lặp cho quá trình huấn luyện.\n",
    "- `learning_rate`: hệ số học $\\alpha$.\n",
    "- `momentum_rate`: hệ số momentum $\\gamma$.\n",
    "- `epochs_to_draw`: số lượng epochs cần đạt được để vẽ đồ thị độ lỗi trong lúc huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMJvYJjl_CWI"
   },
   "outputs": [],
   "source": [
    "def plot_loss(all_loss):\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.plot(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOJR5upR_Gym"
   },
   "outputs": [],
   "source": [
    "#@title Training { display-mode: \"both\" }\n",
    "normalize_method = \"per_pixel\" #@param [\"all_pixels\", \"per_pixel\"]\n",
    "update_weight_method = \"normal\" #@param [\"normal\", \"momentum\"]\n",
    "num_epoch = 1000 #@param {type:\"integer\"}\n",
    "learning_rate = 0.01 #@param {type:\"number\"}\n",
    "momentum_rate = 0.9 #@param {type:\"number\"}\n",
    "epochs_to_draw = 100 #@param {type:\"integer\"}\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "# Load data from file\n",
    "# Make sure that vehicles.dat is in data/\n",
    "train_x, train_y, test_x, test_y = get_vehicle_data()\n",
    "num_train = train_x.shape[0]\n",
    "num_test = test_x.shape[0]\n",
    "\n",
    "# Normalize our data: choose one of the two methods before training\n",
    "if normalize_method == \"all_pixels\":\n",
    "    train_x, test_x = normalize_all_pixels(train_x, test_x) \n",
    "else:\n",
    "    train_x, test_x = normalize_per_pixel(train_x, test_x) \n",
    "\n",
    "# Reshape our data\n",
    "# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n",
    "# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n",
    "train_x = reshape2D(train_x)\n",
    "test_x = reshape2D(test_x)\n",
    "\n",
    "# Pad 1 as the last feature of train_x and test_x\n",
    "train_x = add_one(train_x) \n",
    "test_x = add_one(test_x)\n",
    "\n",
    "# Create classifier\n",
    "num_feature = train_x.shape[1]\n",
    "bin_classifier = LogisticClassifier((num_feature, 1))\n",
    "momentum = np.zeros_like(bin_classifier.w)\n",
    "\n",
    "# Define hyper-parameters and train-related parameters\n",
    "all_loss = []\n",
    "plt.ion()\n",
    "for e in range(num_epoch):    \n",
    "    y_hat = bin_classifier.feed_forward(train_x)\n",
    "    loss = bin_classifier.compute_loss(train_y, y_hat)\n",
    "    grad = bin_classifier.get_grad(train_x, train_y, y_hat)\n",
    "\n",
    "    # Updating weight: choose either normal SGD or SGD with momentum\n",
    "    if update_weight_method == \"normal\":\n",
    "        bin_classifier.update_weight(grad, learning_rate)\n",
    "    else: \n",
    "        bin_classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n",
    "\n",
    "    all_loss.append(loss) \n",
    "\n",
    "    if (e % epochs_to_draw == epochs_to_draw-1):\n",
    "        plot_loss(all_loss)\n",
    "        plt.show()\n",
    "        plt.pause(0.1)     \n",
    "        print(\"Epoch %d: loss is %.5f\" % (e+1, loss))\n",
    "\n",
    "y_hat = bin_classifier.feed_forward(test_x)\n",
    "precision, recall, f1 = test(y_hat, test_y)\n",
    "print(\"Precision: %.3f\" % precision)\n",
    "print(\"Recall: %.3f\" % recall)\n",
    "print(\"F1-score: %.3f\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qYBIeqd0eEd"
   },
   "source": [
    "## Class LogisticRegressionTF: Logistic regression với Tensorflow\n",
    "Chúng ta sử dụng tensorflow eager execution để cài đặt mô hình logistic regression. Với tf eager execution, giá trị của các biến được tính toán ngay lập tức thay vì xây dựng computational graph để chạy sau đó. Một trong những lợi ích thiết thực nhất là giúp chúng ta dễ dàng debug mô hình, xây dựng được dynamic model.\n",
    "\n",
    "Để xây dựng mô hình bằng eager execution, chúng ta thường định nghĩa một lớp đối tượng như mình họa ở dưới.\n",
    "\n",
    "Chúng ta kế thừa lớp Model và cài đặt 2 hàm chính:\n",
    "- init: khởi tạo tất cả các tham số. \n",
    "- call: hàm dùng cho feedforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swk_3L72x75j"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionTF(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_class):\n",
    "        super(LogisticRegressionTF, self).__init__()\n",
    "        # init all weights here\n",
    "        self.dense = tf.keras.layers.Dense(num_class)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        output = self.dense(inputs)\n",
    "        \n",
    "        output = tf.nn.softmax(output)        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5ynuv-y1WM5"
   },
   "source": [
    "### TODO 11: Định nghĩa one-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2720NV003uN"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "def create_one_hot(labels, num_k=10):\n",
    "    \"\"\"TODO 11: create_one_hot\n",
    "    This function creates a one-hot (one-of-k) matrix based on the given labels.\n",
    "\n",
    "    :param labels: list of labels, each label is one of 0, 1, 2,... , num_k - 1\n",
    "    :param num_k: number of classes we want to classify\n",
    "    \"\"\"\n",
    "    eye_mat = None\n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return eye_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__DN5vkP1ei_"
   },
   "outputs": [],
   "source": [
    "### SANITY CHECK\n",
    "x = [1, 2, 3]\n",
    "y = create_one_hot(x, 4)\n",
    "assert y.shape == (3,4), \"Wrong\"\n",
    "assert sum(np.argmax(y, axis=0)) == 3, \"Wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhoNamB81kaz"
   },
   "source": [
    "### Huấn luyện mô hình với Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ct-bwUGm1pDx"
   },
   "outputs": [],
   "source": [
    "#@title Training { display-mode: \"both\" }\n",
    "normalize_method = \"all_pixels\" #@param [\"all_pixels\", \"per_pixel\"]\n",
    "num_epoch = 14 #@param {type:\"integer\"}\n",
    "learning_rate = 0.001 #@param {type:\"number\"}\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "np.random.seed(2020)\n",
    "tf.random.set_seed(2020)\n",
    "\n",
    "# Load data from file\n",
    "# Make sure that vehicles.dat is in data/\n",
    "train_x, train_y, test_x, test_y = get_vehicle_data()\n",
    "num_train = train_x.shape[0]\n",
    "num_test = test_x.shape[0]  \n",
    "\n",
    "#generate_unit_testcase(train_x.copy(), train_y.copy()) \n",
    "#logistic_unit_test()\n",
    "\n",
    "# Normalize our data: choose one of the two methods before training\n",
    "if normalize_method == \"all_pixels\":\n",
    "    train_x, test_x = normalize_all_pixels(train_x, test_x) \n",
    "else:\n",
    "    train_x, test_x = normalize_per_pixel(train_x, test_x) \n",
    "\n",
    "# Reshape our data\n",
    "# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n",
    "# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n",
    "train_x = reshape2D(train_x)\n",
    "test_x = reshape2D(test_x)\n",
    "train_y = create_one_hot(train_y.astype('int32').flatten().tolist(), num_k=2)\n",
    "test_y = create_one_hot(test_y.astype('int32').flatten().tolist(), num_k=2)\n",
    "\n",
    "device = '/cpu:0' if len(tf.config.experimental.list_physical_devices('GPU')) == 0 else '/gpu:0'\n",
    "\n",
    "with tf.device(device):\n",
    "    # build model and optimizer\n",
    "    model = LogisticRegressionTF(num_classes)\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate), loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    # train\n",
    "    model.fit(train_x, train_y, batch_size=batch_size, epochs=num_epoch,\n",
    "              validation_data=(test_x, test_y), verbose=2)\n",
    "\n",
    "    # evaluate on test set\n",
    "    scores = model.evaluate(test_x, test_y, 32, verbose=2)\n",
    "    \n",
    "    y_hat = model.predict(test_x)\n",
    "    precision, recall, f1 = test(y_hat, test_y)\n",
    "    print(\"Precision: %.3f\" % precision)\n",
    "    print(\"Recall: %.3f\" % recall)\n",
    "    print(\"F1-score: %.3f\" % f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vFcAf-yGvakI",
    "8HYardfWwSgk",
    "NVJpl6PWwoWD",
    "_dd6kcfXw6g6",
    "pK1l0tDWxg-Z",
    "fIlk1OZ6x8pt",
    "bcsY9dYnyZpt",
    "Sh0hbNAryb4D",
    "rQJjH3D2ytLu",
    "s4HOnxOXyxLR",
    "I8E3zBWJy-JG",
    "1SORwzFWzB5R",
    "koyotO_gzQ63",
    "CW1a7JUZzTl8",
    "NBTNnbtPzh3h",
    "sZS0GVBkzpu8",
    "eZZJPjbx-9m1",
    "m5ynuv-y1WM5",
    "BhoNamB81kaz"
   ],
   "name": "2_Logistic_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
