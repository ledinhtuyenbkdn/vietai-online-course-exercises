{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vFcAf-yGvakI",
        "8HYardfWwSgk",
        "NVJpl6PWwoWD",
        "_dd6kcfXw6g6",
        "pK1l0tDWxg-Z",
        "fIlk1OZ6x8pt",
        "bcsY9dYnyZpt",
        "Sh0hbNAryb4D",
        "rQJjH3D2ytLu",
        "s4HOnxOXyxLR",
        "I8E3zBWJy-JG",
        "1SORwzFWzB5R",
        "koyotO_gzQ63",
        "CW1a7JUZzTl8",
        "NBTNnbtPzh3h",
        "sZS0GVBkzpu8",
        "eZZJPjbx-9m1",
        "m5ynuv-y1WM5",
        "BhoNamB81kaz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBH6YVjViZbx"
      },
      "source": [
        "# Bài tập về nhà 2: Logistic Regression\n",
        "\n",
        "Trong bài tập này, các bạn sẽ sử dụng kiến thức đã học về logistic regression để giải quyết bài toán phân lớp, cụ thể là phân loại phương tiện giao thông (xe hơi và xe máy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hitFu8V0lNsy"
      },
      "source": [
        "## Giới thiệu\n",
        "Để có thể hoàn tấp bài tập này, các bạn cần nắm rõ những kiến thức sau:\n",
        "* Logistic regression và nguyên tắc hoạt động.\n",
        "* Cách lấy đạo hàm cho các tham số trong mô hình trên.\n",
        "* Giải thuật gradient descent.\n",
        "\n",
        "Bạn có thể tham khảo lại bài giảng để nắm vững các nội dung này. Ngoài ra, các bạn có thể đặt câu hỏi cho đội ngũ giảng viên nếu có thắc mắc.\n",
        "\n",
        "Bạn cần giải quyết bài tập này bằng cả **numpy** và **Tensorflow**.\n",
        "\n",
        "*Lưu ý: để tiện cho việc phân biệt giữa lớp python và lớp trong bài toán phân loại, người viết quy ước rằng khi viết **class** nghiiax là đang nói về python class, khi viết **lớp** nghĩa là đang nói đến lớp của dữ liệu cần phân loại."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V56TgbYmnTb"
      },
      "source": [
        "## Hướng dẫn nộp bài\n",
        "Ở mỗi bài tập, các bạn sẽ được yêu cầu điền phần còn thiếu vào trong hàm, các cell để thực hiện phần bài làm sẽ có dòng đầu tiên như sau:\n",
        "```python\n",
        "# GRADED FUNCTION: <tên hàm>\n",
        "...\n",
        "```\n",
        "Trong cell đó, các bạn sẽ code phần đáp án của mình giữa 2 phần:\n",
        "```python\n",
        "### START CODE HERE ###\n",
        "<phần bài làm>\n",
        "### END CODE HERE ###\n",
        "```\n",
        "Sau khi thực hiện xong bạn từ terminal, bạn chạy file `submit.py` để nộp bài tập.\n",
        "```\n",
        "python submit.py -filepath <PATH_ĐẾN_FILE_BÀI_LÀM_CỦA_BẠN>\n",
        "```\n",
        "Mặc định `-filepath` là `2_Logistic_Regression.ipynb`. Nếu bạn không thay đổi tên hoặc vị trí file bài tập. Bạn có thể đơn giản gọi dòng lệnh sau để nộp bài:\n",
        "```\n",
        "python submit.py\n",
        "```\n",
        "Sau khi chạy dòng lệnh trên, vui lòng điền `username` và `password`, bạn sẽ nhận được kết quả trả về cho bài làm của bạn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-EHEHUzqMH0"
      },
      "source": [
        "## IMPORT CÁC THƯ VIỆN CẦN THIẾT\n",
        "Nếu chạy trên máy tính cá nhân, trước hết bạn cần install các thư viện cần thiết bằng cách chạy dòng lệnh sau trong terminal:\n",
        "```\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "Nếu bạn chạy trên nền tảng Google Colab, bạn có thể bổ qua bước trên."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_2-XKqbqVZH"
      },
      "source": [
        "# IMPORT\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0oUh2V9qkwy",
        "outputId": "06b17290-9415-4689-bb5d-7364e7a141dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt5Vcxv3quAd",
        "outputId": "23e14b99-304d-46c2-e195-ec4c5979b85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Tensorflow version: \", tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZCOnnIbp9Te"
      },
      "source": [
        "## Tải dữ liệu\n",
        "Các bạn chạy cell bên dưới để tải bộ dữ liệu cũng như các hàm dùng để test cách cài đặt của các bạn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C-zKu1Tmll0",
        "outputId": "37dd988c-9881-4377-f01e-7f5cc5c92939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='115H--hHJ1uBASZmCi80WdfN_YtrP7Dzh', dest_path='./assignment2.zip', unzip=True)\n",
        "!rm assignment2.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 115H--hHJ1uBASZmCi80WdfN_YtrP7Dzh into ./assignment2.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtY6lisEsJAz"
      },
      "source": [
        "Dữ liệu tải xuống của bạn bao gồm:\n",
        "* File `vehicle.data`: dữ liệu cho bài tập\n",
        "* File `logistic_unittest.npy`: được dungf để kiểm tra một số hàm mà bạn cài đặt.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPadKNm_lLoW",
        "outputId": "83399dc0-0e0c-4a06-b009-aa7f1097ac2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls assignment2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic_unittest.npy  vehicles.dat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGlQpwFRsmiJ"
      },
      "source": [
        "## Các hàm bổ trợ dùng để đọc dữ liệu\n",
        "Nhóm TA sẽ giúp bạn định nghĩa các hàm bổ trợ trong việc đọc dữ liệu, các bạn không cần chỉnh sửa những hàm này."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkK1HXJxsPHE"
      },
      "source": [
        "\"\"\"\n",
        "These functions help you read data from data files.\n",
        "Author: Kien Huynh\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def load_npy(file_name):\n",
        "    \"\"\"load_npy\n",
        "    Load numpy data file. This is needed as python 2.7 pickle uses ascii as default encoding method but python 3.x uses utf-8.abs.\n",
        "\n",
        "    :param file_name: npy file path\n",
        "    \n",
        "    :return obj: loaded numpy object\n",
        "    \"\"\"\n",
        "    \n",
        "    if (sys.version_info[0] >= 3):\n",
        "        obj = np.load(file_name, encoding='latin1')\n",
        "    elif (sys.version_info[0] >=2):\n",
        "        obj = np.load(file_name)\n",
        "    \n",
        "    return obj\n",
        "\n",
        "\n",
        "def load_list(file_name):\n",
        "    \"\"\"load_list\n",
        "    Load a list object to file_name.\n",
        "\n",
        "    :param file_name: string, file name\n",
        "    \"\"\"\n",
        "    end_of_file = False\n",
        "    list_obj = [] \n",
        "    f = open(file_name, 'rb')\n",
        "    python_version = sys.version_info[0]\n",
        "    while (not end_of_file):\n",
        "        try:\n",
        "            if (python_version >= 3):\n",
        "                list_obj.append(pickle.load(f, encoding='latin1'))\n",
        "            elif (python_version >=2):\n",
        "                list_obj.append(pickle.load(f))\n",
        "        except EOFError:\n",
        "            end_of_file = True\n",
        "            print(\"EOF Reached\")\n",
        "\n",
        "    f.close()\n",
        "    return list_obj \n",
        "\n",
        "\n",
        "def save_list(list_obj, file_name):\n",
        "    \"\"\"save_list\n",
        "    Save a list object to file_name\n",
        "    \n",
        "    :param list_obj: List of objects to be saved\n",
        "    :param file_name: file name.\n",
        "    \"\"\"\n",
        "\n",
        "    f = open(file_name, 'wb')\n",
        "    for obj in list_obj:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "    f.close() \n",
        "\n",
        "\n",
        "def get_vehicle_data():\n",
        "    \"\"\"\n",
        "    Load vehicle data and return it as a list: [train_x, train_y, test_x, test_y].\n",
        "    \"\"\"\n",
        "    print('Reading vehicle data...')\n",
        "    train_x, train_y, test_x, test_y = load_list('./assignment2/vehicles.dat')\n",
        "    train_x = np.transpose(train_x, (2,0,1))\n",
        "    test_x = np.transpose(test_x, (2,0,1)) \n",
        "\n",
        "    print('Done reading')\n",
        "    return train_x, train_y, test_x, test_y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6KQe1EotN5f"
      },
      "source": [
        "## Dữ liệu\n",
        "Tập dữ liệu Vehicles là tập gồm có 2 lớp: xe hơi và xe máy, được gán nhãn lớp 0 (xe hơi) và 1 (xe máy). Ta có thể đọc tập dữ liệu này bằng hàm `get_vehicle_data()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in8dLecatE8W",
        "outputId": "8a537319-6095-433c-9b35-a17ae496f1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "train_x, train_y, test_x, test_y = get_vehicle_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0FI9Kamtj1D"
      },
      "source": [
        "Ở đây, `train_x` là một numpy tensor có kích thước `2400 × 64 × 64` (ý nghĩa: tập dữ liệu huấn luyện `train_x` có 2400 mẫu, mỗi mẫu là 1 ảnh có chiều cao (height) và rộng (width) bằng 64)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDtBjaM4ti0n",
        "outputId": "0a733d85-13ff-4c41-e10d-5afab18136e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOqT8XDgtqRq"
      },
      "source": [
        "`train_y` là ma trận chứa nhãn ứng với mẫu dữ liệu trong `train_x`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywBAe70VtgJ9",
        "outputId": "237461de-2159-40f6-c975-744d13696880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b12urMtOuDBL"
      },
      "source": [
        "Tương tự, test_x có kích thước 600 × 64 × 64, mỗi hàng trong test_y biểu diễn cho nhãn của mỗi mẫu trong test_x.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvR0_z3_uCps",
        "outputId": "65e632cc-ebb2-4392-fbf5-ad7c1fe37fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(600, 64, 64)\n",
            "(600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBTGz_AIuIrL"
      },
      "source": [
        "Hai tensor `train_x` và `train_y` được dùng cho việc huấn luyện mô hình phân loại; hai tensor `test_x` và `test_y` được dùng cho quá trình đánh giá (test).\n",
        "\n",
        "Tập dữ liệu này gồm các ảnh xám (gray images), mỗi ảnh chứa một trong hai loại phương tiện di chuyển: xe máy và xe hơi. Mỗi ảnh có thể chứa trọn vẹn hoặc một phần phương tiện. Cần lưu ý là dữ liệu ảnh ở đây chưa được chuẩn hóa, nên các giá trị vẫn nằm trong khoảng từ 0 đến 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn7_eWbptsxU",
        "outputId": "60ba6e02-f041-4b9c-b1e2-da7639f55378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "imgplot = plt.imshow(train_x[0])\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biwrg-a9uPLG",
        "outputId": "393f2389-6155-4830-a4dd-e837274e10dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "imgplot = plt.imshow(train_x[2399])\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ax76O_auWAR"
      },
      "source": [
        "## Chuẩn hóa dữ liệu ảnh\n",
        "Như đã kể trên, ảnh đầu vào có giá trị từ 0 đến 255. Nếu ta đưa trực tiếp bộ ảnh vào quá trình huấn luyện sẽ làm cho gradient lớn. Vì vậy, trước khi huấn luyện, ta có thể sử dụng phương pháp chuẩn hóa dữ liệu để đưa trung bình (mean) của tập train về 0 và độ lệch chuẩn (standard deviation - std) của nó về 1.\n",
        "\n",
        "Đối với việc xử lý hình ảnh, ta có hai cách chuẩn hóa khác nhau:\n",
        "*   (a) Xem mỗi pixel trong ảnh là một đặc trưng riêng rẽ. Ví dụ, pixel [1, 3] và pixel [4, 2] là hai đặc trưng khác nhau, được tính mean và std riêng.\n",
        "*   (b) Xem các pixel khác nhau trong ảnh là cùng 1 loại đặc trưng. Lúc này, pixel [1, 3] và pixel [4, 2] được xem là cùng 1 loại đặc trưng, được tính mean và std chung.\n",
        "\n",
        "Trong mục này, bạn cần hiện thực cách chuẩn hóa (a) trong hàm ```normalize_per_pixel``` và cách (b) trong hàm ```normalize_all_pixel```. Giả sử ta có ```m``` ảnh train ```x_0..xm−1```, mỗi ảnh train có R hàng và C cột, thì mean và std tính theo cách (a) sẽ là:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overline{x}_{rc}=\\frac{1}{m}\\sum_{i=0}^{m-1}x_{rc}^{(i)}, 0 \\le r \\le R-1,0 \\le c \\le C-1 \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma_{rc}=\\sqrt{\\frac{1}{m}\\sum_{i=0}^{m-1}{(x_{rc}^{(i)}-\\overline{x}_{rc})^2}} \\tag{2}\n",
        "\\end{equation}\n",
        "\n",
        "Đối với cách (b) ta sẽ có:\n",
        "\n",
        "\\begin{equation}\n",
        "\\overline{x} = \\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{x_{rc}^{(i)}}}} \\tag{3}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma=\\sqrt{\\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{(x_{rc}^{(i)}-\\overline{x})^2}}}} \\tag{4}\n",
        "\\end{equation}\n",
        "\n",
        "Sau khi có được mean và std trên toàn bộ data huấn luyện, ta chuẩn hóa các mẫu trong tập huấn luyện theo cách sau:\n",
        "\n",
        "\\begin{equation}\n",
        "x^{(i)} = \\frac{x^{(i)}-\\overline{x}}{\\sigma} \\tag{5}\n",
        "\\end{equation} \n",
        "\n",
        "Đối với cách (a), việc này sẽ được áp dụng riêng cho từng pixel trong số $R\\times{C}$. Với cách (b), thì ta dùng chung $\\overline{x}$ và $\\sigma$ trong công thức (3) và (4) cho toàn bộ tất cả các pixel.\n",
        "\n",
        "Cần lưu ý rằng $\\overline{x}$ và $\\sigma$ chỉ được tính trên $m$ mẫu dữ liệu huấn luyện. Sau đó, hai giá trị này sẽ được dùng lại để chuẩn hóa các mẫu dữ liệu test (và validation nếu có). Việc tính $\\overline{x}$ và $\\sigma$ mà có sử dụng các dữ liệu trong tập test là vi phạm nguyên tắc đánh giá các mô hình học máy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFcAf-yGvakI"
      },
      "source": [
        "### TODO 1: normalize_per_pixel (1đ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHmFIxrluSQb"
      },
      "source": [
        "# GRADED FUNCTION\n",
        "def normalize_per_pixel(train_x, test_x):\n",
        "    \"\"\"TODO 1: normalize_per_pixel\n",
        "    This function computes the mean and standard deviation of the pixels located at the same coordinates across and training images\n",
        "    and performs data scaling on train_x and test_x using these computed values.\n",
        "\n",
        "    :param train_x: training images, shape=(num_train, image_height, image_width)\n",
        "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
        "    \"\"\"\n",
        "    # The shape of train_mean and train_std should be (1, image_height, image_width)\n",
        "    ### START CODE HERE ### (≈4 lines)\n",
        "    train_mean = np.mean(train_x, axis=0)\n",
        "    train_std = np.std(train_x, axis=0)\n",
        "    train_x = (train_x - train_mean) / train_std\n",
        "    test_x = (test_x - train_mean) / train_std\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return train_x, test_x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTv9Jkbu9xnk"
      },
      "source": [
        "### SANITY CHECK\n",
        "train_x = np.arange(2*2*3).reshape(2,2,3)\n",
        "assert np.sum(normalize_per_pixel(train_x, train_x)) == 0, \"Wrong\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HYardfWwSgk"
      },
      "source": [
        "### TODO 2: normalize_all_pixel (1đ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG8ed3buvDSo"
      },
      "source": [
        "# GRADED FUNCTION\n",
        "def normalize_all_pixels(train_x, test_x):\n",
        "    \"\"\"TODO 2: normalize_all_pixels\n",
        "    This function computes the mean and standard deviation of all pixels and performs data scaling on train_x and test_x using these computed values.\n",
        "\n",
        "    :param train_x: training images, shape=(num_train, image_height, image_width)\n",
        "    :param test_x: test images, shape=(num_test, image_height, image_width)\n",
        "    \"\"\"\n",
        "    # The shape of train_mean and train_std should be (1, 1, 1).\n",
        "    ### START CODE HERE ### (≈4 lines)\n",
        "    train_mean = np.mean(train_x)\n",
        "    train_std = np.std(train_x)\n",
        "    train_x = (train_x - train_mean) / train_std\n",
        "    test_x = (test_x - train_mean) / train_std\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return train_x, test_x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wwjizm090Nc"
      },
      "source": [
        "### SANITY CHECK\n",
        "train_x = np.arange(2*2*3).reshape(2,2,3)\n",
        "assert np.sum(normalize_all_pixels(train_x, train_x)) > 0, \"Wrong\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF0YHtNGwhrD"
      },
      "source": [
        "## Duỗi dữ liệu\n",
        "\n",
        "Dữ liệu ở bước trên vẫn còn ở dạng tensor 3D ($2400 \\times 64 \\times 64$). Để có thể thực hiện các phép nhân ma trận trong bài toán logistic regression, ta cần chuẩn chúng về dạng tensor 2D ($2400 \\times 4096$). Các bạn cần thực hiện bước này trong hàm `reshape2D`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVJpl6PWwoWD"
      },
      "source": [
        "### TODO 3: reshape2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoTuzdE2wl2V"
      },
      "source": [
        "# GRADED FUNCTION\n",
        "def reshape2D(tensor):\n",
        "    \"\"\"TODO 3: reshape_2D\n",
        "    Reshape our 3D tensors to 2D. A 3D tensor of shape (num_samples, image_height, image_width) must be reshaped into (num_samples, image_height*image_width).\n",
        "    \"\"\"\n",
        "    result = None\n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    result = tensor.reshape(tensor.shape[0], tensor.shape[1] * tensor.shape[2])\n",
        "    ### END CODE HERE ###\n",
        "    return result"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMl11WsWxdxQ"
      },
      "source": [
        "### SANITY CHECK\n",
        "tensor = np.arange(2*3*4).reshape(2,3,4)\n",
        "assert sum(reshape2D(tensor).shape)==14, \"Wrong\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9kqWYy9wzpc"
      },
      "source": [
        "## Thêm đặc trưng 1 vào dữ liệu\n",
        "Để tính tích vô hướng dễ dàng, nối thêm một cột có giá trị bằng 1 vào `train_x` và `test_x` (concatenate có axis=1). Trong file có sẵn hàm `add_one` và ta nên thực hiện code trong hàm này. Sau bước này, dữ liệu huấn luyện sẽ có kích thước $2400 \\times 4097$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dd6kcfXw6g6"
      },
      "source": [
        "### TODO 4: add_one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-OxDdlIw4H-"
      },
      "source": [
        "# GRADED FUNCTION\n",
        "def add_one(x):\n",
        "    \"\"\"TODO 4: add_one\n",
        "    This function add ones as an additional feature for x.\n",
        "\n",
        "    :param x: input data\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
        "    ### END CODE HERE ###\n",
        "    return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDLPC_nYxap8"
      },
      "source": [
        "### SANITY CHECK\n",
        "x = np.arange(2*3).reshape(2,3)\n",
        "assert add_one(x).sum() == 17, \"Wrong\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1qEL0Ziw_y1"
      },
      "source": [
        "## Class LogisticClassifier: Logistic Regression với numpy\n",
        "\n",
        "Nhằm hỗ trợ cho việc lập trình, đội ngũ TA cung cấp sẵn cho các bạn class **LogisticClassifier**. Một trong các thành phần chính của class LogisticClassifier là `w`, tham số mà ta cần tìm khi huấn luyện. Tham số này là một mảng có số hàng bằng số đặc trưng của dữ liệu đầu vào, số cột bằng 1. Cụ thể trong bài toán phân loại ảnh xe này, `w` sẽ là một ma trận $4097\\times{1}$. `w` được khởi tạo ngẫu nhiên trong hàm `__init__(w_shape)`. Để truy xuất `w` từ bên trong class, ta dùng `self.w`, ví dụ:\n",
        "```python\n",
        "class logistic_classifier(object):\n",
        "    def feed_forward(self, x):\n",
        "        print(self.w)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Veto4H-SxGGB"
      },
      "source": [
        "Để truy xuất w từ bên ngoài class, ta cần có một thực thể của class và gọi thông qua thực thể này, ví dụ:\n",
        "```python\n",
        "if __name__ == \"__main__\":\n",
        "    num_feature = train_x.shape[1]\n",
        "    bin_classifier = LogisticClassifier((num_feature, 1))\n",
        "    print(bin_classifier.w)\n",
        "```\n",
        "\n",
        "Đối với các hàm thuộc class **LogisticClassifier**, việc truy xuất cũng hoàn toàn giống với `w`. Chúng sẽ được mô tả chi tiết trong mục tiếp theo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfClTzjqxDPH"
      },
      "source": [
        "# GRADED FUNCTION\n",
        "class LogisticClassifier(object):\n",
        "    def __init__(self, w_shape):\n",
        "        \"\"\"__init__\n",
        "        \n",
        "        :param w_shape: create w with shape w_shape using normal distribution\n",
        "        \"\"\"\n",
        "\n",
        "        mean = 0\n",
        "        std = 1\n",
        "        self.w = np.random.random(w_shape)\n",
        "\n",
        "\n",
        "    def feed_forward(self, x):\n",
        "        \"\"\"TODO 5: feed_forward\n",
        "        This function computes the output of your logistic classification model.\n",
        "        \n",
        "        :param x: input\n",
        "        \"\"\"\n",
        "        result = None\n",
        "        \n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        z = np.dot(x, self.w)\n",
        "        result = 1 / (1 + np.exp(-z))\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        return result\n",
        "\n",
        "\n",
        "    def compute_loss(self, y, y_hat):\n",
        "        \"\"\"TODO 6: compute_loss\n",
        "        Compute the loss using y (label) and y_hat (predicted class).\n",
        "\n",
        "        :param y:  the label, the actual class of the sample\n",
        "        :param y_hat: the probabilities that the given sample belong to class 1\n",
        "        \"\"\"\n",
        "        loss = 0\n",
        "        \n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        m = y_hat.shape[0]\n",
        "        loss = - 1 / m * (np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)))\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        return loss\n",
        "\n",
        "\n",
        "    def get_grad(self, x, y, y_hat):\n",
        "        \"\"\"TODO 7: get_grad\n",
        "        Compute and return the gradient of w.\n",
        "\n",
        "        :param x: input\n",
        "        :param y: the label, the actual class of the sample data\n",
        "        :param y_hat: predicted y\n",
        "        \"\"\" \n",
        "        w_grad = None\n",
        "        \n",
        "        ### START CODE HERE ### (≈2 lines)\n",
        "        m = y_hat.shape[0]\n",
        "        w_grad = 1 / m * np.dot(x.T, (y_hat - y))\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        return w_grad\n",
        "\n",
        "\n",
        "    def update_weight(self, grad, learning_rate):\n",
        "        \"\"\"TODO 8: update_weight\n",
        "        Update w using the computed gradient.\n",
        "\n",
        "        :param grad: gradient computed from the loss\n",
        "        :param learning_rate: float, learning rate\n",
        "        \"\"\"\n",
        "        ### START CODE HERE ### (≈1 line)\n",
        "        self.w = self.w - learning_rate * grad\n",
        "        ### END CODE HERE ###\n",
        "        return self.w\n",
        "\n",
        "\n",
        "    def update_weight_momentum(self, grad, learning_rate, momentum, momentum_rate):\n",
        "        \"\"\"TODO 9: update_weight using momentum\n",
        "        BONUS:[YC1.8]\n",
        "        Update w using the algorithm with momentum\n",
        "\n",
        "        :param grad: gradient computed from the loss\n",
        "        :param learning_rate: float, learning rate\n",
        "        :param momentum: the array storing momentum for training w, should have the same shape as that of w\n",
        "        :param momentum_rate: float, how much momentum to reuse after each loop (denoted as gamma in the following section)\n",
        "        \"\"\"\n",
        "        ### START CODE HERE ### (≈3 lines)\n",
        "        momentum = momentum_rate * momentum + learning_rate * grad\n",
        "        self.w = self.w - momentum\n",
        "        ### END CODE HERE ###\n",
        "        return self.w\n",
        "\n",
        "\n",
        "    def numerical_check(self, x, y, grad):\n",
        "        eps = 0.000005\n",
        "        w_test0 = np.copy(self.w)\n",
        "        w_test1 = np.copy(self.w)\n",
        "        w_test0[2] = w_test0[2] - eps\n",
        "        w_test1[2] = w_test1[2] + eps\n",
        "\n",
        "        y_hat0 = np.dot(x, w_test0)\n",
        "        y_hat0 = 1. / (1. + np.exp(-y_hat0))\n",
        "        loss0 = self.compute_loss(y, y_hat0) \n",
        "\n",
        "        y_hat1 = np.dot(x, w_test1)\n",
        "        y_hat1 = 1. / (1. + np.exp(-y_hat1))\n",
        "        loss1 = self.compute_loss(y, y_hat1) \n",
        "\n",
        "        numerical_grad = (loss1 - loss0)/(2*eps)\n",
        "        print(numerical_grad)\n",
        "        print(grad[2])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcypA56gxWkK"
      },
      "source": [
        "### SANITY CHECK\n",
        "eps = 0.001        \n",
        "classifer = LogisticClassifier((3,1))\n",
        "classifer.w = np.arange(3*1).reshape(3,1)\n",
        "x = np.ones(2*3).reshape(2,3)\n",
        "y = np.ones(2).reshape(2,1)\n",
        "y_hat = classifer.feed_forward(x)\n",
        "assert abs(sum(y_hat) - 1.905) < eps, \"Wrong\"\n",
        "loss = classifer.compute_loss(y, y_hat)\n",
        "assert abs(loss - 0.048) < eps, \"Wrong\"\n",
        "grad = classifer.get_grad(x, y, y_hat)\n",
        "assert abs(sum(grad) + 0.142) < eps, \"Wrong\"\n",
        "updateweight = classifer.update_weight(grad, 0.1)\n",
        "assert abs(sum(updateweight) - 3.014) < eps, \"Wrong\"\n",
        "updatemomen = classifer.update_weight_momentum(grad, 0.1, 0.1, 0.1)\n",
        "assert abs(sum(updatemomen) - 2.998) < eps, \"Wrong\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK1l0tDWxg-Z"
      },
      "source": [
        "### Tính các giá trị phân loại\n",
        "\n",
        "Các giá trị phân loại, $\\hat{y}$, sẽ được tính trong hàm `feed_forward` của class `LogisticClassifier`. Công thức tính như sau:\n",
        "\n",
        "\\begin{equation}\n",
        "z = xw  \\tag{6}\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "\\hat{y} = \\frac{1}{1+e^{-z}} \\tag{7}\n",
        "\\end{equation}\n",
        "\n",
        "Ở đây, $w = [w_0, w_1,.., w_{4096}]^T$ là các tham số cần học (lưu trong biến `self.w` trong class `LogisticClassifier`). Lẽ ra công thức (6) được viết là $z=xw+w_{4096}$, tuy nhiên ở bước trên ta đã thêm 1 vào làm đặc trưng cuối cho tất cả các mẫu. Việc này giúp cho quá trình nhân ma trận và quản lý các biến gọn hơn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIlk1OZ6x8pt"
      },
      "source": [
        "#### TODO 5: feed_forward\n",
        "Các bạn hoàn thành hàm `feed_forward()` trong class `LogisticClassifier` ở trên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcsY9dYnyZpt"
      },
      "source": [
        "### Tính độ lỗi\n",
        "\n",
        "Việc tính độ lỗi được thực hiện trong hàm `compute_loss` của class `LogisticClassifier`. Công thức tính độ lỗi như sau:\n",
        "\n",
        "\\begin{equation}\n",
        "J(w) = -\\frac{1}{m}\\sum_{i=0}^{m-1}(y^{(i)}\\log{\\hat{y}^{(i)}} + (1-y^{(i)})\\log(1-\\hat{y}^{(i)})) \\tag{8}\n",
        "\\end{equation}\n",
        "\n",
        "Trong đó:\n",
        "-  $y^{(i)}$ là nhãn của mẫu thứ $i$, mẫu thuộc lớp 0 sẽ có $y^{(i)}=0$, mẫu thuộc lớp 1 sẽ có $y^{(i)}=1$. Ta có thể truy cập các nhãn này thông qua biến `train_y` và `test_y`.\n",
        "- $\\hat{y}^{(i)} \\in (0, 1)$ là phần tử thứ $i$ trong vector $\\hat{y}$.\n",
        "- $m=2400$ là tổng số mẫu huấn luyện.\n",
        "\n",
        "\n",
        "Để tính trung bình trên ma trận theo hàng hoặc cột, ta có thể sử dụng hàm `np.mean()` với tham số axis tương ứng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh0hbNAryb4D"
      },
      "source": [
        "#### TODO 6: compute_loss\n",
        "Các bạn hoàn thành hàm `compute_loss()` trong class `LogisticClassifier` ở trên."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQJjH3D2ytLu"
      },
      "source": [
        "### Tính đạo hàm\n",
        "Để tính đạo hàm riêng cho thành phần $w_j$ trong $w$ trong hàm `get_grad`, ta dùng công thức sau:\n",
        "\\begin{equation}\n",
        "\\frac{\\partial  J(w_j)}{\\partial w_j} = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})x^{(i)}_j \\tag{9}\n",
        "\\end{equation}\n",
        "\n",
        "Trong trường hợp này, sau khi thêm 1 vào `train_x` thì ta sẽ có $0 \\le j \\le 4096$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4HOnxOXyxLR"
      },
      "source": [
        "#### TODO 7: get_grad\n",
        "Các bạn hoàn thành hàm `get_grad()` trong class `LogisticClassifier` ở trên."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8E3zBWJy-JG"
      },
      "source": [
        "### Cập nhật $w$\n",
        "Để huấn luyện được mô hình phân loại trong hàm `update_weight`, ta cần cập nhật $w$ theo công thức sau:\n",
        "\\begin{equation}\n",
        "w = w - \\alpha\\times\\frac{\\partial  J(w)}{\\partial w} \\tag{10}\n",
        "\\end{equation}\n",
        "\n",
        "Với $\\alpha$ là hệ số học (`learning_rate`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SORwzFWzB5R"
      },
      "source": [
        "#### TODO 8: update_weight\n",
        "Các bạn hoàn thành hàm `update_weight()` trong class `LogisticClassifier` ở trên."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koyotO_gzQ63"
      },
      "source": [
        "### Cập nhật $w$ dùng momentum\n",
        "\n",
        "Giải thuật cập nhật trình bày trong phần trước có điểm yếu là chậm và dễ rơi vào tối ưu cục bộ. Tuy trong bài này, giải thuật đó cũng đủ để giải quyết, nhưng ta vẫn có thể sử dụng giải thuật có quán tính để việc huấn luyện diễn ra nhanh hơn.\n",
        "\n",
        "Khởi tạo ma trận quán tính trước khi vào vòng lặp chính:\n",
        "\\begin{equation}\n",
        "\\Delta w = 0 \\tag{11}\n",
        "\\end{equation}\n",
        "\n",
        "Ở đây, $\\Delta w$ là ma trận có kích thước bằng chính kích thước của $w$. Quá trình cập nhật $w$ sẽ được diễn ra như sau:\n",
        "\\begin{equation}\n",
        "\\Delta w = \\gamma\\Delta w + \\alpha\\frac{\\partial  J(w)}{\\partial w} \\tag{12}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "w = w - \\Delta w \\tag{13}\n",
        "\\end{equation}\n",
        "\n",
        "Với $\\gamma$ là hệ số quán tính (thường được đặt là 0.9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW1a7JUZzTl8"
      },
      "source": [
        "#### TODO 9: update_weight_momentum\n",
        "Các bạn hoàn thành hàm `update_weight_momentum` vào class `LogisticClassifier` ở trên."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBTNnbtPzh3h"
      },
      "source": [
        "### Đánh giá mô hình phân loại\n",
        "Để đánh giá mô hình phân loại trên tập kiểm thử (`test_x` và `test_y`), trước tiên, ta cần thực hiện tính các giá trị phân loại trên`test_x`. Sau khi đã có các giá trị này, ta sử dụng các tiêu chí sau để đánh giá mô hình:\n",
        "\n",
        "\\begin{equation}\n",
        "Precision = \\frac{TP}{TP+FP} \\tag{14}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "Recall = \\frac{TP}{P} \\tag{15}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "F_1-score = 2\\times\\frac{Precision\\times Recall}{Precision+Recall} \\tag{16}\n",
        "\\end{equation}\n",
        "\n",
        "Trong đó:\n",
        "- Lớp positive là lớp có giá trị y = 1.\n",
        "- TP (true positive) là tổng số các mẫu mà mô hình dự đoán là positive. ($\\hat{y}=1$) và thực sự có nhãn là positive ($y=1$).\n",
        "- FP (false positive) là tổng số các mẫu mô hình dự đoán là positive($\\hat{y}=1$) nhưng thực chất có nhãn là negative ($y=0$).\n",
        "- P là tổng số mẫu positive trong tập test.\n",
        "\n",
        "Nhiệm vụ của bạn trong bước này là tính các thông số trên trong hàm `test`. Khi tiến hành kiểm thử, người ra đề đã tính được các giá trị $Precision=0.766$, $Recall=0.830$ và $F_1-score=0.797$. Bạn hãy cố gắng hoàn thiện bài làm của mình để đạt kết quả tương tự hoặc tốt hơn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZS0GVBkzpu8"
      },
      "source": [
        "#### TODO 10: test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxKX-D5hzSq0"
      },
      "source": [
        "# GRADED FUNCTION\n",
        "def test(y_hat, test_y, thres=0.5):\n",
        "    \"\"\"TODO 10: test\n",
        "    Compute precision, recall and F1-score based on predicted test values\n",
        "\n",
        "    :param y_hat: predicted values, output of classifier.feed_forward\n",
        "    :param test_y: test labels\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute test scores using test_y and y_hat\n",
        "\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    f1 = 0\n",
        "    ### START CODE HERE ### (≈7 lines)\n",
        "    predict = lambda x: 1 if x > thres else 0\n",
        "    predict_vectorize = np.vectorize(predict)\n",
        "    predicted_y = predict_vectorize(y_hat)\n",
        "\n",
        "    TP = np.sum(np.logical_and(predicted_y == 1, test_y == 1))\n",
        "    FP = np.sum(np.logical_and(predicted_y == 1, test_y == 0))\n",
        "    FN = np.sum(np.logical_and(predicted_y == 0, test_y == 1))\n",
        "    \n",
        "    precision = TP / (TP + FP)\n",
        "    recall = TP / (TP + FN)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ju9atbya4B",
        "outputId": "53d3f178-0d3c-4a52-eae3-7174f8b0c714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### SANITY CHECK\n",
        "y_hat = np.array([0.4, 0.7, 0.8, 0.3, 0.2])\n",
        "test_y = np.array([0, 1, 1, 0, 0])\n",
        "#assert sum(test(y_hat, test_y)) == 3, \"Wrong\"\n",
        "print(test(y_hat, test_y))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1.0, 1.0, 1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZZJPjbx-9m1"
      },
      "source": [
        "### Vòng lặp huấn luyện\n",
        "\n",
        "Vòng lặp của quá trình huấn luyện được xây dựng trong đoạn code sau đây. Tất cả khung sườn cho việc thực thi đã được lập trình sẵn. Ta có thể thay đổi hai tham số tác động đến quá trình huấn luyện như sau:\n",
        "\n",
        "- `num_epoch`: số lượng vòng lặp cho quá trình huấn luyện.\n",
        "- `learning_rate`: hệ số học $\\alpha$.\n",
        "- `momentum_rate`: hệ số momentum $\\gamma$.\n",
        "- `epochs_to_draw`: số lượng epochs cần đạt được để vẽ đồ thị độ lỗi trong lúc huấn luyện."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMJvYJjl_CWI"
      },
      "source": [
        "def plot_loss(all_loss):\n",
        "    plt.figure(1)\n",
        "    plt.clf()\n",
        "    plt.plot(all_loss)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOJR5upR_Gym",
        "outputId": "0e2e6a17-1b61-412e-ea67-f5ad930d1eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Training { display-mode: \"both\" }\n",
        "normalize_method = \"per_pixel\" #@param [\"all_pixels\", \"per_pixel\"]\n",
        "update_weight_method = \"momentum\" #@param [\"normal\", \"momentum\"]\n",
        "num_epoch = 10000 #@param {type:\"integer\"}\n",
        "learning_rate = 0.1 #@param {type:\"number\"}\n",
        "momentum_rate = 0.9 #@param {type:\"number\"}\n",
        "epochs_to_draw = 1000 #@param {type:\"integer\"}\n",
        "\n",
        "np.random.seed(2020)\n",
        "\n",
        "# Load data from file\n",
        "# Make sure that vehicles.dat is in data/\n",
        "train_x, train_y, test_x, test_y = get_vehicle_data()\n",
        "num_train = train_x.shape[0]\n",
        "num_test = test_x.shape[0]\n",
        "\n",
        "# Normalize our data: choose one of the two methods before training\n",
        "if normalize_method == \"all_pixels\":\n",
        "    train_x, test_x = normalize_all_pixels(train_x, test_x) \n",
        "else:\n",
        "    train_x, test_x = normalize_per_pixel(train_x, test_x) \n",
        "\n",
        "# Reshape our data\n",
        "# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n",
        "# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n",
        "train_x = reshape2D(train_x)\n",
        "test_x = reshape2D(test_x)\n",
        "\n",
        "# Pad 1 as the last feature of train_x and test_x\n",
        "train_x = add_one(train_x) \n",
        "test_x = add_one(test_x)\n",
        "\n",
        "# Create classifier\n",
        "num_feature = train_x.shape[1]\n",
        "bin_classifier = LogisticClassifier((num_feature, 1))\n",
        "momentum = np.zeros_like(bin_classifier.w)\n",
        "\n",
        "# Define hyper-parameters and train-related parameters\n",
        "all_loss = []\n",
        "plt.ion()\n",
        "for e in range(num_epoch):    \n",
        "    y_hat = bin_classifier.feed_forward(train_x)\n",
        "    loss = bin_classifier.compute_loss(train_y, y_hat)\n",
        "    grad = bin_classifier.get_grad(train_x, train_y, y_hat)\n",
        "\n",
        "    # Updating weight: choose either normal SGD or SGD with momentum\n",
        "    if update_weight_method == \"normal\":\n",
        "        bin_classifier.update_weight(grad, learning_rate)\n",
        "    else: \n",
        "        bin_classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n",
        "\n",
        "    all_loss.append(loss) \n",
        "\n",
        "    if (e % epochs_to_draw == epochs_to_draw-1):\n",
        "        plot_loss(all_loss)\n",
        "        plt.show()\n",
        "        plt.pause(0.1)     \n",
        "        print(\"Epoch %d: loss is %.5f\" % (e+1, loss))\n",
        "\n",
        "y_hat = bin_classifier.feed_forward(test_x)\n",
        "precision, recall, f1 = test(y_hat, test_y)\n",
        "print(\"Precision: %.3f\" % precision)\n",
        "print(\"Recall: %.3f\" % recall)\n",
        "print(\"F1-score: %.3f\" % f1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9000: loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10000: loss is nan\n",
            "Precision: 0.714\n",
            "Recall: 0.767\n",
            "F1-score: 0.740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qYBIeqd0eEd"
      },
      "source": [
        "## Class LogisticRegressionTF: Logistic regression với Tensorflow\n",
        "Chúng ta sử dụng tensorflow eager execution để cài đặt mô hình logistic regression. Với tf eager execution, giá trị của các biến được tính toán ngay lập tức thay vì xây dựng computational graph để chạy sau đó. Một trong những lợi ích thiết thực nhất là giúp chúng ta dễ dàng debug mô hình, xây dựng được dynamic model.\n",
        "\n",
        "Để xây dựng mô hình bằng eager execution, chúng ta thường định nghĩa một lớp đối tượng như mình họa ở dưới.\n",
        "\n",
        "Chúng ta kế thừa lớp Model và cài đặt 2 hàm chính:\n",
        "- init: khởi tạo tất cả các tham số. \n",
        "- call: hàm dùng cho feedforward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swk_3L72x75j"
      },
      "source": [
        "class LogisticRegressionTF(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_class):\n",
        "        super(LogisticRegressionTF, self).__init__()\n",
        "        # init all weights here\n",
        "        self.dense = tf.keras.layers.Dense(num_class)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        output = self.dense(inputs)\n",
        "        \n",
        "        output = tf.nn.softmax(output)        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ynuv-y1WM5"
      },
      "source": [
        "### TODO 11: Định nghĩa one-hot encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2720NV003uN"
      },
      "source": [
        "# GRADED FUNCTION\n",
        "def create_one_hot(labels, num_k=10):\n",
        "    \"\"\"TODO 11: create_one_hot\n",
        "    This function creates a one-hot (one-of-k) matrix based on the given labels.\n",
        "\n",
        "    :param labels: list of labels, each label is one of 0, 1, 2,... , num_k - 1\n",
        "    :param num_k: number of classes we want to classify\n",
        "    \"\"\"\n",
        "    eye_mat = None\n",
        "    ### START CODE HERE ### (≈2 lines)\n",
        "    eye = np.eye(num_k)\n",
        "    eye_mat = eye[labels]\n",
        "    ### END CODE HERE ###\n",
        "    return eye_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__DN5vkP1ei_"
      },
      "source": [
        "### SANITY CHECK\n",
        "x = [1, 2, 3]\n",
        "y = create_one_hot(x, 4)\n",
        "assert y.shape == (3,4), \"Wrong\"\n",
        "assert sum(np.argmax(y, axis=0)) == 3, \"Wrong\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhoNamB81kaz"
      },
      "source": [
        "### Huấn luyện mô hình với Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct-bwUGm1pDx",
        "outputId": "dfaadd48-fdd7-4c47-bcfe-9a496f3421f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Training { display-mode: \"both\" }\n",
        "normalize_method = \"per_pixel\" #@param [\"all_pixels\", \"per_pixel\"]\n",
        "num_epoch =  2000#@param {type:\"integer\"}\n",
        "learning_rate = 0.001 #@param {type:\"number\"}\n",
        "batch_size = 32\n",
        "num_classes = 2\n",
        "np.random.seed(2020)\n",
        "tf.random.set_seed(2020)\n",
        "\n",
        "# Load data from file\n",
        "# Make sure that vehicles.dat is in data/\n",
        "train_x, train_y, test_x, test_y = get_vehicle_data()\n",
        "num_train = train_x.shape[0]\n",
        "num_test = test_x.shape[0]  \n",
        "\n",
        "#generate_unit_testcase(train_x.copy(), train_y.copy()) \n",
        "#logistic_unit_test()\n",
        "\n",
        "# Normalize our data: choose one of the two methods before training\n",
        "if normalize_method == \"all_pixels\":\n",
        "    train_x, test_x = normalize_all_pixels(train_x, test_x) \n",
        "else:\n",
        "    train_x, test_x = normalize_per_pixel(train_x, test_x) \n",
        "\n",
        "# Reshape our data\n",
        "# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n",
        "# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n",
        "train_x = reshape2D(train_x)\n",
        "test_x = reshape2D(test_x)\n",
        "train_y = create_one_hot(train_y.astype('int32').flatten().tolist(), num_k=2)\n",
        "test_y = create_one_hot(test_y.astype('int32').flatten().tolist(), num_k=2)\n",
        "\n",
        "device = '/cpu:0' if len(tf.config.experimental.list_physical_devices('GPU')) == 0 else '/gpu:0'\n",
        "\n",
        "with tf.device(device):\n",
        "    # build model and optimizer\n",
        "    model = LogisticRegressionTF(num_classes)\n",
        "    model.compile(optimizer=tf.optimizers.Adam(learning_rate), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "    # train\n",
        "    model.fit(train_x, train_y, batch_size=batch_size, epochs=num_epoch,\n",
        "              validation_data=(test_x, test_y), verbose=2)\n",
        "\n",
        "    # evaluate on test set\n",
        "    scores = model.evaluate(test_x, test_y, 32, verbose=2)\n",
        "    \n",
        "    y_hat = model.predict(test_x)\n",
        "    precision, recall, f1 = test(y_hat, test_y)\n",
        "    print(\"Precision: %.3f\" % precision)\n",
        "    print(\"Recall: %.3f\" % recall)\n",
        "    print(\"F1-score: %.3f\" % f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n",
            "Epoch 1/2000\n",
            "75/75 - 0s - loss: 0.4585 - accuracy: 0.8242 - val_loss: 0.6015 - val_accuracy: 0.7700\n",
            "Epoch 2/2000\n",
            "75/75 - 0s - loss: 0.3102 - accuracy: 0.8821 - val_loss: 0.7007 - val_accuracy: 0.7417\n",
            "Epoch 3/2000\n",
            "75/75 - 0s - loss: 0.2784 - accuracy: 0.8896 - val_loss: 0.6857 - val_accuracy: 0.7433\n",
            "Epoch 4/2000\n",
            "75/75 - 0s - loss: 0.2317 - accuracy: 0.9075 - val_loss: 0.7339 - val_accuracy: 0.7633\n",
            "Epoch 5/2000\n",
            "75/75 - 0s - loss: 0.1979 - accuracy: 0.9200 - val_loss: 0.6180 - val_accuracy: 0.7867\n",
            "Epoch 6/2000\n",
            "75/75 - 0s - loss: 0.1731 - accuracy: 0.9296 - val_loss: 0.7129 - val_accuracy: 0.7667\n",
            "Epoch 7/2000\n",
            "75/75 - 0s - loss: 0.1513 - accuracy: 0.9458 - val_loss: 0.6867 - val_accuracy: 0.7567\n",
            "Epoch 8/2000\n",
            "75/75 - 0s - loss: 0.1342 - accuracy: 0.9513 - val_loss: 0.7239 - val_accuracy: 0.7717\n",
            "Epoch 9/2000\n",
            "75/75 - 0s - loss: 0.1425 - accuracy: 0.9429 - val_loss: 0.8153 - val_accuracy: 0.7500\n",
            "Epoch 10/2000\n",
            "75/75 - 0s - loss: 0.1273 - accuracy: 0.9513 - val_loss: 0.7369 - val_accuracy: 0.7683\n",
            "Epoch 11/2000\n",
            "75/75 - 0s - loss: 0.0965 - accuracy: 0.9692 - val_loss: 0.7402 - val_accuracy: 0.7717\n",
            "Epoch 12/2000\n",
            "75/75 - 0s - loss: 0.0911 - accuracy: 0.9754 - val_loss: 0.7991 - val_accuracy: 0.7667\n",
            "Epoch 13/2000\n",
            "75/75 - 0s - loss: 0.0882 - accuracy: 0.9721 - val_loss: 0.7806 - val_accuracy: 0.7683\n",
            "Epoch 14/2000\n",
            "75/75 - 0s - loss: 0.0814 - accuracy: 0.9758 - val_loss: 0.8012 - val_accuracy: 0.7767\n",
            "Epoch 15/2000\n",
            "75/75 - 0s - loss: 0.0746 - accuracy: 0.9792 - val_loss: 0.8166 - val_accuracy: 0.7683\n",
            "Epoch 16/2000\n",
            "75/75 - 0s - loss: 0.0689 - accuracy: 0.9837 - val_loss: 0.8111 - val_accuracy: 0.7667\n",
            "Epoch 17/2000\n",
            "75/75 - 0s - loss: 0.0650 - accuracy: 0.9825 - val_loss: 0.8376 - val_accuracy: 0.7617\n",
            "Epoch 18/2000\n",
            "75/75 - 0s - loss: 0.0646 - accuracy: 0.9837 - val_loss: 0.8669 - val_accuracy: 0.7550\n",
            "Epoch 19/2000\n",
            "75/75 - 0s - loss: 0.0538 - accuracy: 0.9883 - val_loss: 0.9441 - val_accuracy: 0.7633\n",
            "Epoch 20/2000\n",
            "75/75 - 0s - loss: 0.0486 - accuracy: 0.9904 - val_loss: 0.8586 - val_accuracy: 0.7617\n",
            "Epoch 21/2000\n",
            "75/75 - 0s - loss: 0.0466 - accuracy: 0.9908 - val_loss: 0.9337 - val_accuracy: 0.7583\n",
            "Epoch 22/2000\n",
            "75/75 - 0s - loss: 0.0495 - accuracy: 0.9883 - val_loss: 0.9215 - val_accuracy: 0.7800\n",
            "Epoch 23/2000\n",
            "75/75 - 0s - loss: 0.0446 - accuracy: 0.9887 - val_loss: 0.9946 - val_accuracy: 0.7550\n",
            "Epoch 24/2000\n",
            "75/75 - 0s - loss: 0.0484 - accuracy: 0.9858 - val_loss: 0.9743 - val_accuracy: 0.7650\n",
            "Epoch 25/2000\n",
            "75/75 - 0s - loss: 0.0411 - accuracy: 0.9917 - val_loss: 1.0142 - val_accuracy: 0.7617\n",
            "Epoch 26/2000\n",
            "75/75 - 0s - loss: 0.0382 - accuracy: 0.9925 - val_loss: 0.9660 - val_accuracy: 0.7683\n",
            "Epoch 27/2000\n",
            "75/75 - 0s - loss: 0.0364 - accuracy: 0.9937 - val_loss: 0.9577 - val_accuracy: 0.7550\n",
            "Epoch 28/2000\n",
            "75/75 - 0s - loss: 0.0328 - accuracy: 0.9950 - val_loss: 1.0128 - val_accuracy: 0.7567\n",
            "Epoch 29/2000\n",
            "75/75 - 0s - loss: 0.0284 - accuracy: 0.9975 - val_loss: 1.0645 - val_accuracy: 0.7667\n",
            "Epoch 30/2000\n",
            "75/75 - 0s - loss: 0.0304 - accuracy: 0.9950 - val_loss: 1.0129 - val_accuracy: 0.7650\n",
            "Epoch 31/2000\n",
            "75/75 - 0s - loss: 0.0299 - accuracy: 0.9937 - val_loss: 1.0935 - val_accuracy: 0.7517\n",
            "Epoch 32/2000\n",
            "75/75 - 0s - loss: 0.0276 - accuracy: 0.9971 - val_loss: 1.0597 - val_accuracy: 0.7567\n",
            "Epoch 33/2000\n",
            "75/75 - 0s - loss: 0.0231 - accuracy: 0.9979 - val_loss: 1.0893 - val_accuracy: 0.7550\n",
            "Epoch 34/2000\n",
            "75/75 - 0s - loss: 0.0318 - accuracy: 0.9933 - val_loss: 1.1196 - val_accuracy: 0.7483\n",
            "Epoch 35/2000\n",
            "75/75 - 0s - loss: 0.0267 - accuracy: 0.9971 - val_loss: 1.0814 - val_accuracy: 0.7567\n",
            "Epoch 36/2000\n",
            "75/75 - 0s - loss: 0.0210 - accuracy: 0.9971 - val_loss: 1.0762 - val_accuracy: 0.7533\n",
            "Epoch 37/2000\n",
            "75/75 - 0s - loss: 0.0194 - accuracy: 0.9979 - val_loss: 1.1391 - val_accuracy: 0.7583\n",
            "Epoch 38/2000\n",
            "75/75 - 0s - loss: 0.0162 - accuracy: 0.9992 - val_loss: 1.1547 - val_accuracy: 0.7600\n",
            "Epoch 39/2000\n",
            "75/75 - 0s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.7533\n",
            "Epoch 40/2000\n",
            "75/75 - 0s - loss: 0.0151 - accuracy: 0.9992 - val_loss: 1.1647 - val_accuracy: 0.7617\n",
            "Epoch 41/2000\n",
            "75/75 - 0s - loss: 0.0147 - accuracy: 0.9983 - val_loss: 1.2017 - val_accuracy: 0.7600\n",
            "Epoch 42/2000\n",
            "75/75 - 0s - loss: 0.0151 - accuracy: 0.9992 - val_loss: 1.1682 - val_accuracy: 0.7650\n",
            "Epoch 43/2000\n",
            "75/75 - 0s - loss: 0.0150 - accuracy: 0.9992 - val_loss: 1.2413 - val_accuracy: 0.7450\n",
            "Epoch 44/2000\n",
            "75/75 - 0s - loss: 0.0159 - accuracy: 0.9975 - val_loss: 1.1603 - val_accuracy: 0.7450\n",
            "Epoch 45/2000\n",
            "75/75 - 0s - loss: 0.0130 - accuracy: 0.9992 - val_loss: 1.2378 - val_accuracy: 0.7483\n",
            "Epoch 46/2000\n",
            "75/75 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.2512 - val_accuracy: 0.7517\n",
            "Epoch 47/2000\n",
            "75/75 - 0s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.2371 - val_accuracy: 0.7533\n",
            "Epoch 48/2000\n",
            "75/75 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.7517\n",
            "Epoch 49/2000\n",
            "75/75 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.7483\n",
            "Epoch 50/2000\n",
            "75/75 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.7517\n",
            "Epoch 51/2000\n",
            "75/75 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2530 - val_accuracy: 0.7567\n",
            "Epoch 52/2000\n",
            "75/75 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2750 - val_accuracy: 0.7567\n",
            "Epoch 53/2000\n",
            "75/75 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2715 - val_accuracy: 0.7467\n",
            "Epoch 54/2000\n",
            "75/75 - 0s - loss: 0.0114 - accuracy: 0.9987 - val_loss: 1.3043 - val_accuracy: 0.7650\n",
            "Epoch 55/2000\n",
            "75/75 - 0s - loss: 0.0103 - accuracy: 0.9992 - val_loss: 1.3117 - val_accuracy: 0.7683\n",
            "Epoch 56/2000\n",
            "75/75 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.2976 - val_accuracy: 0.7467\n",
            "Epoch 57/2000\n",
            "75/75 - 0s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3471 - val_accuracy: 0.7500\n",
            "Epoch 58/2000\n",
            "75/75 - 0s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.3950 - val_accuracy: 0.7483\n",
            "Epoch 59/2000\n",
            "75/75 - 0s - loss: 0.0222 - accuracy: 0.9946 - val_loss: 1.4121 - val_accuracy: 0.7500\n",
            "Epoch 60/2000\n",
            "75/75 - 0s - loss: 0.0221 - accuracy: 0.9933 - val_loss: 1.4112 - val_accuracy: 0.7517\n",
            "Epoch 61/2000\n",
            "75/75 - 0s - loss: 0.0236 - accuracy: 0.9946 - val_loss: 1.4064 - val_accuracy: 0.7633\n",
            "Epoch 62/2000\n",
            "75/75 - 0s - loss: 0.0083 - accuracy: 0.9996 - val_loss: 1.4390 - val_accuracy: 0.7383\n",
            "Epoch 63/2000\n",
            "75/75 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3963 - val_accuracy: 0.7617\n",
            "Epoch 64/2000\n",
            "75/75 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4525 - val_accuracy: 0.7433\n",
            "Epoch 65/2000\n",
            "75/75 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4139 - val_accuracy: 0.7450\n",
            "Epoch 66/2000\n",
            "75/75 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4235 - val_accuracy: 0.7583\n",
            "Epoch 67/2000\n",
            "75/75 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4284 - val_accuracy: 0.7567\n",
            "Epoch 68/2000\n",
            "75/75 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4445 - val_accuracy: 0.7550\n",
            "Epoch 69/2000\n",
            "75/75 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4424 - val_accuracy: 0.7550\n",
            "Epoch 70/2000\n",
            "75/75 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4505 - val_accuracy: 0.7567\n",
            "Epoch 71/2000\n",
            "75/75 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4455 - val_accuracy: 0.7567\n",
            "Epoch 72/2000\n",
            "75/75 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4565 - val_accuracy: 0.7500\n",
            "Epoch 73/2000\n",
            "75/75 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4696 - val_accuracy: 0.7517\n",
            "Epoch 74/2000\n",
            "75/75 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4591 - val_accuracy: 0.7483\n",
            "Epoch 75/2000\n",
            "75/75 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4679 - val_accuracy: 0.7450\n",
            "Epoch 76/2000\n",
            "75/75 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4840 - val_accuracy: 0.7483\n",
            "Epoch 77/2000\n",
            "75/75 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4824 - val_accuracy: 0.7500\n",
            "Epoch 78/2000\n",
            "75/75 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.7483\n",
            "Epoch 79/2000\n",
            "75/75 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.5110 - val_accuracy: 0.7567\n",
            "Epoch 80/2000\n",
            "75/75 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4893 - val_accuracy: 0.7617\n",
            "Epoch 81/2000\n",
            "75/75 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5093 - val_accuracy: 0.7500\n",
            "Epoch 82/2000\n",
            "75/75 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5167 - val_accuracy: 0.7450\n",
            "Epoch 83/2000\n",
            "75/75 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5280 - val_accuracy: 0.7500\n",
            "Epoch 84/2000\n",
            "75/75 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5282 - val_accuracy: 0.7517\n",
            "Epoch 85/2000\n",
            "75/75 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.5267 - val_accuracy: 0.7517\n",
            "Epoch 86/2000\n",
            "75/75 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.5357 - val_accuracy: 0.7550\n",
            "Epoch 87/2000\n",
            "75/75 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5351 - val_accuracy: 0.7550\n",
            "Epoch 88/2000\n",
            "75/75 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5446 - val_accuracy: 0.7450\n",
            "Epoch 89/2000\n",
            "75/75 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5776 - val_accuracy: 0.7400\n",
            "Epoch 90/2000\n",
            "75/75 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5446 - val_accuracy: 0.7483\n",
            "Epoch 91/2000\n",
            "75/75 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.7450\n",
            "Epoch 92/2000\n",
            "75/75 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5557 - val_accuracy: 0.7517\n",
            "Epoch 93/2000\n",
            "75/75 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.7467\n",
            "Epoch 94/2000\n",
            "75/75 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5919 - val_accuracy: 0.7483\n",
            "Epoch 95/2000\n",
            "75/75 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.7483\n",
            "Epoch 96/2000\n",
            "75/75 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.7483\n",
            "Epoch 97/2000\n",
            "75/75 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5913 - val_accuracy: 0.7500\n",
            "Epoch 98/2000\n",
            "75/75 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5913 - val_accuracy: 0.7517\n",
            "Epoch 99/2000\n",
            "75/75 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6035 - val_accuracy: 0.7467\n",
            "Epoch 100/2000\n",
            "75/75 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6216 - val_accuracy: 0.7450\n",
            "Epoch 101/2000\n",
            "75/75 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6105 - val_accuracy: 0.7533\n",
            "Epoch 102/2000\n",
            "75/75 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6243 - val_accuracy: 0.7483\n",
            "Epoch 103/2000\n",
            "75/75 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6382 - val_accuracy: 0.7517\n",
            "Epoch 104/2000\n",
            "75/75 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6220 - val_accuracy: 0.7500\n",
            "Epoch 105/2000\n",
            "75/75 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6116 - val_accuracy: 0.7550\n",
            "Epoch 106/2000\n",
            "75/75 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7148 - val_accuracy: 0.7433\n",
            "Epoch 107/2000\n",
            "75/75 - 0s - loss: 0.1808 - accuracy: 0.9671 - val_loss: 1.9463 - val_accuracy: 0.7850\n",
            "Epoch 108/2000\n",
            "75/75 - 0s - loss: 0.2340 - accuracy: 0.9417 - val_loss: 2.1323 - val_accuracy: 0.7450\n",
            "Epoch 109/2000\n",
            "75/75 - 0s - loss: 0.0576 - accuracy: 0.9796 - val_loss: 1.9185 - val_accuracy: 0.7583\n",
            "Epoch 110/2000\n",
            "75/75 - 0s - loss: 0.0221 - accuracy: 0.9925 - val_loss: 1.8653 - val_accuracy: 0.7700\n",
            "Epoch 111/2000\n",
            "75/75 - 0s - loss: 0.0070 - accuracy: 0.9987 - val_loss: 1.8950 - val_accuracy: 0.7633\n",
            "Epoch 112/2000\n",
            "75/75 - 0s - loss: 0.0027 - accuracy: 0.9996 - val_loss: 1.8482 - val_accuracy: 0.7633\n",
            "Epoch 113/2000\n",
            "75/75 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8793 - val_accuracy: 0.7633\n",
            "Epoch 114/2000\n",
            "75/75 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8745 - val_accuracy: 0.7583\n",
            "Epoch 115/2000\n",
            "75/75 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8614 - val_accuracy: 0.7650\n",
            "Epoch 116/2000\n",
            "75/75 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8726 - val_accuracy: 0.7633\n",
            "Epoch 117/2000\n",
            "75/75 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8657 - val_accuracy: 0.7633\n",
            "Epoch 118/2000\n",
            "75/75 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8687 - val_accuracy: 0.7650\n",
            "Epoch 119/2000\n",
            "75/75 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8660 - val_accuracy: 0.7633\n",
            "Epoch 120/2000\n",
            "75/75 - 0s - loss: 9.6002e-04 - accuracy: 1.0000 - val_loss: 1.8561 - val_accuracy: 0.7667\n",
            "Epoch 121/2000\n",
            "75/75 - 0s - loss: 9.5905e-04 - accuracy: 1.0000 - val_loss: 1.8670 - val_accuracy: 0.7633\n",
            "Epoch 122/2000\n",
            "75/75 - 0s - loss: 9.0011e-04 - accuracy: 1.0000 - val_loss: 1.8610 - val_accuracy: 0.7650\n",
            "Epoch 123/2000\n",
            "75/75 - 0s - loss: 8.7056e-04 - accuracy: 1.0000 - val_loss: 1.8602 - val_accuracy: 0.7650\n",
            "Epoch 124/2000\n",
            "75/75 - 0s - loss: 8.5651e-04 - accuracy: 1.0000 - val_loss: 1.8624 - val_accuracy: 0.7617\n",
            "Epoch 125/2000\n",
            "75/75 - 0s - loss: 8.3098e-04 - accuracy: 1.0000 - val_loss: 1.8569 - val_accuracy: 0.7600\n",
            "Epoch 126/2000\n",
            "75/75 - 0s - loss: 8.2918e-04 - accuracy: 1.0000 - val_loss: 1.8585 - val_accuracy: 0.7650\n",
            "Epoch 127/2000\n",
            "75/75 - 0s - loss: 8.0157e-04 - accuracy: 1.0000 - val_loss: 1.8679 - val_accuracy: 0.7600\n",
            "Epoch 128/2000\n",
            "75/75 - 0s - loss: 7.6511e-04 - accuracy: 1.0000 - val_loss: 1.8641 - val_accuracy: 0.7617\n",
            "Epoch 129/2000\n",
            "75/75 - 0s - loss: 7.5076e-04 - accuracy: 1.0000 - val_loss: 1.8673 - val_accuracy: 0.7567\n",
            "Epoch 130/2000\n",
            "75/75 - 0s - loss: 7.3553e-04 - accuracy: 1.0000 - val_loss: 1.8658 - val_accuracy: 0.7583\n",
            "Epoch 131/2000\n",
            "75/75 - 0s - loss: 7.2519e-04 - accuracy: 1.0000 - val_loss: 1.8732 - val_accuracy: 0.7567\n",
            "Epoch 132/2000\n",
            "75/75 - 0s - loss: 7.0866e-04 - accuracy: 1.0000 - val_loss: 1.8639 - val_accuracy: 0.7567\n",
            "Epoch 133/2000\n",
            "75/75 - 0s - loss: 6.9256e-04 - accuracy: 1.0000 - val_loss: 1.8605 - val_accuracy: 0.7600\n",
            "Epoch 134/2000\n",
            "75/75 - 0s - loss: 6.7745e-04 - accuracy: 1.0000 - val_loss: 1.8622 - val_accuracy: 0.7617\n",
            "Epoch 135/2000\n",
            "75/75 - 0s - loss: 6.6216e-04 - accuracy: 1.0000 - val_loss: 1.8580 - val_accuracy: 0.7617\n",
            "Epoch 136/2000\n",
            "75/75 - 0s - loss: 6.4595e-04 - accuracy: 1.0000 - val_loss: 1.8652 - val_accuracy: 0.7567\n",
            "Epoch 137/2000\n",
            "75/75 - 0s - loss: 6.4049e-04 - accuracy: 1.0000 - val_loss: 1.8664 - val_accuracy: 0.7583\n",
            "Epoch 138/2000\n",
            "75/75 - 0s - loss: 6.2245e-04 - accuracy: 1.0000 - val_loss: 1.8768 - val_accuracy: 0.7583\n",
            "Epoch 139/2000\n",
            "75/75 - 0s - loss: 6.1548e-04 - accuracy: 1.0000 - val_loss: 1.8658 - val_accuracy: 0.7583\n",
            "Epoch 140/2000\n",
            "75/75 - 0s - loss: 6.1330e-04 - accuracy: 1.0000 - val_loss: 1.8580 - val_accuracy: 0.7600\n",
            "Epoch 141/2000\n",
            "75/75 - 0s - loss: 5.8939e-04 - accuracy: 1.0000 - val_loss: 1.8643 - val_accuracy: 0.7600\n",
            "Epoch 142/2000\n",
            "75/75 - 0s - loss: 5.8346e-04 - accuracy: 1.0000 - val_loss: 1.8663 - val_accuracy: 0.7633\n",
            "Epoch 143/2000\n",
            "75/75 - 0s - loss: 5.7571e-04 - accuracy: 1.0000 - val_loss: 1.8829 - val_accuracy: 0.7567\n",
            "Epoch 144/2000\n",
            "75/75 - 0s - loss: 5.7285e-04 - accuracy: 1.0000 - val_loss: 1.8732 - val_accuracy: 0.7567\n",
            "Epoch 145/2000\n",
            "75/75 - 0s - loss: 5.6012e-04 - accuracy: 1.0000 - val_loss: 1.8667 - val_accuracy: 0.7617\n",
            "Epoch 146/2000\n",
            "75/75 - 0s - loss: 5.4774e-04 - accuracy: 1.0000 - val_loss: 1.8730 - val_accuracy: 0.7583\n",
            "Epoch 147/2000\n",
            "75/75 - 0s - loss: 5.3917e-04 - accuracy: 1.0000 - val_loss: 1.8791 - val_accuracy: 0.7567\n",
            "Epoch 148/2000\n",
            "75/75 - 0s - loss: 5.3597e-04 - accuracy: 1.0000 - val_loss: 1.8719 - val_accuracy: 0.7583\n",
            "Epoch 149/2000\n",
            "75/75 - 0s - loss: 5.1543e-04 - accuracy: 1.0000 - val_loss: 1.8702 - val_accuracy: 0.7567\n",
            "Epoch 150/2000\n",
            "75/75 - 0s - loss: 5.1162e-04 - accuracy: 1.0000 - val_loss: 1.8788 - val_accuracy: 0.7567\n",
            "Epoch 151/2000\n",
            "75/75 - 0s - loss: 4.9643e-04 - accuracy: 1.0000 - val_loss: 1.8702 - val_accuracy: 0.7567\n",
            "Epoch 152/2000\n",
            "75/75 - 0s - loss: 5.1200e-04 - accuracy: 1.0000 - val_loss: 1.8771 - val_accuracy: 0.7583\n",
            "Epoch 153/2000\n",
            "75/75 - 0s - loss: 4.7835e-04 - accuracy: 1.0000 - val_loss: 1.8890 - val_accuracy: 0.7567\n",
            "Epoch 154/2000\n",
            "75/75 - 0s - loss: 4.7205e-04 - accuracy: 1.0000 - val_loss: 1.8723 - val_accuracy: 0.7550\n",
            "Epoch 155/2000\n",
            "75/75 - 0s - loss: 4.6606e-04 - accuracy: 1.0000 - val_loss: 1.8779 - val_accuracy: 0.7550\n",
            "Epoch 156/2000\n",
            "75/75 - 0s - loss: 4.5772e-04 - accuracy: 1.0000 - val_loss: 1.8841 - val_accuracy: 0.7550\n",
            "Epoch 157/2000\n",
            "75/75 - 0s - loss: 4.5265e-04 - accuracy: 1.0000 - val_loss: 1.8845 - val_accuracy: 0.7583\n",
            "Epoch 158/2000\n",
            "75/75 - 0s - loss: 4.4236e-04 - accuracy: 1.0000 - val_loss: 1.8895 - val_accuracy: 0.7533\n",
            "Epoch 159/2000\n",
            "75/75 - 0s - loss: 4.3410e-04 - accuracy: 1.0000 - val_loss: 1.8807 - val_accuracy: 0.7567\n",
            "Epoch 160/2000\n",
            "75/75 - 0s - loss: 4.3422e-04 - accuracy: 1.0000 - val_loss: 1.8792 - val_accuracy: 0.7550\n",
            "Epoch 161/2000\n",
            "75/75 - 0s - loss: 4.3291e-04 - accuracy: 1.0000 - val_loss: 1.8831 - val_accuracy: 0.7567\n",
            "Epoch 162/2000\n",
            "75/75 - 0s - loss: 4.3350e-04 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.7567\n",
            "Epoch 163/2000\n",
            "75/75 - 0s - loss: 4.2657e-04 - accuracy: 1.0000 - val_loss: 1.8909 - val_accuracy: 0.7567\n",
            "Epoch 164/2000\n",
            "75/75 - 0s - loss: 4.0382e-04 - accuracy: 1.0000 - val_loss: 1.8920 - val_accuracy: 0.7567\n",
            "Epoch 165/2000\n",
            "75/75 - 0s - loss: 4.0051e-04 - accuracy: 1.0000 - val_loss: 1.9087 - val_accuracy: 0.7550\n",
            "Epoch 166/2000\n",
            "75/75 - 0s - loss: 3.9768e-04 - accuracy: 1.0000 - val_loss: 1.8882 - val_accuracy: 0.7517\n",
            "Epoch 167/2000\n",
            "75/75 - 0s - loss: 3.8094e-04 - accuracy: 1.0000 - val_loss: 1.9009 - val_accuracy: 0.7533\n",
            "Epoch 168/2000\n",
            "75/75 - 0s - loss: 3.8222e-04 - accuracy: 1.0000 - val_loss: 1.8889 - val_accuracy: 0.7517\n",
            "Epoch 169/2000\n",
            "75/75 - 0s - loss: 3.7325e-04 - accuracy: 1.0000 - val_loss: 1.8931 - val_accuracy: 0.7567\n",
            "Epoch 170/2000\n",
            "75/75 - 0s - loss: 3.6561e-04 - accuracy: 1.0000 - val_loss: 1.8959 - val_accuracy: 0.7500\n",
            "Epoch 171/2000\n",
            "75/75 - 0s - loss: 3.6294e-04 - accuracy: 1.0000 - val_loss: 1.9033 - val_accuracy: 0.7483\n",
            "Epoch 172/2000\n",
            "75/75 - 0s - loss: 3.5099e-04 - accuracy: 1.0000 - val_loss: 1.8983 - val_accuracy: 0.7500\n",
            "Epoch 173/2000\n",
            "75/75 - 0s - loss: 3.4581e-04 - accuracy: 1.0000 - val_loss: 1.9094 - val_accuracy: 0.7567\n",
            "Epoch 174/2000\n",
            "75/75 - 0s - loss: 3.3681e-04 - accuracy: 1.0000 - val_loss: 1.9053 - val_accuracy: 0.7517\n",
            "Epoch 175/2000\n",
            "75/75 - 0s - loss: 3.4131e-04 - accuracy: 1.0000 - val_loss: 1.9166 - val_accuracy: 0.7517\n",
            "Epoch 176/2000\n",
            "75/75 - 0s - loss: 3.2812e-04 - accuracy: 1.0000 - val_loss: 1.9240 - val_accuracy: 0.7517\n",
            "Epoch 177/2000\n",
            "75/75 - 0s - loss: 3.2649e-04 - accuracy: 1.0000 - val_loss: 1.9187 - val_accuracy: 0.7517\n",
            "Epoch 178/2000\n",
            "75/75 - 0s - loss: 3.1556e-04 - accuracy: 1.0000 - val_loss: 1.9095 - val_accuracy: 0.7550\n",
            "Epoch 179/2000\n",
            "75/75 - 0s - loss: 3.1718e-04 - accuracy: 1.0000 - val_loss: 1.9242 - val_accuracy: 0.7550\n",
            "Epoch 180/2000\n",
            "75/75 - 0s - loss: 3.1094e-04 - accuracy: 1.0000 - val_loss: 1.9168 - val_accuracy: 0.7550\n",
            "Epoch 181/2000\n",
            "75/75 - 0s - loss: 3.0006e-04 - accuracy: 1.0000 - val_loss: 1.9330 - val_accuracy: 0.7567\n",
            "Epoch 182/2000\n",
            "75/75 - 0s - loss: 2.9137e-04 - accuracy: 1.0000 - val_loss: 1.9331 - val_accuracy: 0.7483\n",
            "Epoch 183/2000\n",
            "75/75 - 0s - loss: 2.8812e-04 - accuracy: 1.0000 - val_loss: 1.9388 - val_accuracy: 0.7517\n",
            "Epoch 184/2000\n",
            "75/75 - 0s - loss: 2.7400e-04 - accuracy: 1.0000 - val_loss: 1.9322 - val_accuracy: 0.7550\n",
            "Epoch 185/2000\n",
            "75/75 - 0s - loss: 2.7967e-04 - accuracy: 1.0000 - val_loss: 1.9410 - val_accuracy: 0.7517\n",
            "Epoch 186/2000\n",
            "75/75 - 0s - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: 1.9361 - val_accuracy: 0.7517\n",
            "Epoch 187/2000\n",
            "75/75 - 0s - loss: 2.7397e-04 - accuracy: 1.0000 - val_loss: 1.9369 - val_accuracy: 0.7550\n",
            "Epoch 188/2000\n",
            "75/75 - 0s - loss: 2.6678e-04 - accuracy: 1.0000 - val_loss: 1.9311 - val_accuracy: 0.7567\n",
            "Epoch 189/2000\n",
            "75/75 - 0s - loss: 2.5885e-04 - accuracy: 1.0000 - val_loss: 1.9387 - val_accuracy: 0.7517\n",
            "Epoch 190/2000\n",
            "75/75 - 0s - loss: 2.4803e-04 - accuracy: 1.0000 - val_loss: 1.9484 - val_accuracy: 0.7533\n",
            "Epoch 191/2000\n",
            "75/75 - 0s - loss: 2.4588e-04 - accuracy: 1.0000 - val_loss: 1.9529 - val_accuracy: 0.7500\n",
            "Epoch 192/2000\n",
            "75/75 - 0s - loss: 2.8260e-04 - accuracy: 1.0000 - val_loss: 1.9632 - val_accuracy: 0.7533\n",
            "Epoch 193/2000\n",
            "75/75 - 0s - loss: 2.4708e-04 - accuracy: 1.0000 - val_loss: 1.9915 - val_accuracy: 0.7483\n",
            "Epoch 194/2000\n",
            "75/75 - 0s - loss: 2.4263e-04 - accuracy: 1.0000 - val_loss: 1.9703 - val_accuracy: 0.7550\n",
            "Epoch 195/2000\n",
            "75/75 - 0s - loss: 2.2942e-04 - accuracy: 1.0000 - val_loss: 1.9748 - val_accuracy: 0.7583\n",
            "Epoch 196/2000\n",
            "75/75 - 0s - loss: 2.2687e-04 - accuracy: 1.0000 - val_loss: 1.9638 - val_accuracy: 0.7517\n",
            "Epoch 197/2000\n",
            "75/75 - 0s - loss: 2.2713e-04 - accuracy: 1.0000 - val_loss: 1.9625 - val_accuracy: 0.7550\n",
            "Epoch 198/2000\n",
            "75/75 - 0s - loss: 2.1826e-04 - accuracy: 1.0000 - val_loss: 1.9800 - val_accuracy: 0.7583\n",
            "Epoch 199/2000\n",
            "75/75 - 0s - loss: 2.1112e-04 - accuracy: 1.0000 - val_loss: 1.9544 - val_accuracy: 0.7550\n",
            "Epoch 200/2000\n",
            "75/75 - 0s - loss: 2.0449e-04 - accuracy: 1.0000 - val_loss: 1.9718 - val_accuracy: 0.7533\n",
            "Epoch 201/2000\n",
            "75/75 - 0s - loss: 2.0914e-04 - accuracy: 1.0000 - val_loss: 1.9573 - val_accuracy: 0.7567\n",
            "Epoch 202/2000\n",
            "75/75 - 0s - loss: 2.1498e-04 - accuracy: 1.0000 - val_loss: 1.9856 - val_accuracy: 0.7567\n",
            "Epoch 203/2000\n",
            "75/75 - 0s - loss: 2.0376e-04 - accuracy: 1.0000 - val_loss: 1.9586 - val_accuracy: 0.7617\n",
            "Epoch 204/2000\n",
            "75/75 - 0s - loss: 0.0484 - accuracy: 0.9912 - val_loss: 2.1382 - val_accuracy: 0.7517\n",
            "Epoch 205/2000\n",
            "75/75 - 0s - loss: 0.1949 - accuracy: 0.9579 - val_loss: 2.4460 - val_accuracy: 0.7350\n",
            "Epoch 206/2000\n",
            "75/75 - 0s - loss: 0.0838 - accuracy: 0.9737 - val_loss: 2.1488 - val_accuracy: 0.7633\n",
            "Epoch 207/2000\n",
            "75/75 - 0s - loss: 0.0139 - accuracy: 0.9958 - val_loss: 2.1358 - val_accuracy: 0.7633\n",
            "Epoch 208/2000\n",
            "75/75 - 0s - loss: 0.0050 - accuracy: 0.9987 - val_loss: 2.1512 - val_accuracy: 0.7650\n",
            "Epoch 209/2000\n",
            "75/75 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1497 - val_accuracy: 0.7567\n",
            "Epoch 210/2000\n",
            "75/75 - 0s - loss: 5.7437e-04 - accuracy: 1.0000 - val_loss: 2.1371 - val_accuracy: 0.7567\n",
            "Epoch 211/2000\n",
            "75/75 - 0s - loss: 4.6975e-04 - accuracy: 1.0000 - val_loss: 2.1311 - val_accuracy: 0.7583\n",
            "Epoch 212/2000\n",
            "75/75 - 0s - loss: 4.2423e-04 - accuracy: 1.0000 - val_loss: 2.1294 - val_accuracy: 0.7567\n",
            "Epoch 213/2000\n",
            "75/75 - 0s - loss: 3.9427e-04 - accuracy: 1.0000 - val_loss: 2.1274 - val_accuracy: 0.7567\n",
            "Epoch 214/2000\n",
            "75/75 - 0s - loss: 3.7145e-04 - accuracy: 1.0000 - val_loss: 2.1251 - val_accuracy: 0.7567\n",
            "Epoch 215/2000\n",
            "75/75 - 0s - loss: 3.5476e-04 - accuracy: 1.0000 - val_loss: 2.1262 - val_accuracy: 0.7567\n",
            "Epoch 216/2000\n",
            "75/75 - 0s - loss: 3.3720e-04 - accuracy: 1.0000 - val_loss: 2.1203 - val_accuracy: 0.7583\n",
            "Epoch 217/2000\n",
            "75/75 - 0s - loss: 3.2593e-04 - accuracy: 1.0000 - val_loss: 2.1211 - val_accuracy: 0.7567\n",
            "Epoch 218/2000\n",
            "75/75 - 0s - loss: 3.1385e-04 - accuracy: 1.0000 - val_loss: 2.1222 - val_accuracy: 0.7567\n",
            "Epoch 219/2000\n",
            "75/75 - 0s - loss: 3.0163e-04 - accuracy: 1.0000 - val_loss: 2.1225 - val_accuracy: 0.7583\n",
            "Epoch 220/2000\n",
            "75/75 - 0s - loss: 2.9315e-04 - accuracy: 1.0000 - val_loss: 2.1214 - val_accuracy: 0.7583\n",
            "Epoch 221/2000\n",
            "75/75 - 0s - loss: 2.8540e-04 - accuracy: 1.0000 - val_loss: 2.1203 - val_accuracy: 0.7583\n",
            "Epoch 222/2000\n",
            "75/75 - 0s - loss: 2.7648e-04 - accuracy: 1.0000 - val_loss: 2.1189 - val_accuracy: 0.7583\n",
            "Epoch 223/2000\n",
            "75/75 - 0s - loss: 2.6821e-04 - accuracy: 1.0000 - val_loss: 2.1184 - val_accuracy: 0.7600\n",
            "Epoch 224/2000\n",
            "75/75 - 0s - loss: 2.6268e-04 - accuracy: 1.0000 - val_loss: 2.1192 - val_accuracy: 0.7600\n",
            "Epoch 225/2000\n",
            "75/75 - 0s - loss: 2.5522e-04 - accuracy: 1.0000 - val_loss: 2.1196 - val_accuracy: 0.7600\n",
            "Epoch 226/2000\n",
            "75/75 - 0s - loss: 2.4896e-04 - accuracy: 1.0000 - val_loss: 2.1186 - val_accuracy: 0.7600\n",
            "Epoch 227/2000\n",
            "75/75 - 0s - loss: 2.4409e-04 - accuracy: 1.0000 - val_loss: 2.1185 - val_accuracy: 0.7617\n",
            "Epoch 228/2000\n",
            "75/75 - 0s - loss: 2.3884e-04 - accuracy: 1.0000 - val_loss: 2.1183 - val_accuracy: 0.7583\n",
            "Epoch 229/2000\n",
            "75/75 - 0s - loss: 2.3249e-04 - accuracy: 1.0000 - val_loss: 2.1192 - val_accuracy: 0.7600\n",
            "Epoch 230/2000\n",
            "75/75 - 0s - loss: 2.2838e-04 - accuracy: 1.0000 - val_loss: 2.1196 - val_accuracy: 0.7600\n",
            "Epoch 231/2000\n",
            "75/75 - 0s - loss: 2.2342e-04 - accuracy: 1.0000 - val_loss: 2.1184 - val_accuracy: 0.7583\n",
            "Epoch 232/2000\n",
            "75/75 - 0s - loss: 2.1902e-04 - accuracy: 1.0000 - val_loss: 2.1177 - val_accuracy: 0.7600\n",
            "Epoch 233/2000\n",
            "75/75 - 0s - loss: 2.1405e-04 - accuracy: 1.0000 - val_loss: 2.1205 - val_accuracy: 0.7600\n",
            "Epoch 234/2000\n",
            "75/75 - 0s - loss: 2.0920e-04 - accuracy: 1.0000 - val_loss: 2.1192 - val_accuracy: 0.7600\n",
            "Epoch 235/2000\n",
            "75/75 - 0s - loss: 2.0732e-04 - accuracy: 1.0000 - val_loss: 2.1199 - val_accuracy: 0.7583\n",
            "Epoch 236/2000\n",
            "75/75 - 0s - loss: 2.0269e-04 - accuracy: 1.0000 - val_loss: 2.1250 - val_accuracy: 0.7583\n",
            "Epoch 237/2000\n",
            "75/75 - 0s - loss: 1.9726e-04 - accuracy: 1.0000 - val_loss: 2.1197 - val_accuracy: 0.7600\n",
            "Epoch 238/2000\n",
            "75/75 - 0s - loss: 1.9687e-04 - accuracy: 1.0000 - val_loss: 2.1171 - val_accuracy: 0.7600\n",
            "Epoch 239/2000\n",
            "75/75 - 0s - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 2.1178 - val_accuracy: 0.7600\n",
            "Epoch 240/2000\n",
            "75/75 - 0s - loss: 1.8800e-04 - accuracy: 1.0000 - val_loss: 2.1237 - val_accuracy: 0.7583\n",
            "Epoch 241/2000\n",
            "75/75 - 0s - loss: 1.8529e-04 - accuracy: 1.0000 - val_loss: 2.1219 - val_accuracy: 0.7583\n",
            "Epoch 242/2000\n",
            "75/75 - 0s - loss: 1.8148e-04 - accuracy: 1.0000 - val_loss: 2.1239 - val_accuracy: 0.7583\n",
            "Epoch 243/2000\n",
            "75/75 - 0s - loss: 1.7855e-04 - accuracy: 1.0000 - val_loss: 2.1238 - val_accuracy: 0.7583\n",
            "Epoch 244/2000\n",
            "75/75 - 0s - loss: 1.7650e-04 - accuracy: 1.0000 - val_loss: 2.1175 - val_accuracy: 0.7583\n",
            "Epoch 245/2000\n",
            "75/75 - 0s - loss: 1.7266e-04 - accuracy: 1.0000 - val_loss: 2.1193 - val_accuracy: 0.7583\n",
            "Epoch 246/2000\n",
            "75/75 - 0s - loss: 1.6997e-04 - accuracy: 1.0000 - val_loss: 2.1215 - val_accuracy: 0.7583\n",
            "Epoch 247/2000\n",
            "75/75 - 0s - loss: 1.6795e-04 - accuracy: 1.0000 - val_loss: 2.1262 - val_accuracy: 0.7583\n",
            "Epoch 248/2000\n",
            "75/75 - 0s - loss: 1.6377e-04 - accuracy: 1.0000 - val_loss: 2.1260 - val_accuracy: 0.7583\n",
            "Epoch 249/2000\n",
            "75/75 - 0s - loss: 1.6184e-04 - accuracy: 1.0000 - val_loss: 2.1272 - val_accuracy: 0.7583\n",
            "Epoch 250/2000\n",
            "75/75 - 0s - loss: 1.5948e-04 - accuracy: 1.0000 - val_loss: 2.1221 - val_accuracy: 0.7583\n",
            "Epoch 251/2000\n",
            "75/75 - 0s - loss: 1.5627e-04 - accuracy: 1.0000 - val_loss: 2.1263 - val_accuracy: 0.7583\n",
            "Epoch 252/2000\n",
            "75/75 - 0s - loss: 1.5451e-04 - accuracy: 1.0000 - val_loss: 2.1295 - val_accuracy: 0.7567\n",
            "Epoch 253/2000\n",
            "75/75 - 0s - loss: 1.5154e-04 - accuracy: 1.0000 - val_loss: 2.1230 - val_accuracy: 0.7583\n",
            "Epoch 254/2000\n",
            "75/75 - 0s - loss: 1.4984e-04 - accuracy: 1.0000 - val_loss: 2.1261 - val_accuracy: 0.7583\n",
            "Epoch 255/2000\n",
            "75/75 - 0s - loss: 1.4718e-04 - accuracy: 1.0000 - val_loss: 2.1263 - val_accuracy: 0.7583\n",
            "Epoch 256/2000\n",
            "75/75 - 0s - loss: 1.4502e-04 - accuracy: 1.0000 - val_loss: 2.1279 - val_accuracy: 0.7583\n",
            "Epoch 257/2000\n",
            "75/75 - 0s - loss: 1.4264e-04 - accuracy: 1.0000 - val_loss: 2.1349 - val_accuracy: 0.7567\n",
            "Epoch 258/2000\n",
            "75/75 - 0s - loss: 1.4183e-04 - accuracy: 1.0000 - val_loss: 2.1288 - val_accuracy: 0.7567\n",
            "Epoch 259/2000\n",
            "75/75 - 0s - loss: 1.4050e-04 - accuracy: 1.0000 - val_loss: 2.1301 - val_accuracy: 0.7567\n",
            "Epoch 260/2000\n",
            "75/75 - 0s - loss: 1.3580e-04 - accuracy: 1.0000 - val_loss: 2.1276 - val_accuracy: 0.7583\n",
            "Epoch 261/2000\n",
            "75/75 - 0s - loss: 1.3502e-04 - accuracy: 1.0000 - val_loss: 2.1286 - val_accuracy: 0.7583\n",
            "Epoch 262/2000\n",
            "75/75 - 0s - loss: 1.3237e-04 - accuracy: 1.0000 - val_loss: 2.1327 - val_accuracy: 0.7567\n",
            "Epoch 263/2000\n",
            "75/75 - 0s - loss: 1.3094e-04 - accuracy: 1.0000 - val_loss: 2.1358 - val_accuracy: 0.7583\n",
            "Epoch 264/2000\n",
            "75/75 - 0s - loss: 1.2906e-04 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.7567\n",
            "Epoch 265/2000\n",
            "75/75 - 0s - loss: 1.2700e-04 - accuracy: 1.0000 - val_loss: 2.1284 - val_accuracy: 0.7583\n",
            "Epoch 266/2000\n",
            "75/75 - 0s - loss: 1.2515e-04 - accuracy: 1.0000 - val_loss: 2.1295 - val_accuracy: 0.7583\n",
            "Epoch 267/2000\n",
            "75/75 - 0s - loss: 1.2524e-04 - accuracy: 1.0000 - val_loss: 2.1327 - val_accuracy: 0.7550\n",
            "Epoch 268/2000\n",
            "75/75 - 0s - loss: 1.2200e-04 - accuracy: 1.0000 - val_loss: 2.1297 - val_accuracy: 0.7567\n",
            "Epoch 269/2000\n",
            "75/75 - 0s - loss: 1.2019e-04 - accuracy: 1.0000 - val_loss: 2.1325 - val_accuracy: 0.7567\n",
            "Epoch 270/2000\n",
            "75/75 - 0s - loss: 1.1794e-04 - accuracy: 1.0000 - val_loss: 2.1273 - val_accuracy: 0.7583\n",
            "Epoch 271/2000\n",
            "75/75 - 0s - loss: 1.1662e-04 - accuracy: 1.0000 - val_loss: 2.1334 - val_accuracy: 0.7583\n",
            "Epoch 272/2000\n",
            "75/75 - 0s - loss: 1.1523e-04 - accuracy: 1.0000 - val_loss: 2.1375 - val_accuracy: 0.7567\n",
            "Epoch 273/2000\n",
            "75/75 - 0s - loss: 1.1374e-04 - accuracy: 1.0000 - val_loss: 2.1397 - val_accuracy: 0.7567\n",
            "Epoch 274/2000\n",
            "75/75 - 0s - loss: 1.1261e-04 - accuracy: 1.0000 - val_loss: 2.1369 - val_accuracy: 0.7567\n",
            "Epoch 275/2000\n",
            "75/75 - 0s - loss: 1.0959e-04 - accuracy: 1.0000 - val_loss: 2.1357 - val_accuracy: 0.7600\n",
            "Epoch 276/2000\n",
            "75/75 - 0s - loss: 1.0819e-04 - accuracy: 1.0000 - val_loss: 2.1455 - val_accuracy: 0.7583\n",
            "Epoch 277/2000\n",
            "75/75 - 0s - loss: 1.0718e-04 - accuracy: 1.0000 - val_loss: 2.1414 - val_accuracy: 0.7567\n",
            "Epoch 278/2000\n",
            "75/75 - 0s - loss: 1.0569e-04 - accuracy: 1.0000 - val_loss: 2.1413 - val_accuracy: 0.7583\n",
            "Epoch 279/2000\n",
            "75/75 - 0s - loss: 1.0282e-04 - accuracy: 1.0000 - val_loss: 2.1494 - val_accuracy: 0.7567\n",
            "Epoch 280/2000\n",
            "75/75 - 0s - loss: 1.0281e-04 - accuracy: 1.0000 - val_loss: 2.1498 - val_accuracy: 0.7583\n",
            "Epoch 281/2000\n",
            "75/75 - 0s - loss: 1.0259e-04 - accuracy: 1.0000 - val_loss: 2.1512 - val_accuracy: 0.7583\n",
            "Epoch 282/2000\n",
            "75/75 - 0s - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 2.1465 - val_accuracy: 0.7583\n",
            "Epoch 283/2000\n",
            "75/75 - 0s - loss: 9.8703e-05 - accuracy: 1.0000 - val_loss: 2.1401 - val_accuracy: 0.7600\n",
            "Epoch 284/2000\n",
            "75/75 - 0s - loss: 9.6787e-05 - accuracy: 1.0000 - val_loss: 2.1521 - val_accuracy: 0.7583\n",
            "Epoch 285/2000\n",
            "75/75 - 0s - loss: 9.6036e-05 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.7583\n",
            "Epoch 286/2000\n",
            "75/75 - 0s - loss: 9.4606e-05 - accuracy: 1.0000 - val_loss: 2.1510 - val_accuracy: 0.7583\n",
            "Epoch 287/2000\n",
            "75/75 - 0s - loss: 9.2806e-05 - accuracy: 1.0000 - val_loss: 2.1518 - val_accuracy: 0.7583\n",
            "Epoch 288/2000\n",
            "75/75 - 0s - loss: 9.0956e-05 - accuracy: 1.0000 - val_loss: 2.1508 - val_accuracy: 0.7583\n",
            "Epoch 289/2000\n",
            "75/75 - 0s - loss: 9.0290e-05 - accuracy: 1.0000 - val_loss: 2.1513 - val_accuracy: 0.7600\n",
            "Epoch 290/2000\n",
            "75/75 - 0s - loss: 8.5998e-05 - accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.7583\n",
            "Epoch 291/2000\n",
            "75/75 - 0s - loss: 8.9628e-05 - accuracy: 1.0000 - val_loss: 2.1480 - val_accuracy: 0.7567\n",
            "Epoch 292/2000\n",
            "75/75 - 0s - loss: 8.6782e-05 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.7583\n",
            "Epoch 293/2000\n",
            "75/75 - 0s - loss: 8.3678e-05 - accuracy: 1.0000 - val_loss: 2.1508 - val_accuracy: 0.7583\n",
            "Epoch 294/2000\n",
            "75/75 - 0s - loss: 8.4519e-05 - accuracy: 1.0000 - val_loss: 2.1541 - val_accuracy: 0.7567\n",
            "Epoch 295/2000\n",
            "75/75 - 0s - loss: 8.2886e-05 - accuracy: 1.0000 - val_loss: 2.1490 - val_accuracy: 0.7583\n",
            "Epoch 296/2000\n",
            "75/75 - 0s - loss: 8.2538e-05 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.7583\n",
            "Epoch 297/2000\n",
            "75/75 - 0s - loss: 8.0765e-05 - accuracy: 1.0000 - val_loss: 2.1692 - val_accuracy: 0.7583\n",
            "Epoch 298/2000\n",
            "75/75 - 0s - loss: 7.9194e-05 - accuracy: 1.0000 - val_loss: 2.1576 - val_accuracy: 0.7567\n",
            "Epoch 299/2000\n",
            "75/75 - 0s - loss: 7.7793e-05 - accuracy: 1.0000 - val_loss: 2.1556 - val_accuracy: 0.7550\n",
            "Epoch 300/2000\n",
            "75/75 - 0s - loss: 7.4972e-05 - accuracy: 1.0000 - val_loss: 2.1626 - val_accuracy: 0.7567\n",
            "Epoch 301/2000\n",
            "75/75 - 0s - loss: 7.3751e-05 - accuracy: 1.0000 - val_loss: 2.1651 - val_accuracy: 0.7550\n",
            "Epoch 302/2000\n",
            "75/75 - 0s - loss: 7.3490e-05 - accuracy: 1.0000 - val_loss: 2.1719 - val_accuracy: 0.7567\n",
            "Epoch 303/2000\n",
            "75/75 - 0s - loss: 7.2225e-05 - accuracy: 1.0000 - val_loss: 2.1654 - val_accuracy: 0.7550\n",
            "Epoch 304/2000\n",
            "75/75 - 0s - loss: 7.1275e-05 - accuracy: 1.0000 - val_loss: 2.1717 - val_accuracy: 0.7550\n",
            "Epoch 305/2000\n",
            "75/75 - 0s - loss: 7.0607e-05 - accuracy: 1.0000 - val_loss: 2.1774 - val_accuracy: 0.7567\n",
            "Epoch 306/2000\n",
            "75/75 - 0s - loss: 6.9747e-05 - accuracy: 1.0000 - val_loss: 2.1749 - val_accuracy: 0.7550\n",
            "Epoch 307/2000\n",
            "75/75 - 0s - loss: 6.7816e-05 - accuracy: 1.0000 - val_loss: 2.1856 - val_accuracy: 0.7583\n",
            "Epoch 308/2000\n",
            "75/75 - 0s - loss: 6.6330e-05 - accuracy: 1.0000 - val_loss: 2.1805 - val_accuracy: 0.7550\n",
            "Epoch 309/2000\n",
            "75/75 - 0s - loss: 6.6484e-05 - accuracy: 1.0000 - val_loss: 2.1853 - val_accuracy: 0.7567\n",
            "Epoch 310/2000\n",
            "75/75 - 0s - loss: 6.5237e-05 - accuracy: 1.0000 - val_loss: 2.1847 - val_accuracy: 0.7550\n",
            "Epoch 311/2000\n",
            "75/75 - 0s - loss: 6.4129e-05 - accuracy: 1.0000 - val_loss: 2.1952 - val_accuracy: 0.7533\n",
            "Epoch 312/2000\n",
            "75/75 - 0s - loss: 6.1909e-05 - accuracy: 1.0000 - val_loss: 2.1895 - val_accuracy: 0.7533\n",
            "Epoch 313/2000\n",
            "75/75 - 0s - loss: 6.3953e-05 - accuracy: 1.0000 - val_loss: 2.2042 - val_accuracy: 0.7533\n",
            "Epoch 314/2000\n",
            "75/75 - 0s - loss: 6.2395e-05 - accuracy: 1.0000 - val_loss: 2.1998 - val_accuracy: 0.7567\n",
            "Epoch 315/2000\n",
            "75/75 - 0s - loss: 6.2259e-05 - accuracy: 1.0000 - val_loss: 2.2084 - val_accuracy: 0.7567\n",
            "Epoch 316/2000\n",
            "75/75 - 0s - loss: 5.9360e-05 - accuracy: 1.0000 - val_loss: 2.1867 - val_accuracy: 0.7583\n",
            "Epoch 317/2000\n",
            "75/75 - 0s - loss: 5.8294e-05 - accuracy: 1.0000 - val_loss: 2.2051 - val_accuracy: 0.7567\n",
            "Epoch 318/2000\n",
            "75/75 - 0s - loss: 5.8042e-05 - accuracy: 1.0000 - val_loss: 2.2036 - val_accuracy: 0.7533\n",
            "Epoch 319/2000\n",
            "75/75 - 0s - loss: 5.4946e-05 - accuracy: 1.0000 - val_loss: 2.2107 - val_accuracy: 0.7533\n",
            "Epoch 320/2000\n",
            "75/75 - 0s - loss: 5.4764e-05 - accuracy: 1.0000 - val_loss: 2.2190 - val_accuracy: 0.7550\n",
            "Epoch 321/2000\n",
            "75/75 - 0s - loss: 5.2148e-05 - accuracy: 1.0000 - val_loss: 2.2006 - val_accuracy: 0.7550\n",
            "Epoch 322/2000\n",
            "75/75 - 0s - loss: 5.3623e-05 - accuracy: 1.0000 - val_loss: 2.2002 - val_accuracy: 0.7533\n",
            "Epoch 323/2000\n",
            "75/75 - 0s - loss: 5.1722e-05 - accuracy: 1.0000 - val_loss: 2.2115 - val_accuracy: 0.7533\n",
            "Epoch 324/2000\n",
            "75/75 - 0s - loss: 4.9901e-05 - accuracy: 1.0000 - val_loss: 2.2029 - val_accuracy: 0.7533\n",
            "Epoch 325/2000\n",
            "75/75 - 0s - loss: 4.7701e-05 - accuracy: 1.0000 - val_loss: 2.1991 - val_accuracy: 0.7533\n",
            "Epoch 326/2000\n",
            "75/75 - 0s - loss: 4.7920e-05 - accuracy: 1.0000 - val_loss: 2.2083 - val_accuracy: 0.7550\n",
            "Epoch 327/2000\n",
            "75/75 - 0s - loss: 4.6934e-05 - accuracy: 1.0000 - val_loss: 2.2122 - val_accuracy: 0.7550\n",
            "Epoch 328/2000\n",
            "75/75 - 0s - loss: 4.6728e-05 - accuracy: 1.0000 - val_loss: 2.2083 - val_accuracy: 0.7533\n",
            "Epoch 329/2000\n",
            "75/75 - 0s - loss: 4.7764e-05 - accuracy: 1.0000 - val_loss: 2.2305 - val_accuracy: 0.7517\n",
            "Epoch 330/2000\n",
            "75/75 - 0s - loss: 4.4430e-05 - accuracy: 1.0000 - val_loss: 2.2402 - val_accuracy: 0.7533\n",
            "Epoch 331/2000\n",
            "75/75 - 0s - loss: 4.5752e-05 - accuracy: 1.0000 - val_loss: 2.2275 - val_accuracy: 0.7550\n",
            "Epoch 332/2000\n",
            "75/75 - 0s - loss: 4.2919e-05 - accuracy: 1.0000 - val_loss: 2.2206 - val_accuracy: 0.7517\n",
            "Epoch 333/2000\n",
            "75/75 - 0s - loss: 4.2717e-05 - accuracy: 1.0000 - val_loss: 2.2196 - val_accuracy: 0.7533\n",
            "Epoch 334/2000\n",
            "75/75 - 0s - loss: 3.9558e-05 - accuracy: 1.0000 - val_loss: 2.2300 - val_accuracy: 0.7517\n",
            "Epoch 335/2000\n",
            "75/75 - 0s - loss: 3.9337e-05 - accuracy: 1.0000 - val_loss: 2.2220 - val_accuracy: 0.7567\n",
            "Epoch 336/2000\n",
            "75/75 - 0s - loss: 3.9330e-05 - accuracy: 1.0000 - val_loss: 2.2485 - val_accuracy: 0.7517\n",
            "Epoch 337/2000\n",
            "75/75 - 0s - loss: 3.7017e-05 - accuracy: 1.0000 - val_loss: 2.2346 - val_accuracy: 0.7533\n",
            "Epoch 338/2000\n",
            "75/75 - 0s - loss: 3.8094e-05 - accuracy: 1.0000 - val_loss: 2.2373 - val_accuracy: 0.7517\n",
            "Epoch 339/2000\n",
            "75/75 - 0s - loss: 3.5167e-05 - accuracy: 1.0000 - val_loss: 2.2463 - val_accuracy: 0.7517\n",
            "Epoch 340/2000\n",
            "75/75 - 0s - loss: 3.4365e-05 - accuracy: 1.0000 - val_loss: 2.2445 - val_accuracy: 0.7517\n",
            "Epoch 341/2000\n",
            "75/75 - 0s - loss: 3.4180e-05 - accuracy: 1.0000 - val_loss: 2.2598 - val_accuracy: 0.7517\n",
            "Epoch 342/2000\n",
            "75/75 - 0s - loss: 3.4207e-05 - accuracy: 1.0000 - val_loss: 2.2429 - val_accuracy: 0.7517\n",
            "Epoch 343/2000\n",
            "75/75 - 0s - loss: 3.3442e-05 - accuracy: 1.0000 - val_loss: 2.2606 - val_accuracy: 0.7567\n",
            "Epoch 344/2000\n",
            "75/75 - 0s - loss: 3.3636e-05 - accuracy: 1.0000 - val_loss: 2.2469 - val_accuracy: 0.7533\n",
            "Epoch 345/2000\n",
            "75/75 - 0s - loss: 1.5888e-04 - accuracy: 1.0000 - val_loss: 2.4671 - val_accuracy: 0.7467\n",
            "Epoch 346/2000\n",
            "75/75 - 0s - loss: 0.2658 - accuracy: 0.9483 - val_loss: 2.3065 - val_accuracy: 0.7633\n",
            "Epoch 347/2000\n",
            "75/75 - 0s - loss: 0.0520 - accuracy: 0.9867 - val_loss: 2.5343 - val_accuracy: 0.7267\n",
            "Epoch 348/2000\n",
            "75/75 - 0s - loss: 0.0130 - accuracy: 0.9967 - val_loss: 2.3151 - val_accuracy: 0.7500\n",
            "Epoch 349/2000\n",
            "75/75 - 0s - loss: 0.0146 - accuracy: 0.9950 - val_loss: 2.4684 - val_accuracy: 0.7433\n",
            "Epoch 350/2000\n",
            "75/75 - 0s - loss: 0.0028 - accuracy: 0.9992 - val_loss: 2.4051 - val_accuracy: 0.7583\n",
            "Epoch 351/2000\n",
            "75/75 - 0s - loss: 4.7501e-04 - accuracy: 1.0000 - val_loss: 2.3958 - val_accuracy: 0.7550\n",
            "Epoch 352/2000\n",
            "75/75 - 0s - loss: 2.5905e-04 - accuracy: 1.0000 - val_loss: 2.3839 - val_accuracy: 0.7617\n",
            "Epoch 353/2000\n",
            "75/75 - 0s - loss: 2.2818e-04 - accuracy: 1.0000 - val_loss: 2.3828 - val_accuracy: 0.7617\n",
            "Epoch 354/2000\n",
            "75/75 - 0s - loss: 2.0451e-04 - accuracy: 1.0000 - val_loss: 2.3777 - val_accuracy: 0.7633\n",
            "Epoch 355/2000\n",
            "75/75 - 0s - loss: 1.9071e-04 - accuracy: 1.0000 - val_loss: 2.3761 - val_accuracy: 0.7650\n",
            "Epoch 356/2000\n",
            "75/75 - 0s - loss: 1.7667e-04 - accuracy: 1.0000 - val_loss: 2.3754 - val_accuracy: 0.7633\n",
            "Epoch 357/2000\n",
            "75/75 - 0s - loss: 1.6730e-04 - accuracy: 1.0000 - val_loss: 2.3747 - val_accuracy: 0.7633\n",
            "Epoch 358/2000\n",
            "75/75 - 0s - loss: 1.5817e-04 - accuracy: 1.0000 - val_loss: 2.3742 - val_accuracy: 0.7633\n",
            "Epoch 359/2000\n",
            "75/75 - 0s - loss: 1.5040e-04 - accuracy: 1.0000 - val_loss: 2.3728 - val_accuracy: 0.7633\n",
            "Epoch 360/2000\n",
            "75/75 - 0s - loss: 1.4479e-04 - accuracy: 1.0000 - val_loss: 2.3726 - val_accuracy: 0.7633\n",
            "Epoch 361/2000\n",
            "75/75 - 0s - loss: 1.3845e-04 - accuracy: 1.0000 - val_loss: 2.3725 - val_accuracy: 0.7633\n",
            "Epoch 362/2000\n",
            "75/75 - 0s - loss: 1.3259e-04 - accuracy: 1.0000 - val_loss: 2.3724 - val_accuracy: 0.7633\n",
            "Epoch 363/2000\n",
            "75/75 - 0s - loss: 1.2799e-04 - accuracy: 1.0000 - val_loss: 2.3709 - val_accuracy: 0.7633\n",
            "Epoch 364/2000\n",
            "75/75 - 0s - loss: 1.2366e-04 - accuracy: 1.0000 - val_loss: 2.3704 - val_accuracy: 0.7617\n",
            "Epoch 365/2000\n",
            "75/75 - 0s - loss: 1.1946e-04 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.7617\n",
            "Epoch 366/2000\n",
            "75/75 - 0s - loss: 1.1602e-04 - accuracy: 1.0000 - val_loss: 2.3687 - val_accuracy: 0.7600\n",
            "Epoch 367/2000\n",
            "75/75 - 0s - loss: 1.1221e-04 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.7600\n",
            "Epoch 368/2000\n",
            "75/75 - 0s - loss: 1.0917e-04 - accuracy: 1.0000 - val_loss: 2.3698 - val_accuracy: 0.7600\n",
            "Epoch 369/2000\n",
            "75/75 - 0s - loss: 1.0606e-04 - accuracy: 1.0000 - val_loss: 2.3693 - val_accuracy: 0.7600\n",
            "Epoch 370/2000\n",
            "75/75 - 0s - loss: 1.0321e-04 - accuracy: 1.0000 - val_loss: 2.3687 - val_accuracy: 0.7600\n",
            "Epoch 371/2000\n",
            "75/75 - 0s - loss: 1.0006e-04 - accuracy: 1.0000 - val_loss: 2.3677 - val_accuracy: 0.7600\n",
            "Epoch 372/2000\n",
            "75/75 - 0s - loss: 9.7835e-05 - accuracy: 1.0000 - val_loss: 2.3673 - val_accuracy: 0.7617\n",
            "Epoch 373/2000\n",
            "75/75 - 0s - loss: 9.5597e-05 - accuracy: 1.0000 - val_loss: 2.3664 - val_accuracy: 0.7600\n",
            "Epoch 374/2000\n",
            "75/75 - 0s - loss: 9.2578e-05 - accuracy: 1.0000 - val_loss: 2.3665 - val_accuracy: 0.7600\n",
            "Epoch 375/2000\n",
            "75/75 - 0s - loss: 9.0455e-05 - accuracy: 1.0000 - val_loss: 2.3668 - val_accuracy: 0.7600\n",
            "Epoch 376/2000\n",
            "75/75 - 0s - loss: 8.8312e-05 - accuracy: 1.0000 - val_loss: 2.3656 - val_accuracy: 0.7600\n",
            "Epoch 377/2000\n",
            "75/75 - 0s - loss: 8.6241e-05 - accuracy: 1.0000 - val_loss: 2.3667 - val_accuracy: 0.7600\n",
            "Epoch 378/2000\n",
            "75/75 - 0s - loss: 8.4078e-05 - accuracy: 1.0000 - val_loss: 2.3658 - val_accuracy: 0.7617\n",
            "Epoch 379/2000\n",
            "75/75 - 0s - loss: 8.2527e-05 - accuracy: 1.0000 - val_loss: 2.3661 - val_accuracy: 0.7617\n",
            "Epoch 380/2000\n",
            "75/75 - 0s - loss: 8.0377e-05 - accuracy: 1.0000 - val_loss: 2.3650 - val_accuracy: 0.7600\n",
            "Epoch 381/2000\n",
            "75/75 - 0s - loss: 7.8874e-05 - accuracy: 1.0000 - val_loss: 2.3645 - val_accuracy: 0.7617\n",
            "Epoch 382/2000\n",
            "75/75 - 0s - loss: 7.7322e-05 - accuracy: 1.0000 - val_loss: 2.3645 - val_accuracy: 0.7617\n",
            "Epoch 383/2000\n",
            "75/75 - 0s - loss: 7.5415e-05 - accuracy: 1.0000 - val_loss: 2.3650 - val_accuracy: 0.7617\n",
            "Epoch 384/2000\n",
            "75/75 - 0s - loss: 7.3782e-05 - accuracy: 1.0000 - val_loss: 2.3641 - val_accuracy: 0.7600\n",
            "Epoch 385/2000\n",
            "75/75 - 0s - loss: 7.2351e-05 - accuracy: 1.0000 - val_loss: 2.3639 - val_accuracy: 0.7617\n",
            "Epoch 386/2000\n",
            "75/75 - 0s - loss: 7.1430e-05 - accuracy: 1.0000 - val_loss: 2.3620 - val_accuracy: 0.7617\n",
            "Epoch 387/2000\n",
            "75/75 - 0s - loss: 6.9361e-05 - accuracy: 1.0000 - val_loss: 2.3637 - val_accuracy: 0.7617\n",
            "Epoch 388/2000\n",
            "75/75 - 0s - loss: 6.8011e-05 - accuracy: 1.0000 - val_loss: 2.3638 - val_accuracy: 0.7600\n",
            "Epoch 389/2000\n",
            "75/75 - 0s - loss: 6.6488e-05 - accuracy: 1.0000 - val_loss: 2.3637 - val_accuracy: 0.7617\n",
            "Epoch 390/2000\n",
            "75/75 - 0s - loss: 6.5408e-05 - accuracy: 1.0000 - val_loss: 2.3642 - val_accuracy: 0.7583\n",
            "Epoch 391/2000\n",
            "75/75 - 0s - loss: 6.4091e-05 - accuracy: 1.0000 - val_loss: 2.3623 - val_accuracy: 0.7583\n",
            "Epoch 392/2000\n",
            "75/75 - 0s - loss: 6.3124e-05 - accuracy: 1.0000 - val_loss: 2.3638 - val_accuracy: 0.7567\n",
            "Epoch 393/2000\n",
            "75/75 - 0s - loss: 6.1637e-05 - accuracy: 1.0000 - val_loss: 2.3629 - val_accuracy: 0.7583\n",
            "Epoch 394/2000\n",
            "75/75 - 0s - loss: 6.0745e-05 - accuracy: 1.0000 - val_loss: 2.3611 - val_accuracy: 0.7583\n",
            "Epoch 395/2000\n",
            "75/75 - 0s - loss: 5.9411e-05 - accuracy: 1.0000 - val_loss: 2.3637 - val_accuracy: 0.7583\n",
            "Epoch 396/2000\n",
            "75/75 - 0s - loss: 5.8275e-05 - accuracy: 1.0000 - val_loss: 2.3636 - val_accuracy: 0.7550\n",
            "Epoch 397/2000\n",
            "75/75 - 0s - loss: 5.6966e-05 - accuracy: 1.0000 - val_loss: 2.3626 - val_accuracy: 0.7583\n",
            "Epoch 398/2000\n",
            "75/75 - 0s - loss: 5.6290e-05 - accuracy: 1.0000 - val_loss: 2.3633 - val_accuracy: 0.7583\n",
            "Epoch 399/2000\n",
            "75/75 - 0s - loss: 5.4996e-05 - accuracy: 1.0000 - val_loss: 2.3633 - val_accuracy: 0.7583\n",
            "Epoch 400/2000\n",
            "75/75 - 0s - loss: 5.4138e-05 - accuracy: 1.0000 - val_loss: 2.3608 - val_accuracy: 0.7583\n",
            "Epoch 401/2000\n",
            "75/75 - 0s - loss: 5.3148e-05 - accuracy: 1.0000 - val_loss: 2.3623 - val_accuracy: 0.7583\n",
            "Epoch 402/2000\n",
            "75/75 - 0s - loss: 5.2061e-05 - accuracy: 1.0000 - val_loss: 2.3622 - val_accuracy: 0.7600\n",
            "Epoch 403/2000\n",
            "75/75 - 0s - loss: 5.1040e-05 - accuracy: 1.0000 - val_loss: 2.3607 - val_accuracy: 0.7583\n",
            "Epoch 404/2000\n",
            "75/75 - 0s - loss: 5.0485e-05 - accuracy: 1.0000 - val_loss: 2.3624 - val_accuracy: 0.7583\n",
            "Epoch 405/2000\n",
            "75/75 - 0s - loss: 4.9308e-05 - accuracy: 1.0000 - val_loss: 2.3641 - val_accuracy: 0.7567\n",
            "Epoch 406/2000\n",
            "75/75 - 0s - loss: 4.8350e-05 - accuracy: 1.0000 - val_loss: 2.3634 - val_accuracy: 0.7567\n",
            "Epoch 407/2000\n",
            "75/75 - 0s - loss: 4.7756e-05 - accuracy: 1.0000 - val_loss: 2.3640 - val_accuracy: 0.7567\n",
            "Epoch 408/2000\n",
            "75/75 - 0s - loss: 4.6808e-05 - accuracy: 1.0000 - val_loss: 2.3631 - val_accuracy: 0.7567\n",
            "Epoch 409/2000\n",
            "75/75 - 0s - loss: 4.5992e-05 - accuracy: 1.0000 - val_loss: 2.3635 - val_accuracy: 0.7567\n",
            "Epoch 410/2000\n",
            "75/75 - 0s - loss: 4.5196e-05 - accuracy: 1.0000 - val_loss: 2.3628 - val_accuracy: 0.7583\n",
            "Epoch 411/2000\n",
            "75/75 - 0s - loss: 4.4511e-05 - accuracy: 1.0000 - val_loss: 2.3597 - val_accuracy: 0.7600\n",
            "Epoch 412/2000\n",
            "75/75 - 0s - loss: 4.3622e-05 - accuracy: 1.0000 - val_loss: 2.3657 - val_accuracy: 0.7567\n",
            "Epoch 413/2000\n",
            "75/75 - 0s - loss: 4.2966e-05 - accuracy: 1.0000 - val_loss: 2.3635 - val_accuracy: 0.7583\n",
            "Epoch 414/2000\n",
            "75/75 - 0s - loss: 4.2225e-05 - accuracy: 1.0000 - val_loss: 2.3636 - val_accuracy: 0.7583\n",
            "Epoch 415/2000\n",
            "75/75 - 0s - loss: 4.1550e-05 - accuracy: 1.0000 - val_loss: 2.3607 - val_accuracy: 0.7600\n",
            "Epoch 416/2000\n",
            "75/75 - 0s - loss: 4.0723e-05 - accuracy: 1.0000 - val_loss: 2.3656 - val_accuracy: 0.7583\n",
            "Epoch 417/2000\n",
            "75/75 - 0s - loss: 4.0387e-05 - accuracy: 1.0000 - val_loss: 2.3640 - val_accuracy: 0.7600\n",
            "Epoch 418/2000\n",
            "75/75 - 0s - loss: 3.9394e-05 - accuracy: 1.0000 - val_loss: 2.3673 - val_accuracy: 0.7567\n",
            "Epoch 419/2000\n",
            "75/75 - 0s - loss: 3.8746e-05 - accuracy: 1.0000 - val_loss: 2.3612 - val_accuracy: 0.7617\n",
            "Epoch 420/2000\n",
            "75/75 - 0s - loss: 3.8184e-05 - accuracy: 1.0000 - val_loss: 2.3627 - val_accuracy: 0.7600\n",
            "Epoch 421/2000\n",
            "75/75 - 0s - loss: 3.7561e-05 - accuracy: 1.0000 - val_loss: 2.3630 - val_accuracy: 0.7583\n",
            "Epoch 422/2000\n",
            "75/75 - 0s - loss: 3.6946e-05 - accuracy: 1.0000 - val_loss: 2.3662 - val_accuracy: 0.7583\n",
            "Epoch 423/2000\n",
            "75/75 - 0s - loss: 3.6175e-05 - accuracy: 1.0000 - val_loss: 2.3624 - val_accuracy: 0.7583\n",
            "Epoch 424/2000\n",
            "75/75 - 0s - loss: 3.5574e-05 - accuracy: 1.0000 - val_loss: 2.3656 - val_accuracy: 0.7583\n",
            "Epoch 425/2000\n",
            "75/75 - 0s - loss: 3.4901e-05 - accuracy: 1.0000 - val_loss: 2.3648 - val_accuracy: 0.7583\n",
            "Epoch 426/2000\n",
            "75/75 - 0s - loss: 3.4435e-05 - accuracy: 1.0000 - val_loss: 2.3658 - val_accuracy: 0.7583\n",
            "Epoch 427/2000\n",
            "75/75 - 0s - loss: 3.3775e-05 - accuracy: 1.0000 - val_loss: 2.3668 - val_accuracy: 0.7583\n",
            "Epoch 428/2000\n",
            "75/75 - 0s - loss: 3.3121e-05 - accuracy: 1.0000 - val_loss: 2.3632 - val_accuracy: 0.7600\n",
            "Epoch 429/2000\n",
            "75/75 - 0s - loss: 3.2677e-05 - accuracy: 1.0000 - val_loss: 2.3670 - val_accuracy: 0.7600\n",
            "Epoch 430/2000\n",
            "75/75 - 0s - loss: 3.2062e-05 - accuracy: 1.0000 - val_loss: 2.3677 - val_accuracy: 0.7583\n",
            "Epoch 431/2000\n",
            "75/75 - 0s - loss: 3.1877e-05 - accuracy: 1.0000 - val_loss: 2.3664 - val_accuracy: 0.7583\n",
            "Epoch 432/2000\n",
            "75/75 - 0s - loss: 3.1090e-05 - accuracy: 1.0000 - val_loss: 2.3654 - val_accuracy: 0.7583\n",
            "Epoch 433/2000\n",
            "75/75 - 0s - loss: 3.0608e-05 - accuracy: 1.0000 - val_loss: 2.3654 - val_accuracy: 0.7600\n",
            "Epoch 434/2000\n",
            "75/75 - 0s - loss: 3.0168e-05 - accuracy: 1.0000 - val_loss: 2.3688 - val_accuracy: 0.7583\n",
            "Epoch 435/2000\n",
            "75/75 - 0s - loss: 2.9448e-05 - accuracy: 1.0000 - val_loss: 2.3641 - val_accuracy: 0.7583\n",
            "Epoch 436/2000\n",
            "75/75 - 0s - loss: 2.9043e-05 - accuracy: 1.0000 - val_loss: 2.3654 - val_accuracy: 0.7583\n",
            "Epoch 437/2000\n",
            "75/75 - 0s - loss: 2.8703e-05 - accuracy: 1.0000 - val_loss: 2.3637 - val_accuracy: 0.7600\n",
            "Epoch 438/2000\n",
            "75/75 - 0s - loss: 2.8068e-05 - accuracy: 1.0000 - val_loss: 2.3703 - val_accuracy: 0.7567\n",
            "Epoch 439/2000\n",
            "75/75 - 0s - loss: 2.7596e-05 - accuracy: 1.0000 - val_loss: 2.3663 - val_accuracy: 0.7600\n",
            "Epoch 440/2000\n",
            "75/75 - 0s - loss: 2.7163e-05 - accuracy: 1.0000 - val_loss: 2.3671 - val_accuracy: 0.7633\n",
            "Epoch 441/2000\n",
            "75/75 - 0s - loss: 2.6873e-05 - accuracy: 1.0000 - val_loss: 2.3681 - val_accuracy: 0.7600\n",
            "Epoch 442/2000\n",
            "75/75 - 0s - loss: 2.6210e-05 - accuracy: 1.0000 - val_loss: 2.3716 - val_accuracy: 0.7600\n",
            "Epoch 443/2000\n",
            "75/75 - 0s - loss: 2.5864e-05 - accuracy: 1.0000 - val_loss: 2.3715 - val_accuracy: 0.7600\n",
            "Epoch 444/2000\n",
            "75/75 - 0s - loss: 2.5442e-05 - accuracy: 1.0000 - val_loss: 2.3663 - val_accuracy: 0.7633\n",
            "Epoch 445/2000\n",
            "75/75 - 0s - loss: 2.5076e-05 - accuracy: 1.0000 - val_loss: 2.3679 - val_accuracy: 0.7600\n",
            "Epoch 446/2000\n",
            "75/75 - 0s - loss: 2.4616e-05 - accuracy: 1.0000 - val_loss: 2.3692 - val_accuracy: 0.7600\n",
            "Epoch 447/2000\n",
            "75/75 - 0s - loss: 2.4260e-05 - accuracy: 1.0000 - val_loss: 2.3720 - val_accuracy: 0.7600\n",
            "Epoch 448/2000\n",
            "75/75 - 0s - loss: 2.3847e-05 - accuracy: 1.0000 - val_loss: 2.3722 - val_accuracy: 0.7583\n",
            "Epoch 449/2000\n",
            "75/75 - 0s - loss: 2.3267e-05 - accuracy: 1.0000 - val_loss: 2.3698 - val_accuracy: 0.7617\n",
            "Epoch 450/2000\n",
            "75/75 - 0s - loss: 2.3018e-05 - accuracy: 1.0000 - val_loss: 2.3696 - val_accuracy: 0.7617\n",
            "Epoch 451/2000\n",
            "75/75 - 0s - loss: 2.2520e-05 - accuracy: 1.0000 - val_loss: 2.3797 - val_accuracy: 0.7533\n",
            "Epoch 452/2000\n",
            "75/75 - 0s - loss: 2.1944e-05 - accuracy: 1.0000 - val_loss: 2.3705 - val_accuracy: 0.7617\n",
            "Epoch 453/2000\n",
            "75/75 - 0s - loss: 2.2059e-05 - accuracy: 1.0000 - val_loss: 2.3687 - val_accuracy: 0.7600\n",
            "Epoch 454/2000\n",
            "75/75 - 0s - loss: 2.1332e-05 - accuracy: 1.0000 - val_loss: 2.3701 - val_accuracy: 0.7600\n",
            "Epoch 455/2000\n",
            "75/75 - 0s - loss: 2.1244e-05 - accuracy: 1.0000 - val_loss: 2.3741 - val_accuracy: 0.7583\n",
            "Epoch 456/2000\n",
            "75/75 - 0s - loss: 2.0769e-05 - accuracy: 1.0000 - val_loss: 2.3756 - val_accuracy: 0.7583\n",
            "Epoch 457/2000\n",
            "75/75 - 0s - loss: 2.0514e-05 - accuracy: 1.0000 - val_loss: 2.3820 - val_accuracy: 0.7550\n",
            "Epoch 458/2000\n",
            "75/75 - 0s - loss: 2.0271e-05 - accuracy: 1.0000 - val_loss: 2.3772 - val_accuracy: 0.7567\n",
            "Epoch 459/2000\n",
            "75/75 - 0s - loss: 1.9889e-05 - accuracy: 1.0000 - val_loss: 2.3840 - val_accuracy: 0.7550\n",
            "Epoch 460/2000\n",
            "75/75 - 0s - loss: 1.9303e-05 - accuracy: 1.0000 - val_loss: 2.3767 - val_accuracy: 0.7550\n",
            "Epoch 461/2000\n",
            "75/75 - 0s - loss: 1.9026e-05 - accuracy: 1.0000 - val_loss: 2.3797 - val_accuracy: 0.7550\n",
            "Epoch 462/2000\n",
            "75/75 - 0s - loss: 1.8844e-05 - accuracy: 1.0000 - val_loss: 2.3830 - val_accuracy: 0.7550\n",
            "Epoch 463/2000\n",
            "75/75 - 0s - loss: 1.8385e-05 - accuracy: 1.0000 - val_loss: 2.3797 - val_accuracy: 0.7567\n",
            "Epoch 464/2000\n",
            "75/75 - 0s - loss: 1.8132e-05 - accuracy: 1.0000 - val_loss: 2.3899 - val_accuracy: 0.7567\n",
            "Epoch 465/2000\n",
            "75/75 - 0s - loss: 1.7659e-05 - accuracy: 1.0000 - val_loss: 2.3914 - val_accuracy: 0.7567\n",
            "Epoch 466/2000\n",
            "75/75 - 0s - loss: 1.7719e-05 - accuracy: 1.0000 - val_loss: 2.3953 - val_accuracy: 0.7550\n",
            "Epoch 467/2000\n",
            "75/75 - 0s - loss: 1.7109e-05 - accuracy: 1.0000 - val_loss: 2.3870 - val_accuracy: 0.7567\n",
            "Epoch 468/2000\n",
            "75/75 - 0s - loss: 1.6781e-05 - accuracy: 1.0000 - val_loss: 2.3847 - val_accuracy: 0.7533\n",
            "Epoch 469/2000\n",
            "75/75 - 0s - loss: 1.6589e-05 - accuracy: 1.0000 - val_loss: 2.3855 - val_accuracy: 0.7567\n",
            "Epoch 470/2000\n",
            "75/75 - 0s - loss: 1.6127e-05 - accuracy: 1.0000 - val_loss: 2.3880 - val_accuracy: 0.7567\n",
            "Epoch 471/2000\n",
            "75/75 - 0s - loss: 1.6034e-05 - accuracy: 1.0000 - val_loss: 2.3881 - val_accuracy: 0.7567\n",
            "Epoch 472/2000\n",
            "75/75 - 0s - loss: 1.5702e-05 - accuracy: 1.0000 - val_loss: 2.3943 - val_accuracy: 0.7550\n",
            "Epoch 473/2000\n",
            "75/75 - 0s - loss: 1.5501e-05 - accuracy: 1.0000 - val_loss: 2.3898 - val_accuracy: 0.7567\n",
            "Epoch 474/2000\n",
            "75/75 - 0s - loss: 1.5203e-05 - accuracy: 1.0000 - val_loss: 2.3958 - val_accuracy: 0.7583\n",
            "Epoch 475/2000\n",
            "75/75 - 0s - loss: 1.5025e-05 - accuracy: 1.0000 - val_loss: 2.3918 - val_accuracy: 0.7533\n",
            "Epoch 476/2000\n",
            "75/75 - 0s - loss: 1.4756e-05 - accuracy: 1.0000 - val_loss: 2.3992 - val_accuracy: 0.7517\n",
            "Epoch 477/2000\n",
            "75/75 - 0s - loss: 1.4489e-05 - accuracy: 1.0000 - val_loss: 2.4059 - val_accuracy: 0.7550\n",
            "Epoch 478/2000\n",
            "75/75 - 0s - loss: 1.4468e-05 - accuracy: 1.0000 - val_loss: 2.3981 - val_accuracy: 0.7550\n",
            "Epoch 479/2000\n",
            "75/75 - 0s - loss: 1.4065e-05 - accuracy: 1.0000 - val_loss: 2.3998 - val_accuracy: 0.7567\n",
            "Epoch 480/2000\n",
            "75/75 - 0s - loss: 1.3900e-05 - accuracy: 1.0000 - val_loss: 2.3960 - val_accuracy: 0.7533\n",
            "Epoch 481/2000\n",
            "75/75 - 0s - loss: 1.3796e-05 - accuracy: 1.0000 - val_loss: 2.3990 - val_accuracy: 0.7550\n",
            "Epoch 482/2000\n",
            "75/75 - 0s - loss: 1.3352e-05 - accuracy: 1.0000 - val_loss: 2.4024 - val_accuracy: 0.7550\n",
            "Epoch 483/2000\n",
            "75/75 - 0s - loss: 1.2997e-05 - accuracy: 1.0000 - val_loss: 2.4113 - val_accuracy: 0.7550\n",
            "Epoch 484/2000\n",
            "75/75 - 0s - loss: 1.2612e-05 - accuracy: 1.0000 - val_loss: 2.4071 - val_accuracy: 0.7567\n",
            "Epoch 485/2000\n",
            "75/75 - 0s - loss: 1.2519e-05 - accuracy: 1.0000 - val_loss: 2.4038 - val_accuracy: 0.7550\n",
            "Epoch 486/2000\n",
            "75/75 - 0s - loss: 1.2549e-05 - accuracy: 1.0000 - val_loss: 2.4051 - val_accuracy: 0.7550\n",
            "Epoch 487/2000\n",
            "75/75 - 0s - loss: 1.2287e-05 - accuracy: 1.0000 - val_loss: 2.4113 - val_accuracy: 0.7533\n",
            "Epoch 488/2000\n",
            "75/75 - 0s - loss: 1.1826e-05 - accuracy: 1.0000 - val_loss: 2.4045 - val_accuracy: 0.7567\n",
            "Epoch 489/2000\n",
            "75/75 - 0s - loss: 1.1867e-05 - accuracy: 1.0000 - val_loss: 2.4060 - val_accuracy: 0.7500\n",
            "Epoch 490/2000\n",
            "75/75 - 0s - loss: 1.1423e-05 - accuracy: 1.0000 - val_loss: 2.4144 - val_accuracy: 0.7550\n",
            "Epoch 491/2000\n",
            "75/75 - 0s - loss: 1.1544e-05 - accuracy: 1.0000 - val_loss: 2.4169 - val_accuracy: 0.7517\n",
            "Epoch 492/2000\n",
            "75/75 - 0s - loss: 1.1126e-05 - accuracy: 1.0000 - val_loss: 2.4083 - val_accuracy: 0.7567\n",
            "Epoch 493/2000\n",
            "75/75 - 0s - loss: 1.0805e-05 - accuracy: 1.0000 - val_loss: 2.4220 - val_accuracy: 0.7567\n",
            "Epoch 494/2000\n",
            "75/75 - 0s - loss: 1.0868e-05 - accuracy: 1.0000 - val_loss: 2.4235 - val_accuracy: 0.7533\n",
            "Epoch 495/2000\n",
            "75/75 - 0s - loss: 1.0438e-05 - accuracy: 1.0000 - val_loss: 2.4248 - val_accuracy: 0.7517\n",
            "Epoch 496/2000\n",
            "75/75 - 0s - loss: 1.0418e-05 - accuracy: 1.0000 - val_loss: 2.4311 - val_accuracy: 0.7533\n",
            "Epoch 497/2000\n",
            "75/75 - 0s - loss: 9.9612e-06 - accuracy: 1.0000 - val_loss: 2.4126 - val_accuracy: 0.7583\n",
            "Epoch 498/2000\n",
            "75/75 - 0s - loss: 9.9216e-06 - accuracy: 1.0000 - val_loss: 2.4290 - val_accuracy: 0.7550\n",
            "Epoch 499/2000\n",
            "75/75 - 0s - loss: 9.8451e-06 - accuracy: 1.0000 - val_loss: 2.4302 - val_accuracy: 0.7567\n",
            "Epoch 500/2000\n",
            "75/75 - 0s - loss: 9.5366e-06 - accuracy: 1.0000 - val_loss: 2.4370 - val_accuracy: 0.7483\n",
            "Epoch 501/2000\n",
            "75/75 - 0s - loss: 9.3929e-06 - accuracy: 1.0000 - val_loss: 2.4455 - val_accuracy: 0.7500\n",
            "Epoch 502/2000\n",
            "75/75 - 0s - loss: 9.3433e-06 - accuracy: 1.0000 - val_loss: 2.4239 - val_accuracy: 0.7500\n",
            "Epoch 503/2000\n",
            "75/75 - 0s - loss: 9.1196e-06 - accuracy: 1.0000 - val_loss: 2.4416 - val_accuracy: 0.7533\n",
            "Epoch 504/2000\n",
            "75/75 - 0s - loss: 8.9334e-06 - accuracy: 1.0000 - val_loss: 2.4357 - val_accuracy: 0.7500\n",
            "Epoch 505/2000\n",
            "75/75 - 0s - loss: 8.8273e-06 - accuracy: 1.0000 - val_loss: 2.4516 - val_accuracy: 0.7517\n",
            "Epoch 506/2000\n",
            "75/75 - 0s - loss: 8.3273e-06 - accuracy: 1.0000 - val_loss: 2.4237 - val_accuracy: 0.7583\n",
            "Epoch 507/2000\n",
            "75/75 - 0s - loss: 8.4839e-06 - accuracy: 1.0000 - val_loss: 2.4560 - val_accuracy: 0.7500\n",
            "Epoch 508/2000\n",
            "75/75 - 0s - loss: 8.0007e-06 - accuracy: 1.0000 - val_loss: 2.4526 - val_accuracy: 0.7533\n",
            "Epoch 509/2000\n",
            "75/75 - 0s - loss: 8.0004e-06 - accuracy: 1.0000 - val_loss: 2.4563 - val_accuracy: 0.7500\n",
            "Epoch 510/2000\n",
            "75/75 - 0s - loss: 7.8638e-06 - accuracy: 1.0000 - val_loss: 2.4405 - val_accuracy: 0.7583\n",
            "Epoch 511/2000\n",
            "75/75 - 0s - loss: 8.0998e-06 - accuracy: 1.0000 - val_loss: 2.4614 - val_accuracy: 0.7517\n",
            "Epoch 512/2000\n",
            "75/75 - 0s - loss: 7.6313e-06 - accuracy: 1.0000 - val_loss: 2.4488 - val_accuracy: 0.7533\n",
            "Epoch 513/2000\n",
            "75/75 - 0s - loss: 7.3565e-06 - accuracy: 1.0000 - val_loss: 2.4547 - val_accuracy: 0.7517\n",
            "Epoch 514/2000\n",
            "75/75 - 0s - loss: 7.1438e-06 - accuracy: 1.0000 - val_loss: 2.4601 - val_accuracy: 0.7483\n",
            "Epoch 515/2000\n",
            "75/75 - 0s - loss: 7.3016e-06 - accuracy: 1.0000 - val_loss: 2.4669 - val_accuracy: 0.7500\n",
            "Epoch 516/2000\n",
            "75/75 - 0s - loss: 7.2582e-06 - accuracy: 1.0000 - val_loss: 2.4655 - val_accuracy: 0.7567\n",
            "Epoch 517/2000\n",
            "75/75 - 0s - loss: 7.0437e-06 - accuracy: 1.0000 - val_loss: 2.4792 - val_accuracy: 0.7483\n",
            "Epoch 518/2000\n",
            "75/75 - 0s - loss: 7.8446e-06 - accuracy: 1.0000 - val_loss: 2.4575 - val_accuracy: 0.7500\n",
            "Epoch 519/2000\n",
            "75/75 - 0s - loss: 6.7693e-06 - accuracy: 1.0000 - val_loss: 2.4624 - val_accuracy: 0.7533\n",
            "Epoch 520/2000\n",
            "75/75 - 0s - loss: 6.4042e-06 - accuracy: 1.0000 - val_loss: 2.4628 - val_accuracy: 0.7533\n",
            "Epoch 521/2000\n",
            "75/75 - 0s - loss: 6.1649e-06 - accuracy: 1.0000 - val_loss: 2.4842 - val_accuracy: 0.7483\n",
            "Epoch 522/2000\n",
            "75/75 - 0s - loss: 5.8669e-06 - accuracy: 1.0000 - val_loss: 2.4832 - val_accuracy: 0.7550\n",
            "Epoch 523/2000\n",
            "75/75 - 0s - loss: 6.0701e-06 - accuracy: 1.0000 - val_loss: 2.4783 - val_accuracy: 0.7567\n",
            "Epoch 524/2000\n",
            "75/75 - 0s - loss: 5.8083e-06 - accuracy: 1.0000 - val_loss: 2.4632 - val_accuracy: 0.7583\n",
            "Epoch 525/2000\n",
            "75/75 - 0s - loss: 5.8189e-06 - accuracy: 1.0000 - val_loss: 2.4829 - val_accuracy: 0.7533\n",
            "Epoch 526/2000\n",
            "75/75 - 0s - loss: 5.7014e-06 - accuracy: 1.0000 - val_loss: 2.4836 - val_accuracy: 0.7517\n",
            "Epoch 527/2000\n",
            "75/75 - 0s - loss: 5.2822e-06 - accuracy: 1.0000 - val_loss: 2.4655 - val_accuracy: 0.7533\n",
            "Epoch 528/2000\n",
            "75/75 - 0s - loss: 5.2995e-06 - accuracy: 1.0000 - val_loss: 2.4970 - val_accuracy: 0.7500\n",
            "Epoch 529/2000\n",
            "75/75 - 0s - loss: 5.4673e-06 - accuracy: 1.0000 - val_loss: 2.4928 - val_accuracy: 0.7500\n",
            "Epoch 530/2000\n",
            "75/75 - 0s - loss: 5.2090e-06 - accuracy: 1.0000 - val_loss: 2.5160 - val_accuracy: 0.7500\n",
            "Epoch 531/2000\n",
            "75/75 - 0s - loss: 4.9588e-06 - accuracy: 1.0000 - val_loss: 2.5069 - val_accuracy: 0.7517\n",
            "Epoch 532/2000\n",
            "75/75 - 0s - loss: 4.8705e-06 - accuracy: 1.0000 - val_loss: 2.4837 - val_accuracy: 0.7500\n",
            "Epoch 533/2000\n",
            "75/75 - 0s - loss: 5.1094e-06 - accuracy: 1.0000 - val_loss: 2.5266 - val_accuracy: 0.7500\n",
            "Epoch 534/2000\n",
            "75/75 - 0s - loss: 4.7525e-06 - accuracy: 1.0000 - val_loss: 2.5043 - val_accuracy: 0.7533\n",
            "Epoch 535/2000\n",
            "75/75 - 0s - loss: 4.4153e-06 - accuracy: 1.0000 - val_loss: 2.5011 - val_accuracy: 0.7533\n",
            "Epoch 536/2000\n",
            "75/75 - 0s - loss: 4.8446e-06 - accuracy: 1.0000 - val_loss: 2.4996 - val_accuracy: 0.7533\n",
            "Epoch 537/2000\n",
            "75/75 - 0s - loss: 4.4248e-06 - accuracy: 1.0000 - val_loss: 2.5054 - val_accuracy: 0.7533\n",
            "Epoch 538/2000\n",
            "75/75 - 0s - loss: 4.1663e-06 - accuracy: 1.0000 - val_loss: 2.5101 - val_accuracy: 0.7517\n",
            "Epoch 539/2000\n",
            "75/75 - 0s - loss: 4.3621e-06 - accuracy: 1.0000 - val_loss: 2.4997 - val_accuracy: 0.7550\n",
            "Epoch 540/2000\n",
            "75/75 - 0s - loss: 4.1603e-06 - accuracy: 1.0000 - val_loss: 2.4892 - val_accuracy: 0.7583\n",
            "Epoch 541/2000\n",
            "75/75 - 0s - loss: 4.7841e-06 - accuracy: 1.0000 - val_loss: 2.4928 - val_accuracy: 0.7533\n",
            "Epoch 542/2000\n",
            "75/75 - 0s - loss: 0.0311 - accuracy: 0.9929 - val_loss: 2.5928 - val_accuracy: 0.7483\n",
            "Epoch 543/2000\n",
            "75/75 - 0s - loss: 0.1085 - accuracy: 0.9775 - val_loss: 2.5438 - val_accuracy: 0.7567\n",
            "Epoch 544/2000\n",
            "75/75 - 0s - loss: 0.0245 - accuracy: 0.9925 - val_loss: 2.4968 - val_accuracy: 0.7633\n",
            "Epoch 545/2000\n",
            "75/75 - 0s - loss: 0.0162 - accuracy: 0.9946 - val_loss: 2.5739 - val_accuracy: 0.7567\n",
            "Epoch 546/2000\n",
            "75/75 - 0s - loss: 0.0045 - accuracy: 0.9987 - val_loss: 2.4854 - val_accuracy: 0.7583\n",
            "Epoch 547/2000\n",
            "75/75 - 0s - loss: 0.0025 - accuracy: 0.9987 - val_loss: 2.5171 - val_accuracy: 0.7600\n",
            "Epoch 548/2000\n",
            "75/75 - 0s - loss: 5.9852e-04 - accuracy: 1.0000 - val_loss: 2.5572 - val_accuracy: 0.7467\n",
            "Epoch 549/2000\n",
            "75/75 - 0s - loss: 6.8610e-05 - accuracy: 1.0000 - val_loss: 2.5603 - val_accuracy: 0.7517\n",
            "Epoch 550/2000\n",
            "75/75 - 0s - loss: 5.4114e-05 - accuracy: 1.0000 - val_loss: 2.5593 - val_accuracy: 0.7517\n",
            "Epoch 551/2000\n",
            "75/75 - 0s - loss: 4.9228e-05 - accuracy: 1.0000 - val_loss: 2.5592 - val_accuracy: 0.7517\n",
            "Epoch 552/2000\n",
            "75/75 - 0s - loss: 4.6011e-05 - accuracy: 1.0000 - val_loss: 2.5581 - val_accuracy: 0.7517\n",
            "Epoch 553/2000\n",
            "75/75 - 0s - loss: 4.3166e-05 - accuracy: 1.0000 - val_loss: 2.5571 - val_accuracy: 0.7517\n",
            "Epoch 554/2000\n",
            "75/75 - 0s - loss: 4.0863e-05 - accuracy: 1.0000 - val_loss: 2.5555 - val_accuracy: 0.7517\n",
            "Epoch 555/2000\n",
            "75/75 - 0s - loss: 3.8906e-05 - accuracy: 1.0000 - val_loss: 2.5552 - val_accuracy: 0.7517\n",
            "Epoch 556/2000\n",
            "75/75 - 0s - loss: 3.7230e-05 - accuracy: 1.0000 - val_loss: 2.5546 - val_accuracy: 0.7517\n",
            "Epoch 557/2000\n",
            "75/75 - 0s - loss: 3.5744e-05 - accuracy: 1.0000 - val_loss: 2.5532 - val_accuracy: 0.7517\n",
            "Epoch 558/2000\n",
            "75/75 - 0s - loss: 3.4387e-05 - accuracy: 1.0000 - val_loss: 2.5527 - val_accuracy: 0.7517\n",
            "Epoch 559/2000\n",
            "75/75 - 0s - loss: 3.3238e-05 - accuracy: 1.0000 - val_loss: 2.5521 - val_accuracy: 0.7517\n",
            "Epoch 560/2000\n",
            "75/75 - 0s - loss: 3.2081e-05 - accuracy: 1.0000 - val_loss: 2.5505 - val_accuracy: 0.7517\n",
            "Epoch 561/2000\n",
            "75/75 - 0s - loss: 3.1023e-05 - accuracy: 1.0000 - val_loss: 2.5498 - val_accuracy: 0.7517\n",
            "Epoch 562/2000\n",
            "75/75 - 0s - loss: 3.0087e-05 - accuracy: 1.0000 - val_loss: 2.5491 - val_accuracy: 0.7500\n",
            "Epoch 563/2000\n",
            "75/75 - 0s - loss: 2.9222e-05 - accuracy: 1.0000 - val_loss: 2.5481 - val_accuracy: 0.7500\n",
            "Epoch 564/2000\n",
            "75/75 - 0s - loss: 2.8408e-05 - accuracy: 1.0000 - val_loss: 2.5466 - val_accuracy: 0.7500\n",
            "Epoch 565/2000\n",
            "75/75 - 0s - loss: 2.7597e-05 - accuracy: 1.0000 - val_loss: 2.5458 - val_accuracy: 0.7500\n",
            "Epoch 566/2000\n",
            "75/75 - 0s - loss: 2.6882e-05 - accuracy: 1.0000 - val_loss: 2.5454 - val_accuracy: 0.7500\n",
            "Epoch 567/2000\n",
            "75/75 - 0s - loss: 2.6216e-05 - accuracy: 1.0000 - val_loss: 2.5449 - val_accuracy: 0.7500\n",
            "Epoch 568/2000\n",
            "75/75 - 0s - loss: 2.5566e-05 - accuracy: 1.0000 - val_loss: 2.5442 - val_accuracy: 0.7500\n",
            "Epoch 569/2000\n",
            "75/75 - 0s - loss: 2.4923e-05 - accuracy: 1.0000 - val_loss: 2.5433 - val_accuracy: 0.7500\n",
            "Epoch 570/2000\n",
            "75/75 - 0s - loss: 2.4329e-05 - accuracy: 1.0000 - val_loss: 2.5430 - val_accuracy: 0.7517\n",
            "Epoch 571/2000\n",
            "75/75 - 0s - loss: 2.3759e-05 - accuracy: 1.0000 - val_loss: 2.5418 - val_accuracy: 0.7517\n",
            "Epoch 572/2000\n",
            "75/75 - 0s - loss: 2.3211e-05 - accuracy: 1.0000 - val_loss: 2.5412 - val_accuracy: 0.7517\n",
            "Epoch 573/2000\n",
            "75/75 - 0s - loss: 2.2705e-05 - accuracy: 1.0000 - val_loss: 2.5411 - val_accuracy: 0.7517\n",
            "Epoch 574/2000\n",
            "75/75 - 0s - loss: 2.2227e-05 - accuracy: 1.0000 - val_loss: 2.5403 - val_accuracy: 0.7517\n",
            "Epoch 575/2000\n",
            "75/75 - 0s - loss: 2.1749e-05 - accuracy: 1.0000 - val_loss: 2.5397 - val_accuracy: 0.7517\n",
            "Epoch 576/2000\n",
            "75/75 - 0s - loss: 2.1297e-05 - accuracy: 1.0000 - val_loss: 2.5391 - val_accuracy: 0.7517\n",
            "Epoch 577/2000\n",
            "75/75 - 0s - loss: 2.0856e-05 - accuracy: 1.0000 - val_loss: 2.5389 - val_accuracy: 0.7517\n",
            "Epoch 578/2000\n",
            "75/75 - 0s - loss: 2.0440e-05 - accuracy: 1.0000 - val_loss: 2.5377 - val_accuracy: 0.7517\n",
            "Epoch 579/2000\n",
            "75/75 - 0s - loss: 2.0004e-05 - accuracy: 1.0000 - val_loss: 2.5383 - val_accuracy: 0.7517\n",
            "Epoch 580/2000\n",
            "75/75 - 0s - loss: 1.9624e-05 - accuracy: 1.0000 - val_loss: 2.5364 - val_accuracy: 0.7517\n",
            "Epoch 581/2000\n",
            "75/75 - 0s - loss: 1.9256e-05 - accuracy: 1.0000 - val_loss: 2.5373 - val_accuracy: 0.7517\n",
            "Epoch 582/2000\n",
            "75/75 - 0s - loss: 1.8834e-05 - accuracy: 1.0000 - val_loss: 2.5368 - val_accuracy: 0.7517\n",
            "Epoch 583/2000\n",
            "75/75 - 0s - loss: 1.8477e-05 - accuracy: 1.0000 - val_loss: 2.5366 - val_accuracy: 0.7517\n",
            "Epoch 584/2000\n",
            "75/75 - 0s - loss: 1.8126e-05 - accuracy: 1.0000 - val_loss: 2.5357 - val_accuracy: 0.7517\n",
            "Epoch 585/2000\n",
            "75/75 - 0s - loss: 1.7777e-05 - accuracy: 1.0000 - val_loss: 2.5351 - val_accuracy: 0.7517\n",
            "Epoch 586/2000\n",
            "75/75 - 0s - loss: 1.7426e-05 - accuracy: 1.0000 - val_loss: 2.5354 - val_accuracy: 0.7517\n",
            "Epoch 587/2000\n",
            "75/75 - 0s - loss: 1.7155e-05 - accuracy: 1.0000 - val_loss: 2.5351 - val_accuracy: 0.7517\n",
            "Epoch 588/2000\n",
            "75/75 - 0s - loss: 1.6802e-05 - accuracy: 1.0000 - val_loss: 2.5345 - val_accuracy: 0.7517\n",
            "Epoch 589/2000\n",
            "75/75 - 0s - loss: 1.6504e-05 - accuracy: 1.0000 - val_loss: 2.5336 - val_accuracy: 0.7517\n",
            "Epoch 590/2000\n",
            "75/75 - 0s - loss: 1.6192e-05 - accuracy: 1.0000 - val_loss: 2.5337 - val_accuracy: 0.7533\n",
            "Epoch 591/2000\n",
            "75/75 - 0s - loss: 1.5864e-05 - accuracy: 1.0000 - val_loss: 2.5335 - val_accuracy: 0.7517\n",
            "Epoch 592/2000\n",
            "75/75 - 0s - loss: 1.5601e-05 - accuracy: 1.0000 - val_loss: 2.5319 - val_accuracy: 0.7500\n",
            "Epoch 593/2000\n",
            "75/75 - 0s - loss: 1.5333e-05 - accuracy: 1.0000 - val_loss: 2.5323 - val_accuracy: 0.7500\n",
            "Epoch 594/2000\n",
            "75/75 - 0s - loss: 1.5036e-05 - accuracy: 1.0000 - val_loss: 2.5334 - val_accuracy: 0.7500\n",
            "Epoch 595/2000\n",
            "75/75 - 0s - loss: 1.4777e-05 - accuracy: 1.0000 - val_loss: 2.5325 - val_accuracy: 0.7500\n",
            "Epoch 596/2000\n",
            "75/75 - 0s - loss: 1.4498e-05 - accuracy: 1.0000 - val_loss: 2.5320 - val_accuracy: 0.7500\n",
            "Epoch 597/2000\n",
            "75/75 - 0s - loss: 1.4300e-05 - accuracy: 1.0000 - val_loss: 2.5311 - val_accuracy: 0.7500\n",
            "Epoch 598/2000\n",
            "75/75 - 0s - loss: 1.4008e-05 - accuracy: 1.0000 - val_loss: 2.5305 - val_accuracy: 0.7500\n",
            "Epoch 599/2000\n",
            "75/75 - 0s - loss: 1.3755e-05 - accuracy: 1.0000 - val_loss: 2.5313 - val_accuracy: 0.7500\n",
            "Epoch 600/2000\n",
            "75/75 - 0s - loss: 1.3508e-05 - accuracy: 1.0000 - val_loss: 2.5306 - val_accuracy: 0.7500\n",
            "Epoch 601/2000\n",
            "75/75 - 0s - loss: 1.3282e-05 - accuracy: 1.0000 - val_loss: 2.5300 - val_accuracy: 0.7500\n",
            "Epoch 602/2000\n",
            "75/75 - 0s - loss: 1.3079e-05 - accuracy: 1.0000 - val_loss: 2.5296 - val_accuracy: 0.7500\n",
            "Epoch 603/2000\n",
            "75/75 - 0s - loss: 1.2828e-05 - accuracy: 1.0000 - val_loss: 2.5297 - val_accuracy: 0.7500\n",
            "Epoch 604/2000\n",
            "75/75 - 0s - loss: 1.2586e-05 - accuracy: 1.0000 - val_loss: 2.5287 - val_accuracy: 0.7500\n",
            "Epoch 605/2000\n",
            "75/75 - 0s - loss: 1.2400e-05 - accuracy: 1.0000 - val_loss: 2.5283 - val_accuracy: 0.7500\n",
            "Epoch 606/2000\n",
            "75/75 - 0s - loss: 1.2169e-05 - accuracy: 1.0000 - val_loss: 2.5275 - val_accuracy: 0.7500\n",
            "Epoch 607/2000\n",
            "75/75 - 0s - loss: 1.1970e-05 - accuracy: 1.0000 - val_loss: 2.5275 - val_accuracy: 0.7500\n",
            "Epoch 608/2000\n",
            "75/75 - 0s - loss: 1.1803e-05 - accuracy: 1.0000 - val_loss: 2.5275 - val_accuracy: 0.7500\n",
            "Epoch 609/2000\n",
            "75/75 - 0s - loss: 1.1562e-05 - accuracy: 1.0000 - val_loss: 2.5280 - val_accuracy: 0.7517\n",
            "Epoch 610/2000\n",
            "75/75 - 0s - loss: 1.1366e-05 - accuracy: 1.0000 - val_loss: 2.5262 - val_accuracy: 0.7533\n",
            "Epoch 611/2000\n",
            "75/75 - 0s - loss: 1.1162e-05 - accuracy: 1.0000 - val_loss: 2.5277 - val_accuracy: 0.7517\n",
            "Epoch 612/2000\n",
            "75/75 - 0s - loss: 1.1010e-05 - accuracy: 1.0000 - val_loss: 2.5277 - val_accuracy: 0.7517\n",
            "Epoch 613/2000\n",
            "75/75 - 0s - loss: 1.0831e-05 - accuracy: 1.0000 - val_loss: 2.5275 - val_accuracy: 0.7517\n",
            "Epoch 614/2000\n",
            "75/75 - 0s - loss: 1.0614e-05 - accuracy: 1.0000 - val_loss: 2.5261 - val_accuracy: 0.7517\n",
            "Epoch 615/2000\n",
            "75/75 - 0s - loss: 1.0445e-05 - accuracy: 1.0000 - val_loss: 2.5265 - val_accuracy: 0.7517\n",
            "Epoch 616/2000\n",
            "75/75 - 0s - loss: 1.0301e-05 - accuracy: 1.0000 - val_loss: 2.5258 - val_accuracy: 0.7533\n",
            "Epoch 617/2000\n",
            "75/75 - 0s - loss: 1.0110e-05 - accuracy: 1.0000 - val_loss: 2.5255 - val_accuracy: 0.7533\n",
            "Epoch 618/2000\n",
            "75/75 - 0s - loss: 9.9383e-06 - accuracy: 1.0000 - val_loss: 2.5256 - val_accuracy: 0.7533\n",
            "Epoch 619/2000\n",
            "75/75 - 0s - loss: 9.7771e-06 - accuracy: 1.0000 - val_loss: 2.5265 - val_accuracy: 0.7533\n",
            "Epoch 620/2000\n",
            "75/75 - 0s - loss: 9.6064e-06 - accuracy: 1.0000 - val_loss: 2.5251 - val_accuracy: 0.7533\n",
            "Epoch 621/2000\n",
            "75/75 - 0s - loss: 9.4660e-06 - accuracy: 1.0000 - val_loss: 2.5251 - val_accuracy: 0.7533\n",
            "Epoch 622/2000\n",
            "75/75 - 0s - loss: 9.3265e-06 - accuracy: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.7533\n",
            "Epoch 623/2000\n",
            "75/75 - 0s - loss: 9.1520e-06 - accuracy: 1.0000 - val_loss: 2.5249 - val_accuracy: 0.7533\n",
            "Epoch 624/2000\n",
            "75/75 - 0s - loss: 8.9951e-06 - accuracy: 1.0000 - val_loss: 2.5256 - val_accuracy: 0.7533\n",
            "Epoch 625/2000\n",
            "75/75 - 0s - loss: 8.8565e-06 - accuracy: 1.0000 - val_loss: 2.5253 - val_accuracy: 0.7533\n",
            "Epoch 626/2000\n",
            "75/75 - 0s - loss: 8.7061e-06 - accuracy: 1.0000 - val_loss: 2.5253 - val_accuracy: 0.7533\n",
            "Epoch 627/2000\n",
            "75/75 - 0s - loss: 8.5744e-06 - accuracy: 1.0000 - val_loss: 2.5251 - val_accuracy: 0.7533\n",
            "Epoch 628/2000\n",
            "75/75 - 0s - loss: 8.4381e-06 - accuracy: 1.0000 - val_loss: 2.5251 - val_accuracy: 0.7533\n",
            "Epoch 629/2000\n",
            "75/75 - 0s - loss: 8.3104e-06 - accuracy: 1.0000 - val_loss: 2.5245 - val_accuracy: 0.7533\n",
            "Epoch 630/2000\n",
            "75/75 - 0s - loss: 8.1654e-06 - accuracy: 1.0000 - val_loss: 2.5245 - val_accuracy: 0.7533\n",
            "Epoch 631/2000\n",
            "75/75 - 0s - loss: 8.0345e-06 - accuracy: 1.0000 - val_loss: 2.5237 - val_accuracy: 0.7533\n",
            "Epoch 632/2000\n",
            "75/75 - 0s - loss: 7.9320e-06 - accuracy: 1.0000 - val_loss: 2.5246 - val_accuracy: 0.7533\n",
            "Epoch 633/2000\n",
            "75/75 - 0s - loss: 7.8141e-06 - accuracy: 1.0000 - val_loss: 2.5246 - val_accuracy: 0.7533\n",
            "Epoch 634/2000\n",
            "75/75 - 0s - loss: 7.6851e-06 - accuracy: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.7533\n",
            "Epoch 635/2000\n",
            "75/75 - 0s - loss: 7.6061e-06 - accuracy: 1.0000 - val_loss: 2.5252 - val_accuracy: 0.7550\n",
            "Epoch 636/2000\n",
            "75/75 - 0s - loss: 7.4681e-06 - accuracy: 1.0000 - val_loss: 2.5246 - val_accuracy: 0.7550\n",
            "Epoch 637/2000\n",
            "75/75 - 0s - loss: 7.3308e-06 - accuracy: 1.0000 - val_loss: 2.5242 - val_accuracy: 0.7550\n",
            "Epoch 638/2000\n",
            "75/75 - 0s - loss: 7.1824e-06 - accuracy: 1.0000 - val_loss: 2.5246 - val_accuracy: 0.7550\n",
            "Epoch 639/2000\n",
            "75/75 - 0s - loss: 7.1018e-06 - accuracy: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.7567\n",
            "Epoch 640/2000\n",
            "75/75 - 0s - loss: 6.9906e-06 - accuracy: 1.0000 - val_loss: 2.5248 - val_accuracy: 0.7550\n",
            "Epoch 641/2000\n",
            "75/75 - 0s - loss: 6.8679e-06 - accuracy: 1.0000 - val_loss: 2.5241 - val_accuracy: 0.7567\n",
            "Epoch 642/2000\n",
            "75/75 - 0s - loss: 6.7693e-06 - accuracy: 1.0000 - val_loss: 2.5249 - val_accuracy: 0.7567\n",
            "Epoch 643/2000\n",
            "75/75 - 0s - loss: 6.7177e-06 - accuracy: 1.0000 - val_loss: 2.5239 - val_accuracy: 0.7550\n",
            "Epoch 644/2000\n",
            "75/75 - 0s - loss: 6.5693e-06 - accuracy: 1.0000 - val_loss: 2.5251 - val_accuracy: 0.7550\n",
            "Epoch 645/2000\n",
            "75/75 - 0s - loss: 6.4991e-06 - accuracy: 1.0000 - val_loss: 2.5274 - val_accuracy: 0.7533\n",
            "Epoch 646/2000\n",
            "75/75 - 0s - loss: 6.3772e-06 - accuracy: 1.0000 - val_loss: 2.5254 - val_accuracy: 0.7550\n",
            "Epoch 647/2000\n",
            "75/75 - 0s - loss: 6.2759e-06 - accuracy: 1.0000 - val_loss: 2.5238 - val_accuracy: 0.7550\n",
            "Epoch 648/2000\n",
            "75/75 - 0s - loss: 6.1979e-06 - accuracy: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.7533\n",
            "Epoch 649/2000\n",
            "75/75 - 0s - loss: 6.0932e-06 - accuracy: 1.0000 - val_loss: 2.5263 - val_accuracy: 0.7533\n",
            "Epoch 650/2000\n",
            "75/75 - 0s - loss: 5.9879e-06 - accuracy: 1.0000 - val_loss: 2.5277 - val_accuracy: 0.7533\n",
            "Epoch 651/2000\n",
            "75/75 - 0s - loss: 5.9092e-06 - accuracy: 1.0000 - val_loss: 2.5272 - val_accuracy: 0.7533\n",
            "Epoch 652/2000\n",
            "75/75 - 0s - loss: 5.8110e-06 - accuracy: 1.0000 - val_loss: 2.5250 - val_accuracy: 0.7533\n",
            "Epoch 653/2000\n",
            "75/75 - 0s - loss: 5.7477e-06 - accuracy: 1.0000 - val_loss: 2.5251 - val_accuracy: 0.7533\n",
            "Epoch 654/2000\n",
            "75/75 - 0s - loss: 5.6406e-06 - accuracy: 1.0000 - val_loss: 2.5246 - val_accuracy: 0.7533\n",
            "Epoch 655/2000\n",
            "75/75 - 0s - loss: 5.5884e-06 - accuracy: 1.0000 - val_loss: 2.5280 - val_accuracy: 0.7533\n",
            "Epoch 656/2000\n",
            "75/75 - 0s - loss: 5.4997e-06 - accuracy: 1.0000 - val_loss: 2.5267 - val_accuracy: 0.7533\n",
            "Epoch 657/2000\n",
            "75/75 - 0s - loss: 5.4707e-06 - accuracy: 1.0000 - val_loss: 2.5304 - val_accuracy: 0.7550\n",
            "Epoch 658/2000\n",
            "75/75 - 0s - loss: 5.3226e-06 - accuracy: 1.0000 - val_loss: 2.5283 - val_accuracy: 0.7550\n",
            "Epoch 659/2000\n",
            "75/75 - 0s - loss: 5.2478e-06 - accuracy: 1.0000 - val_loss: 2.5260 - val_accuracy: 0.7533\n",
            "Epoch 660/2000\n",
            "75/75 - 0s - loss: 5.1692e-06 - accuracy: 1.0000 - val_loss: 2.5275 - val_accuracy: 0.7550\n",
            "Epoch 661/2000\n",
            "75/75 - 0s - loss: 5.0808e-06 - accuracy: 1.0000 - val_loss: 2.5297 - val_accuracy: 0.7517\n",
            "Epoch 662/2000\n",
            "75/75 - 0s - loss: 5.0010e-06 - accuracy: 1.0000 - val_loss: 2.5280 - val_accuracy: 0.7533\n",
            "Epoch 663/2000\n",
            "75/75 - 0s - loss: 4.9337e-06 - accuracy: 1.0000 - val_loss: 2.5308 - val_accuracy: 0.7517\n",
            "Epoch 664/2000\n",
            "75/75 - 0s - loss: 4.8217e-06 - accuracy: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.7533\n",
            "Epoch 665/2000\n",
            "75/75 - 0s - loss: 4.8047e-06 - accuracy: 1.0000 - val_loss: 2.5286 - val_accuracy: 0.7533\n",
            "Epoch 666/2000\n",
            "75/75 - 0s - loss: 4.7398e-06 - accuracy: 1.0000 - val_loss: 2.5253 - val_accuracy: 0.7533\n",
            "Epoch 667/2000\n",
            "75/75 - 0s - loss: 4.6558e-06 - accuracy: 1.0000 - val_loss: 2.5288 - val_accuracy: 0.7533\n",
            "Epoch 668/2000\n",
            "75/75 - 0s - loss: 4.5783e-06 - accuracy: 1.0000 - val_loss: 2.5298 - val_accuracy: 0.7533\n",
            "Epoch 669/2000\n",
            "75/75 - 0s - loss: 4.5213e-06 - accuracy: 1.0000 - val_loss: 2.5293 - val_accuracy: 0.7533\n",
            "Epoch 670/2000\n",
            "75/75 - 0s - loss: 4.4089e-06 - accuracy: 1.0000 - val_loss: 2.5345 - val_accuracy: 0.7533\n",
            "Epoch 671/2000\n",
            "75/75 - 0s - loss: 4.4023e-06 - accuracy: 1.0000 - val_loss: 2.5322 - val_accuracy: 0.7533\n",
            "Epoch 672/2000\n",
            "75/75 - 0s - loss: 4.2899e-06 - accuracy: 1.0000 - val_loss: 2.5254 - val_accuracy: 0.7533\n",
            "Epoch 673/2000\n",
            "75/75 - 0s - loss: 4.2891e-06 - accuracy: 1.0000 - val_loss: 2.5304 - val_accuracy: 0.7533\n",
            "Epoch 674/2000\n",
            "75/75 - 0s - loss: 4.1817e-06 - accuracy: 1.0000 - val_loss: 2.5329 - val_accuracy: 0.7517\n",
            "Epoch 675/2000\n",
            "75/75 - 0s - loss: 4.1247e-06 - accuracy: 1.0000 - val_loss: 2.5324 - val_accuracy: 0.7533\n",
            "Epoch 676/2000\n",
            "75/75 - 0s - loss: 4.0580e-06 - accuracy: 1.0000 - val_loss: 2.5285 - val_accuracy: 0.7533\n",
            "Epoch 677/2000\n",
            "75/75 - 0s - loss: 3.9783e-06 - accuracy: 1.0000 - val_loss: 2.5347 - val_accuracy: 0.7517\n",
            "Epoch 678/2000\n",
            "75/75 - 0s - loss: 3.9388e-06 - accuracy: 1.0000 - val_loss: 2.5389 - val_accuracy: 0.7533\n",
            "Epoch 679/2000\n",
            "75/75 - 0s - loss: 3.8271e-06 - accuracy: 1.0000 - val_loss: 2.5301 - val_accuracy: 0.7533\n",
            "Epoch 680/2000\n",
            "75/75 - 0s - loss: 3.8032e-06 - accuracy: 1.0000 - val_loss: 2.5365 - val_accuracy: 0.7533\n",
            "Epoch 681/2000\n",
            "75/75 - 0s - loss: 3.7664e-06 - accuracy: 1.0000 - val_loss: 2.5368 - val_accuracy: 0.7517\n",
            "Epoch 682/2000\n",
            "75/75 - 0s - loss: 3.7163e-06 - accuracy: 1.0000 - val_loss: 2.5368 - val_accuracy: 0.7517\n",
            "Epoch 683/2000\n",
            "75/75 - 0s - loss: 3.6054e-06 - accuracy: 1.0000 - val_loss: 2.5386 - val_accuracy: 0.7517\n",
            "Epoch 684/2000\n",
            "75/75 - 0s - loss: 3.5796e-06 - accuracy: 1.0000 - val_loss: 2.5402 - val_accuracy: 0.7517\n",
            "Epoch 685/2000\n",
            "75/75 - 0s - loss: 3.5213e-06 - accuracy: 1.0000 - val_loss: 2.5320 - val_accuracy: 0.7550\n",
            "Epoch 686/2000\n",
            "75/75 - 0s - loss: 3.4595e-06 - accuracy: 1.0000 - val_loss: 2.5393 - val_accuracy: 0.7517\n",
            "Epoch 687/2000\n",
            "75/75 - 0s - loss: 3.4310e-06 - accuracy: 1.0000 - val_loss: 2.5436 - val_accuracy: 0.7550\n",
            "Epoch 688/2000\n",
            "75/75 - 0s - loss: 3.3695e-06 - accuracy: 1.0000 - val_loss: 2.5381 - val_accuracy: 0.7517\n",
            "Epoch 689/2000\n",
            "75/75 - 0s - loss: 3.3103e-06 - accuracy: 1.0000 - val_loss: 2.5378 - val_accuracy: 0.7550\n",
            "Epoch 690/2000\n",
            "75/75 - 0s - loss: 3.2862e-06 - accuracy: 1.0000 - val_loss: 2.5402 - val_accuracy: 0.7517\n",
            "Epoch 691/2000\n",
            "75/75 - 0s - loss: 3.1918e-06 - accuracy: 1.0000 - val_loss: 2.5448 - val_accuracy: 0.7550\n",
            "Epoch 692/2000\n",
            "75/75 - 0s - loss: 3.1987e-06 - accuracy: 1.0000 - val_loss: 2.5423 - val_accuracy: 0.7533\n",
            "Epoch 693/2000\n",
            "75/75 - 0s - loss: 3.0782e-06 - accuracy: 1.0000 - val_loss: 2.5365 - val_accuracy: 0.7567\n",
            "Epoch 694/2000\n",
            "75/75 - 0s - loss: 3.0910e-06 - accuracy: 1.0000 - val_loss: 2.5447 - val_accuracy: 0.7567\n",
            "Epoch 695/2000\n",
            "75/75 - 0s - loss: 3.0235e-06 - accuracy: 1.0000 - val_loss: 2.5378 - val_accuracy: 0.7567\n",
            "Epoch 696/2000\n",
            "75/75 - 0s - loss: 2.9467e-06 - accuracy: 1.0000 - val_loss: 2.5422 - val_accuracy: 0.7567\n",
            "Epoch 697/2000\n",
            "75/75 - 0s - loss: 2.8779e-06 - accuracy: 1.0000 - val_loss: 2.5512 - val_accuracy: 0.7550\n",
            "Epoch 698/2000\n",
            "75/75 - 0s - loss: 2.8601e-06 - accuracy: 1.0000 - val_loss: 2.5442 - val_accuracy: 0.7567\n",
            "Epoch 699/2000\n",
            "75/75 - 0s - loss: 2.8365e-06 - accuracy: 1.0000 - val_loss: 2.5456 - val_accuracy: 0.7567\n",
            "Epoch 700/2000\n",
            "75/75 - 0s - loss: 2.8057e-06 - accuracy: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.7567\n",
            "Epoch 701/2000\n",
            "75/75 - 0s - loss: 2.7330e-06 - accuracy: 1.0000 - val_loss: 2.5529 - val_accuracy: 0.7550\n",
            "Epoch 702/2000\n",
            "75/75 - 0s - loss: 2.7424e-06 - accuracy: 1.0000 - val_loss: 2.5496 - val_accuracy: 0.7550\n",
            "Epoch 703/2000\n",
            "75/75 - 0s - loss: 2.6300e-06 - accuracy: 1.0000 - val_loss: 2.5493 - val_accuracy: 0.7567\n",
            "Epoch 704/2000\n",
            "75/75 - 0s - loss: 2.6182e-06 - accuracy: 1.0000 - val_loss: 2.5530 - val_accuracy: 0.7567\n",
            "Epoch 705/2000\n",
            "75/75 - 0s - loss: 2.5921e-06 - accuracy: 1.0000 - val_loss: 2.5536 - val_accuracy: 0.7567\n",
            "Epoch 706/2000\n",
            "75/75 - 0s - loss: 2.5265e-06 - accuracy: 1.0000 - val_loss: 2.5492 - val_accuracy: 0.7567\n",
            "Epoch 707/2000\n",
            "75/75 - 0s - loss: 2.4770e-06 - accuracy: 1.0000 - val_loss: 2.5448 - val_accuracy: 0.7567\n",
            "Epoch 708/2000\n",
            "75/75 - 0s - loss: 2.4418e-06 - accuracy: 1.0000 - val_loss: 2.5601 - val_accuracy: 0.7567\n",
            "Epoch 709/2000\n",
            "75/75 - 0s - loss: 2.4067e-06 - accuracy: 1.0000 - val_loss: 2.5527 - val_accuracy: 0.7567\n",
            "Epoch 710/2000\n",
            "75/75 - 0s - loss: 2.3332e-06 - accuracy: 1.0000 - val_loss: 2.5514 - val_accuracy: 0.7583\n",
            "Epoch 711/2000\n",
            "75/75 - 0s - loss: 2.3149e-06 - accuracy: 1.0000 - val_loss: 2.5581 - val_accuracy: 0.7550\n",
            "Epoch 712/2000\n",
            "75/75 - 0s - loss: 2.2597e-06 - accuracy: 1.0000 - val_loss: 2.5591 - val_accuracy: 0.7550\n",
            "Epoch 713/2000\n",
            "75/75 - 0s - loss: 2.2455e-06 - accuracy: 1.0000 - val_loss: 2.5457 - val_accuracy: 0.7567\n",
            "Epoch 714/2000\n",
            "75/75 - 0s - loss: 2.1922e-06 - accuracy: 1.0000 - val_loss: 2.5492 - val_accuracy: 0.7567\n",
            "Epoch 715/2000\n",
            "75/75 - 0s - loss: 2.1810e-06 - accuracy: 1.0000 - val_loss: 2.5536 - val_accuracy: 0.7550\n",
            "Epoch 716/2000\n",
            "75/75 - 0s - loss: 2.1437e-06 - accuracy: 1.0000 - val_loss: 2.5503 - val_accuracy: 0.7567\n",
            "Epoch 717/2000\n",
            "75/75 - 0s - loss: 2.0548e-06 - accuracy: 1.0000 - val_loss: 2.5559 - val_accuracy: 0.7533\n",
            "Epoch 718/2000\n",
            "75/75 - 0s - loss: 2.0720e-06 - accuracy: 1.0000 - val_loss: 2.5588 - val_accuracy: 0.7550\n",
            "Epoch 719/2000\n",
            "75/75 - 0s - loss: 2.0074e-06 - accuracy: 1.0000 - val_loss: 2.5603 - val_accuracy: 0.7567\n",
            "Epoch 720/2000\n",
            "75/75 - 0s - loss: 2.0874e-06 - accuracy: 1.0000 - val_loss: 2.5657 - val_accuracy: 0.7533\n",
            "Epoch 721/2000\n",
            "75/75 - 0s - loss: 1.9385e-06 - accuracy: 1.0000 - val_loss: 2.5590 - val_accuracy: 0.7550\n",
            "Epoch 722/2000\n",
            "75/75 - 0s - loss: 1.9115e-06 - accuracy: 1.0000 - val_loss: 2.5692 - val_accuracy: 0.7567\n",
            "Epoch 723/2000\n",
            "75/75 - 0s - loss: 1.9118e-06 - accuracy: 1.0000 - val_loss: 2.5720 - val_accuracy: 0.7567\n",
            "Epoch 724/2000\n",
            "75/75 - 0s - loss: 1.8515e-06 - accuracy: 1.0000 - val_loss: 2.5568 - val_accuracy: 0.7550\n",
            "Epoch 725/2000\n",
            "75/75 - 0s - loss: 1.8836e-06 - accuracy: 1.0000 - val_loss: 2.5776 - val_accuracy: 0.7550\n",
            "Epoch 726/2000\n",
            "75/75 - 0s - loss: 1.8421e-06 - accuracy: 1.0000 - val_loss: 2.5543 - val_accuracy: 0.7550\n",
            "Epoch 727/2000\n",
            "75/75 - 0s - loss: 1.8042e-06 - accuracy: 1.0000 - val_loss: 2.5647 - val_accuracy: 0.7567\n",
            "Epoch 728/2000\n",
            "75/75 - 0s - loss: 1.7340e-06 - accuracy: 1.0000 - val_loss: 2.5635 - val_accuracy: 0.7550\n",
            "Epoch 729/2000\n",
            "75/75 - 0s - loss: 1.6978e-06 - accuracy: 1.0000 - val_loss: 2.5714 - val_accuracy: 0.7567\n",
            "Epoch 730/2000\n",
            "75/75 - 0s - loss: 1.6564e-06 - accuracy: 1.0000 - val_loss: 2.5672 - val_accuracy: 0.7550\n",
            "Epoch 731/2000\n",
            "75/75 - 0s - loss: 1.6395e-06 - accuracy: 1.0000 - val_loss: 2.5700 - val_accuracy: 0.7550\n",
            "Epoch 732/2000\n",
            "75/75 - 0s - loss: 1.6204e-06 - accuracy: 1.0000 - val_loss: 2.5581 - val_accuracy: 0.7567\n",
            "Epoch 733/2000\n",
            "75/75 - 0s - loss: 1.6303e-06 - accuracy: 1.0000 - val_loss: 2.5756 - val_accuracy: 0.7567\n",
            "Epoch 734/2000\n",
            "75/75 - 0s - loss: 1.5385e-06 - accuracy: 1.0000 - val_loss: 2.5788 - val_accuracy: 0.7583\n",
            "Epoch 735/2000\n",
            "75/75 - 0s - loss: 1.5808e-06 - accuracy: 1.0000 - val_loss: 2.5622 - val_accuracy: 0.7567\n",
            "Epoch 736/2000\n",
            "75/75 - 0s - loss: 1.5500e-06 - accuracy: 1.0000 - val_loss: 2.5806 - val_accuracy: 0.7583\n",
            "Epoch 737/2000\n",
            "75/75 - 0s - loss: 1.4579e-06 - accuracy: 1.0000 - val_loss: 2.5846 - val_accuracy: 0.7567\n",
            "Epoch 738/2000\n",
            "75/75 - 0s - loss: 1.4540e-06 - accuracy: 1.0000 - val_loss: 2.5816 - val_accuracy: 0.7583\n",
            "Epoch 739/2000\n",
            "75/75 - 0s - loss: 1.4286e-06 - accuracy: 1.0000 - val_loss: 2.5779 - val_accuracy: 0.7583\n",
            "Epoch 740/2000\n",
            "75/75 - 0s - loss: 1.3971e-06 - accuracy: 1.0000 - val_loss: 2.5870 - val_accuracy: 0.7550\n",
            "Epoch 741/2000\n",
            "75/75 - 0s - loss: 1.3763e-06 - accuracy: 1.0000 - val_loss: 2.5793 - val_accuracy: 0.7567\n",
            "Epoch 742/2000\n",
            "75/75 - 0s - loss: 1.3625e-06 - accuracy: 1.0000 - val_loss: 2.5865 - val_accuracy: 0.7567\n",
            "Epoch 743/2000\n",
            "75/75 - 0s - loss: 1.3704e-06 - accuracy: 1.0000 - val_loss: 2.5922 - val_accuracy: 0.7567\n",
            "Epoch 744/2000\n",
            "75/75 - 0s - loss: 1.3269e-06 - accuracy: 1.0000 - val_loss: 2.5842 - val_accuracy: 0.7567\n",
            "Epoch 745/2000\n",
            "75/75 - 0s - loss: 1.2496e-06 - accuracy: 1.0000 - val_loss: 2.5852 - val_accuracy: 0.7567\n",
            "Epoch 746/2000\n",
            "75/75 - 0s - loss: 1.2336e-06 - accuracy: 1.0000 - val_loss: 2.5751 - val_accuracy: 0.7583\n",
            "Epoch 747/2000\n",
            "75/75 - 0s - loss: 1.2359e-06 - accuracy: 1.0000 - val_loss: 2.5805 - val_accuracy: 0.7550\n",
            "Epoch 748/2000\n",
            "75/75 - 0s - loss: 1.2116e-06 - accuracy: 1.0000 - val_loss: 2.5877 - val_accuracy: 0.7567\n",
            "Epoch 749/2000\n",
            "75/75 - 0s - loss: 1.1884e-06 - accuracy: 1.0000 - val_loss: 2.6040 - val_accuracy: 0.7550\n",
            "Epoch 750/2000\n",
            "75/75 - 0s - loss: 1.1604e-06 - accuracy: 1.0000 - val_loss: 2.5957 - val_accuracy: 0.7567\n",
            "Epoch 751/2000\n",
            "75/75 - 0s - loss: 1.1998e-06 - accuracy: 1.0000 - val_loss: 2.5867 - val_accuracy: 0.7550\n",
            "Epoch 752/2000\n",
            "75/75 - 0s - loss: 1.1125e-06 - accuracy: 1.0000 - val_loss: 2.5908 - val_accuracy: 0.7567\n",
            "Epoch 753/2000\n",
            "75/75 - 0s - loss: 1.0544e-06 - accuracy: 1.0000 - val_loss: 2.5900 - val_accuracy: 0.7583\n",
            "Epoch 754/2000\n",
            "75/75 - 0s - loss: 1.0635e-06 - accuracy: 1.0000 - val_loss: 2.5900 - val_accuracy: 0.7567\n",
            "Epoch 755/2000\n",
            "75/75 - 0s - loss: 1.0149e-06 - accuracy: 1.0000 - val_loss: 2.5824 - val_accuracy: 0.7583\n",
            "Epoch 756/2000\n",
            "75/75 - 0s - loss: 1.0030e-06 - accuracy: 1.0000 - val_loss: 2.5931 - val_accuracy: 0.7567\n",
            "Epoch 757/2000\n",
            "75/75 - 0s - loss: 9.8574e-07 - accuracy: 1.0000 - val_loss: 2.5846 - val_accuracy: 0.7567\n",
            "Epoch 758/2000\n",
            "75/75 - 0s - loss: 1.0017e-06 - accuracy: 1.0000 - val_loss: 2.6022 - val_accuracy: 0.7550\n",
            "Epoch 759/2000\n",
            "75/75 - 0s - loss: 9.9569e-07 - accuracy: 1.0000 - val_loss: 2.5980 - val_accuracy: 0.7567\n",
            "Epoch 760/2000\n",
            "75/75 - 0s - loss: 9.9380e-07 - accuracy: 1.0000 - val_loss: 2.5851 - val_accuracy: 0.7567\n",
            "Epoch 761/2000\n",
            "75/75 - 0s - loss: 9.1212e-07 - accuracy: 1.0000 - val_loss: 2.5993 - val_accuracy: 0.7567\n",
            "Epoch 762/2000\n",
            "75/75 - 0s - loss: 9.0372e-07 - accuracy: 1.0000 - val_loss: 2.6048 - val_accuracy: 0.7550\n",
            "Epoch 763/2000\n",
            "75/75 - 0s - loss: 9.7008e-07 - accuracy: 1.0000 - val_loss: 2.6071 - val_accuracy: 0.7550\n",
            "Epoch 764/2000\n",
            "75/75 - 0s - loss: 8.7443e-07 - accuracy: 1.0000 - val_loss: 2.6175 - val_accuracy: 0.7550\n",
            "Epoch 765/2000\n",
            "75/75 - 0s - loss: 8.4618e-07 - accuracy: 1.0000 - val_loss: 2.6293 - val_accuracy: 0.7567\n",
            "Epoch 766/2000\n",
            "75/75 - 0s - loss: 7.9682e-07 - accuracy: 1.0000 - val_loss: 2.5953 - val_accuracy: 0.7600\n",
            "Epoch 767/2000\n",
            "75/75 - 0s - loss: 7.7941e-07 - accuracy: 1.0000 - val_loss: 2.6040 - val_accuracy: 0.7550\n",
            "Epoch 768/2000\n",
            "75/75 - 0s - loss: 7.9195e-07 - accuracy: 1.0000 - val_loss: 2.6185 - val_accuracy: 0.7567\n",
            "Epoch 769/2000\n",
            "75/75 - 0s - loss: 7.6647e-07 - accuracy: 1.0000 - val_loss: 2.6002 - val_accuracy: 0.7583\n",
            "Epoch 770/2000\n",
            "75/75 - 0s - loss: 7.3713e-07 - accuracy: 1.0000 - val_loss: 2.6291 - val_accuracy: 0.7550\n",
            "Epoch 771/2000\n",
            "75/75 - 0s - loss: 7.4419e-07 - accuracy: 1.0000 - val_loss: 2.6241 - val_accuracy: 0.7567\n",
            "Epoch 772/2000\n",
            "75/75 - 0s - loss: 7.0073e-07 - accuracy: 1.0000 - val_loss: 2.6296 - val_accuracy: 0.7567\n",
            "Epoch 773/2000\n",
            "75/75 - 0s - loss: 6.7064e-07 - accuracy: 1.0000 - val_loss: 2.6086 - val_accuracy: 0.7583\n",
            "Epoch 774/2000\n",
            "75/75 - 0s - loss: 6.6490e-07 - accuracy: 1.0000 - val_loss: 2.6145 - val_accuracy: 0.7583\n",
            "Epoch 775/2000\n",
            "75/75 - 0s - loss: 6.4497e-07 - accuracy: 1.0000 - val_loss: 2.6229 - val_accuracy: 0.7550\n",
            "Epoch 776/2000\n",
            "75/75 - 0s - loss: 6.5835e-07 - accuracy: 1.0000 - val_loss: 2.6120 - val_accuracy: 0.7567\n",
            "Epoch 777/2000\n",
            "75/75 - 0s - loss: 6.5848e-07 - accuracy: 1.0000 - val_loss: 2.6352 - val_accuracy: 0.7567\n",
            "Epoch 778/2000\n",
            "75/75 - 0s - loss: 5.7981e-07 - accuracy: 1.0000 - val_loss: 2.6145 - val_accuracy: 0.7550\n",
            "Epoch 779/2000\n",
            "75/75 - 0s - loss: 6.5170e-07 - accuracy: 1.0000 - val_loss: 2.6420 - val_accuracy: 0.7567\n",
            "Epoch 780/2000\n",
            "75/75 - 0s - loss: 6.7188e-07 - accuracy: 1.0000 - val_loss: 2.6196 - val_accuracy: 0.7567\n",
            "Epoch 781/2000\n",
            "75/75 - 0s - loss: 5.4163e-07 - accuracy: 1.0000 - val_loss: 2.6392 - val_accuracy: 0.7517\n",
            "Epoch 782/2000\n",
            "75/75 - 0s - loss: 5.6594e-07 - accuracy: 1.0000 - val_loss: 2.6382 - val_accuracy: 0.7517\n",
            "Epoch 783/2000\n",
            "75/75 - 0s - loss: 6.7673e-07 - accuracy: 1.0000 - val_loss: 2.6239 - val_accuracy: 0.7533\n",
            "Epoch 784/2000\n",
            "75/75 - 0s - loss: 5.8033e-07 - accuracy: 1.0000 - val_loss: 2.6583 - val_accuracy: 0.7550\n",
            "Epoch 785/2000\n",
            "75/75 - 0s - loss: 5.3525e-07 - accuracy: 1.0000 - val_loss: 2.6531 - val_accuracy: 0.7567\n",
            "Epoch 786/2000\n",
            "75/75 - 0s - loss: 4.9313e-07 - accuracy: 1.0000 - val_loss: 2.6472 - val_accuracy: 0.7533\n",
            "Epoch 787/2000\n",
            "75/75 - 0s - loss: 4.8660e-07 - accuracy: 1.0000 - val_loss: 2.6424 - val_accuracy: 0.7533\n",
            "Epoch 788/2000\n",
            "75/75 - 0s - loss: 5.3252e-07 - accuracy: 1.0000 - val_loss: 2.6457 - val_accuracy: 0.7550\n",
            "Epoch 789/2000\n",
            "75/75 - 0s - loss: 5.5095e-07 - accuracy: 1.0000 - val_loss: 2.6457 - val_accuracy: 0.7550\n",
            "Epoch 790/2000\n",
            "75/75 - 0s - loss: 0.0029 - accuracy: 0.9983 - val_loss: 2.8009 - val_accuracy: 0.7417\n",
            "Epoch 791/2000\n",
            "75/75 - 0s - loss: 0.1171 - accuracy: 0.9775 - val_loss: 2.7995 - val_accuracy: 0.7517\n",
            "Epoch 792/2000\n",
            "75/75 - 0s - loss: 0.0284 - accuracy: 0.9925 - val_loss: 2.6845 - val_accuracy: 0.7600\n",
            "Epoch 793/2000\n",
            "75/75 - 0s - loss: 0.0118 - accuracy: 0.9950 - val_loss: 2.8129 - val_accuracy: 0.7417\n",
            "Epoch 794/2000\n",
            "75/75 - 0s - loss: 4.5422e-04 - accuracy: 0.9996 - val_loss: 2.7915 - val_accuracy: 0.7433\n",
            "Epoch 795/2000\n",
            "75/75 - 0s - loss: 6.5138e-05 - accuracy: 1.0000 - val_loss: 2.7925 - val_accuracy: 0.7433\n",
            "Epoch 796/2000\n",
            "75/75 - 0s - loss: 4.8639e-05 - accuracy: 1.0000 - val_loss: 2.7945 - val_accuracy: 0.7417\n",
            "Epoch 797/2000\n",
            "75/75 - 0s - loss: 4.1510e-05 - accuracy: 1.0000 - val_loss: 2.7935 - val_accuracy: 0.7417\n",
            "Epoch 798/2000\n",
            "75/75 - 0s - loss: 3.7548e-05 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.7417\n",
            "Epoch 799/2000\n",
            "75/75 - 0s - loss: 3.4388e-05 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.7417\n",
            "Epoch 800/2000\n",
            "75/75 - 0s - loss: 3.1799e-05 - accuracy: 1.0000 - val_loss: 2.7947 - val_accuracy: 0.7417\n",
            "Epoch 801/2000\n",
            "75/75 - 0s - loss: 2.9883e-05 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7417\n",
            "Epoch 802/2000\n",
            "75/75 - 0s - loss: 2.8116e-05 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7400\n",
            "Epoch 803/2000\n",
            "75/75 - 0s - loss: 2.6564e-05 - accuracy: 1.0000 - val_loss: 2.7949 - val_accuracy: 0.7400\n",
            "Epoch 804/2000\n",
            "75/75 - 0s - loss: 2.5330e-05 - accuracy: 1.0000 - val_loss: 2.7952 - val_accuracy: 0.7400\n",
            "Epoch 805/2000\n",
            "75/75 - 0s - loss: 2.4078e-05 - accuracy: 1.0000 - val_loss: 2.7949 - val_accuracy: 0.7400\n",
            "Epoch 806/2000\n",
            "75/75 - 0s - loss: 2.2951e-05 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7400\n",
            "Epoch 807/2000\n",
            "75/75 - 0s - loss: 2.2125e-05 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.7400\n",
            "Epoch 808/2000\n",
            "75/75 - 0s - loss: 2.1164e-05 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.7400\n",
            "Epoch 809/2000\n",
            "75/75 - 0s - loss: 2.0350e-05 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7400\n",
            "Epoch 810/2000\n",
            "75/75 - 0s - loss: 1.9609e-05 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.7400\n",
            "Epoch 811/2000\n",
            "75/75 - 0s - loss: 1.8846e-05 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.7400\n",
            "Epoch 812/2000\n",
            "75/75 - 0s - loss: 1.8269e-05 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7400\n",
            "Epoch 813/2000\n",
            "75/75 - 0s - loss: 1.7616e-05 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.7400\n",
            "Epoch 814/2000\n",
            "75/75 - 0s - loss: 1.7031e-05 - accuracy: 1.0000 - val_loss: 2.7939 - val_accuracy: 0.7400\n",
            "Epoch 815/2000\n",
            "75/75 - 0s - loss: 1.6525e-05 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.7400\n",
            "Epoch 816/2000\n",
            "75/75 - 0s - loss: 1.5981e-05 - accuracy: 1.0000 - val_loss: 2.7941 - val_accuracy: 0.7400\n",
            "Epoch 817/2000\n",
            "75/75 - 0s - loss: 1.5506e-05 - accuracy: 1.0000 - val_loss: 2.7939 - val_accuracy: 0.7400\n",
            "Epoch 818/2000\n",
            "75/75 - 0s - loss: 1.5034e-05 - accuracy: 1.0000 - val_loss: 2.7927 - val_accuracy: 0.7400\n",
            "Epoch 819/2000\n",
            "75/75 - 0s - loss: 1.4570e-05 - accuracy: 1.0000 - val_loss: 2.7932 - val_accuracy: 0.7400\n",
            "Epoch 820/2000\n",
            "75/75 - 0s - loss: 1.4156e-05 - accuracy: 1.0000 - val_loss: 2.7933 - val_accuracy: 0.7400\n",
            "Epoch 821/2000\n",
            "75/75 - 0s - loss: 1.3758e-05 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.7400\n",
            "Epoch 822/2000\n",
            "75/75 - 0s - loss: 1.3344e-05 - accuracy: 1.0000 - val_loss: 2.7930 - val_accuracy: 0.7400\n",
            "Epoch 823/2000\n",
            "75/75 - 0s - loss: 1.3028e-05 - accuracy: 1.0000 - val_loss: 2.7924 - val_accuracy: 0.7400\n",
            "Epoch 824/2000\n",
            "75/75 - 0s - loss: 1.2643e-05 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.7400\n",
            "Epoch 825/2000\n",
            "75/75 - 0s - loss: 1.2293e-05 - accuracy: 1.0000 - val_loss: 2.7924 - val_accuracy: 0.7400\n",
            "Epoch 826/2000\n",
            "75/75 - 0s - loss: 1.1992e-05 - accuracy: 1.0000 - val_loss: 2.7920 - val_accuracy: 0.7400\n",
            "Epoch 827/2000\n",
            "75/75 - 0s - loss: 1.1643e-05 - accuracy: 1.0000 - val_loss: 2.7917 - val_accuracy: 0.7417\n",
            "Epoch 828/2000\n",
            "75/75 - 0s - loss: 1.1343e-05 - accuracy: 1.0000 - val_loss: 2.7911 - val_accuracy: 0.7417\n",
            "Epoch 829/2000\n",
            "75/75 - 0s - loss: 1.1050e-05 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.7417\n",
            "Epoch 830/2000\n",
            "75/75 - 0s - loss: 1.0764e-05 - accuracy: 1.0000 - val_loss: 2.7907 - val_accuracy: 0.7400\n",
            "Epoch 831/2000\n",
            "75/75 - 0s - loss: 1.0477e-05 - accuracy: 1.0000 - val_loss: 2.7901 - val_accuracy: 0.7400\n",
            "Epoch 832/2000\n",
            "75/75 - 0s - loss: 1.0223e-05 - accuracy: 1.0000 - val_loss: 2.7899 - val_accuracy: 0.7400\n",
            "Epoch 833/2000\n",
            "75/75 - 0s - loss: 9.9948e-06 - accuracy: 1.0000 - val_loss: 2.7896 - val_accuracy: 0.7400\n",
            "Epoch 834/2000\n",
            "75/75 - 0s - loss: 9.7520e-06 - accuracy: 1.0000 - val_loss: 2.7894 - val_accuracy: 0.7400\n",
            "Epoch 835/2000\n",
            "75/75 - 0s - loss: 9.4929e-06 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.7400\n",
            "Epoch 836/2000\n",
            "75/75 - 0s - loss: 9.2595e-06 - accuracy: 1.0000 - val_loss: 2.7890 - val_accuracy: 0.7400\n",
            "Epoch 837/2000\n",
            "75/75 - 0s - loss: 9.0277e-06 - accuracy: 1.0000 - val_loss: 2.7883 - val_accuracy: 0.7400\n",
            "Epoch 838/2000\n",
            "75/75 - 0s - loss: 8.8157e-06 - accuracy: 1.0000 - val_loss: 2.7885 - val_accuracy: 0.7400\n",
            "Epoch 839/2000\n",
            "75/75 - 0s - loss: 8.6148e-06 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.7400\n",
            "Epoch 840/2000\n",
            "75/75 - 0s - loss: 8.3950e-06 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.7400\n",
            "Epoch 841/2000\n",
            "75/75 - 0s - loss: 8.1991e-06 - accuracy: 1.0000 - val_loss: 2.7870 - val_accuracy: 0.7400\n",
            "Epoch 842/2000\n",
            "75/75 - 0s - loss: 7.9949e-06 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.7400\n",
            "Epoch 843/2000\n",
            "75/75 - 0s - loss: 7.8107e-06 - accuracy: 1.0000 - val_loss: 2.7871 - val_accuracy: 0.7400\n",
            "Epoch 844/2000\n",
            "75/75 - 0s - loss: 7.6515e-06 - accuracy: 1.0000 - val_loss: 2.7865 - val_accuracy: 0.7400\n",
            "Epoch 845/2000\n",
            "75/75 - 0s - loss: 7.4540e-06 - accuracy: 1.0000 - val_loss: 2.7858 - val_accuracy: 0.7400\n",
            "Epoch 846/2000\n",
            "75/75 - 0s - loss: 7.2827e-06 - accuracy: 1.0000 - val_loss: 2.7856 - val_accuracy: 0.7383\n",
            "Epoch 847/2000\n",
            "75/75 - 0s - loss: 7.1208e-06 - accuracy: 1.0000 - val_loss: 2.7847 - val_accuracy: 0.7383\n",
            "Epoch 848/2000\n",
            "75/75 - 0s - loss: 6.9522e-06 - accuracy: 1.0000 - val_loss: 2.7846 - val_accuracy: 0.7383\n",
            "Epoch 849/2000\n",
            "75/75 - 0s - loss: 6.7837e-06 - accuracy: 1.0000 - val_loss: 2.7846 - val_accuracy: 0.7400\n",
            "Epoch 850/2000\n",
            "75/75 - 0s - loss: 6.6288e-06 - accuracy: 1.0000 - val_loss: 2.7841 - val_accuracy: 0.7400\n",
            "Epoch 851/2000\n",
            "75/75 - 0s - loss: 6.4945e-06 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.7400\n",
            "Epoch 852/2000\n",
            "75/75 - 0s - loss: 6.3356e-06 - accuracy: 1.0000 - val_loss: 2.7834 - val_accuracy: 0.7400\n",
            "Epoch 853/2000\n",
            "75/75 - 0s - loss: 6.1872e-06 - accuracy: 1.0000 - val_loss: 2.7826 - val_accuracy: 0.7400\n",
            "Epoch 854/2000\n",
            "75/75 - 0s - loss: 6.0728e-06 - accuracy: 1.0000 - val_loss: 2.7829 - val_accuracy: 0.7400\n",
            "Epoch 855/2000\n",
            "75/75 - 0s - loss: 5.9128e-06 - accuracy: 1.0000 - val_loss: 2.7825 - val_accuracy: 0.7400\n",
            "Epoch 856/2000\n",
            "75/75 - 0s - loss: 5.7819e-06 - accuracy: 1.0000 - val_loss: 2.7820 - val_accuracy: 0.7400\n",
            "Epoch 857/2000\n",
            "75/75 - 0s - loss: 5.6583e-06 - accuracy: 1.0000 - val_loss: 2.7813 - val_accuracy: 0.7400\n",
            "Epoch 858/2000\n",
            "75/75 - 0s - loss: 5.5141e-06 - accuracy: 1.0000 - val_loss: 2.7819 - val_accuracy: 0.7400\n",
            "Epoch 859/2000\n",
            "75/75 - 0s - loss: 5.3998e-06 - accuracy: 1.0000 - val_loss: 2.7814 - val_accuracy: 0.7400\n",
            "Epoch 860/2000\n",
            "75/75 - 0s - loss: 5.2792e-06 - accuracy: 1.0000 - val_loss: 2.7805 - val_accuracy: 0.7400\n",
            "Epoch 861/2000\n",
            "75/75 - 0s - loss: 5.1608e-06 - accuracy: 1.0000 - val_loss: 2.7798 - val_accuracy: 0.7400\n",
            "Epoch 862/2000\n",
            "75/75 - 0s - loss: 5.0612e-06 - accuracy: 1.0000 - val_loss: 2.7797 - val_accuracy: 0.7400\n",
            "Epoch 863/2000\n",
            "75/75 - 0s - loss: 4.9413e-06 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.7417\n",
            "Epoch 864/2000\n",
            "75/75 - 0s - loss: 4.8218e-06 - accuracy: 1.0000 - val_loss: 2.7783 - val_accuracy: 0.7417\n",
            "Epoch 865/2000\n",
            "75/75 - 0s - loss: 4.7153e-06 - accuracy: 1.0000 - val_loss: 2.7772 - val_accuracy: 0.7433\n",
            "Epoch 866/2000\n",
            "75/75 - 0s - loss: 4.6211e-06 - accuracy: 1.0000 - val_loss: 2.7778 - val_accuracy: 0.7433\n",
            "Epoch 867/2000\n",
            "75/75 - 0s - loss: 4.5109e-06 - accuracy: 1.0000 - val_loss: 2.7774 - val_accuracy: 0.7433\n",
            "Epoch 868/2000\n",
            "75/75 - 0s - loss: 4.4060e-06 - accuracy: 1.0000 - val_loss: 2.7775 - val_accuracy: 0.7433\n",
            "Epoch 869/2000\n",
            "75/75 - 0s - loss: 4.3053e-06 - accuracy: 1.0000 - val_loss: 2.7765 - val_accuracy: 0.7433\n",
            "Epoch 870/2000\n",
            "75/75 - 0s - loss: 4.2240e-06 - accuracy: 1.0000 - val_loss: 2.7771 - val_accuracy: 0.7433\n",
            "Epoch 871/2000\n",
            "75/75 - 0s - loss: 4.1265e-06 - accuracy: 1.0000 - val_loss: 2.7758 - val_accuracy: 0.7433\n",
            "Epoch 872/2000\n",
            "75/75 - 0s - loss: 4.0202e-06 - accuracy: 1.0000 - val_loss: 2.7754 - val_accuracy: 0.7433\n",
            "Epoch 873/2000\n",
            "75/75 - 0s - loss: 3.9373e-06 - accuracy: 1.0000 - val_loss: 2.7749 - val_accuracy: 0.7433\n",
            "Epoch 874/2000\n",
            "75/75 - 0s - loss: 3.8542e-06 - accuracy: 1.0000 - val_loss: 2.7746 - val_accuracy: 0.7433\n",
            "Epoch 875/2000\n",
            "75/75 - 0s - loss: 3.7587e-06 - accuracy: 1.0000 - val_loss: 2.7738 - val_accuracy: 0.7433\n",
            "Epoch 876/2000\n",
            "75/75 - 0s - loss: 3.6776e-06 - accuracy: 1.0000 - val_loss: 2.7734 - val_accuracy: 0.7433\n",
            "Epoch 877/2000\n",
            "75/75 - 0s - loss: 3.5929e-06 - accuracy: 1.0000 - val_loss: 2.7722 - val_accuracy: 0.7433\n",
            "Epoch 878/2000\n",
            "75/75 - 0s - loss: 3.5147e-06 - accuracy: 1.0000 - val_loss: 2.7725 - val_accuracy: 0.7433\n",
            "Epoch 879/2000\n",
            "75/75 - 0s - loss: 3.4439e-06 - accuracy: 1.0000 - val_loss: 2.7711 - val_accuracy: 0.7433\n",
            "Epoch 880/2000\n",
            "75/75 - 0s - loss: 3.3655e-06 - accuracy: 1.0000 - val_loss: 2.7709 - val_accuracy: 0.7433\n",
            "Epoch 881/2000\n",
            "75/75 - 0s - loss: 3.2798e-06 - accuracy: 1.0000 - val_loss: 2.7710 - val_accuracy: 0.7433\n",
            "Epoch 882/2000\n",
            "75/75 - 0s - loss: 3.2065e-06 - accuracy: 1.0000 - val_loss: 2.7697 - val_accuracy: 0.7433\n",
            "Epoch 883/2000\n",
            "75/75 - 0s - loss: 3.1383e-06 - accuracy: 1.0000 - val_loss: 2.7692 - val_accuracy: 0.7433\n",
            "Epoch 884/2000\n",
            "75/75 - 0s - loss: 3.0793e-06 - accuracy: 1.0000 - val_loss: 2.7678 - val_accuracy: 0.7433\n",
            "Epoch 885/2000\n",
            "75/75 - 0s - loss: 3.0084e-06 - accuracy: 1.0000 - val_loss: 2.7688 - val_accuracy: 0.7433\n",
            "Epoch 886/2000\n",
            "75/75 - 0s - loss: 2.9383e-06 - accuracy: 1.0000 - val_loss: 2.7686 - val_accuracy: 0.7433\n",
            "Epoch 887/2000\n",
            "75/75 - 0s - loss: 2.8825e-06 - accuracy: 1.0000 - val_loss: 2.7678 - val_accuracy: 0.7433\n",
            "Epoch 888/2000\n",
            "75/75 - 0s - loss: 2.8131e-06 - accuracy: 1.0000 - val_loss: 2.7672 - val_accuracy: 0.7417\n",
            "Epoch 889/2000\n",
            "75/75 - 0s - loss: 2.7496e-06 - accuracy: 1.0000 - val_loss: 2.7660 - val_accuracy: 0.7433\n",
            "Epoch 890/2000\n",
            "75/75 - 0s - loss: 2.6847e-06 - accuracy: 1.0000 - val_loss: 2.7662 - val_accuracy: 0.7417\n",
            "Epoch 891/2000\n",
            "75/75 - 0s - loss: 2.6341e-06 - accuracy: 1.0000 - val_loss: 2.7654 - val_accuracy: 0.7417\n",
            "Epoch 892/2000\n",
            "75/75 - 0s - loss: 2.5690e-06 - accuracy: 1.0000 - val_loss: 2.7641 - val_accuracy: 0.7417\n",
            "Epoch 893/2000\n",
            "75/75 - 0s - loss: 2.5153e-06 - accuracy: 1.0000 - val_loss: 2.7638 - val_accuracy: 0.7417\n",
            "Epoch 894/2000\n",
            "75/75 - 0s - loss: 2.4631e-06 - accuracy: 1.0000 - val_loss: 2.7636 - val_accuracy: 0.7417\n",
            "Epoch 895/2000\n",
            "75/75 - 0s - loss: 2.4067e-06 - accuracy: 1.0000 - val_loss: 2.7630 - val_accuracy: 0.7417\n",
            "Epoch 896/2000\n",
            "75/75 - 0s - loss: 2.3579e-06 - accuracy: 1.0000 - val_loss: 2.7622 - val_accuracy: 0.7417\n",
            "Epoch 897/2000\n",
            "75/75 - 0s - loss: 2.3040e-06 - accuracy: 1.0000 - val_loss: 2.7610 - val_accuracy: 0.7417\n",
            "Epoch 898/2000\n",
            "75/75 - 0s - loss: 2.2541e-06 - accuracy: 1.0000 - val_loss: 2.7599 - val_accuracy: 0.7417\n",
            "Epoch 899/2000\n",
            "75/75 - 0s - loss: 2.2016e-06 - accuracy: 1.0000 - val_loss: 2.7590 - val_accuracy: 0.7417\n",
            "Epoch 900/2000\n",
            "75/75 - 0s - loss: 2.1602e-06 - accuracy: 1.0000 - val_loss: 2.7597 - val_accuracy: 0.7417\n",
            "Epoch 901/2000\n",
            "75/75 - 0s - loss: 2.1145e-06 - accuracy: 1.0000 - val_loss: 2.7600 - val_accuracy: 0.7417\n",
            "Epoch 902/2000\n",
            "75/75 - 0s - loss: 2.0669e-06 - accuracy: 1.0000 - val_loss: 2.7578 - val_accuracy: 0.7417\n",
            "Epoch 903/2000\n",
            "75/75 - 0s - loss: 2.0172e-06 - accuracy: 1.0000 - val_loss: 2.7580 - val_accuracy: 0.7417\n",
            "Epoch 904/2000\n",
            "75/75 - 0s - loss: 1.9761e-06 - accuracy: 1.0000 - val_loss: 2.7565 - val_accuracy: 0.7417\n",
            "Epoch 905/2000\n",
            "75/75 - 0s - loss: 1.9358e-06 - accuracy: 1.0000 - val_loss: 2.7570 - val_accuracy: 0.7417\n",
            "Epoch 906/2000\n",
            "75/75 - 0s - loss: 1.9033e-06 - accuracy: 1.0000 - val_loss: 2.7549 - val_accuracy: 0.7417\n",
            "Epoch 907/2000\n",
            "75/75 - 0s - loss: 1.8568e-06 - accuracy: 1.0000 - val_loss: 2.7547 - val_accuracy: 0.7417\n",
            "Epoch 908/2000\n",
            "75/75 - 0s - loss: 1.8218e-06 - accuracy: 1.0000 - val_loss: 2.7543 - val_accuracy: 0.7417\n",
            "Epoch 909/2000\n",
            "75/75 - 0s - loss: 1.7772e-06 - accuracy: 1.0000 - val_loss: 2.7535 - val_accuracy: 0.7417\n",
            "Epoch 910/2000\n",
            "75/75 - 0s - loss: 1.7459e-06 - accuracy: 1.0000 - val_loss: 2.7541 - val_accuracy: 0.7417\n",
            "Epoch 911/2000\n",
            "75/75 - 0s - loss: 1.6950e-06 - accuracy: 1.0000 - val_loss: 2.7521 - val_accuracy: 0.7417\n",
            "Epoch 912/2000\n",
            "75/75 - 0s - loss: 1.6648e-06 - accuracy: 1.0000 - val_loss: 2.7509 - val_accuracy: 0.7417\n",
            "Epoch 913/2000\n",
            "75/75 - 0s - loss: 1.6288e-06 - accuracy: 1.0000 - val_loss: 2.7512 - val_accuracy: 0.7417\n",
            "Epoch 914/2000\n",
            "75/75 - 0s - loss: 1.5936e-06 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.7417\n",
            "Epoch 915/2000\n",
            "75/75 - 0s - loss: 1.5613e-06 - accuracy: 1.0000 - val_loss: 2.7500 - val_accuracy: 0.7417\n",
            "Epoch 916/2000\n",
            "75/75 - 0s - loss: 1.5238e-06 - accuracy: 1.0000 - val_loss: 2.7495 - val_accuracy: 0.7417\n",
            "Epoch 917/2000\n",
            "75/75 - 0s - loss: 1.5011e-06 - accuracy: 1.0000 - val_loss: 2.7482 - val_accuracy: 0.7417\n",
            "Epoch 918/2000\n",
            "75/75 - 0s - loss: 1.4656e-06 - accuracy: 1.0000 - val_loss: 2.7476 - val_accuracy: 0.7417\n",
            "Epoch 919/2000\n",
            "75/75 - 0s - loss: 1.4390e-06 - accuracy: 1.0000 - val_loss: 2.7458 - val_accuracy: 0.7417\n",
            "Epoch 920/2000\n",
            "75/75 - 0s - loss: 1.4103e-06 - accuracy: 1.0000 - val_loss: 2.7465 - val_accuracy: 0.7417\n",
            "Epoch 921/2000\n",
            "75/75 - 0s - loss: 1.3740e-06 - accuracy: 1.0000 - val_loss: 2.7459 - val_accuracy: 0.7450\n",
            "Epoch 922/2000\n",
            "75/75 - 0s - loss: 1.3511e-06 - accuracy: 1.0000 - val_loss: 2.7453 - val_accuracy: 0.7433\n",
            "Epoch 923/2000\n",
            "75/75 - 0s - loss: 1.3249e-06 - accuracy: 1.0000 - val_loss: 2.7451 - val_accuracy: 0.7433\n",
            "Epoch 924/2000\n",
            "75/75 - 0s - loss: 1.2953e-06 - accuracy: 1.0000 - val_loss: 2.7445 - val_accuracy: 0.7450\n",
            "Epoch 925/2000\n",
            "75/75 - 0s - loss: 1.2671e-06 - accuracy: 1.0000 - val_loss: 2.7441 - val_accuracy: 0.7450\n",
            "Epoch 926/2000\n",
            "75/75 - 0s - loss: 1.2418e-06 - accuracy: 1.0000 - val_loss: 2.7419 - val_accuracy: 0.7450\n",
            "Epoch 927/2000\n",
            "75/75 - 0s - loss: 1.2157e-06 - accuracy: 1.0000 - val_loss: 2.7420 - val_accuracy: 0.7450\n",
            "Epoch 928/2000\n",
            "75/75 - 0s - loss: 1.1914e-06 - accuracy: 1.0000 - val_loss: 2.7402 - val_accuracy: 0.7467\n",
            "Epoch 929/2000\n",
            "75/75 - 0s - loss: 1.1677e-06 - accuracy: 1.0000 - val_loss: 2.7396 - val_accuracy: 0.7467\n",
            "Epoch 930/2000\n",
            "75/75 - 0s - loss: 1.1499e-06 - accuracy: 1.0000 - val_loss: 2.7411 - val_accuracy: 0.7467\n",
            "Epoch 931/2000\n",
            "75/75 - 0s - loss: 1.1237e-06 - accuracy: 1.0000 - val_loss: 2.7400 - val_accuracy: 0.7467\n",
            "Epoch 932/2000\n",
            "75/75 - 0s - loss: 1.0986e-06 - accuracy: 1.0000 - val_loss: 2.7391 - val_accuracy: 0.7467\n",
            "Epoch 933/2000\n",
            "75/75 - 0s - loss: 1.0802e-06 - accuracy: 1.0000 - val_loss: 2.7380 - val_accuracy: 0.7467\n",
            "Epoch 934/2000\n",
            "75/75 - 0s - loss: 1.0582e-06 - accuracy: 1.0000 - val_loss: 2.7365 - val_accuracy: 0.7483\n",
            "Epoch 935/2000\n",
            "75/75 - 0s - loss: 1.0375e-06 - accuracy: 1.0000 - val_loss: 2.7368 - val_accuracy: 0.7483\n",
            "Epoch 936/2000\n",
            "75/75 - 0s - loss: 1.0193e-06 - accuracy: 1.0000 - val_loss: 2.7352 - val_accuracy: 0.7483\n",
            "Epoch 937/2000\n",
            "75/75 - 0s - loss: 9.9640e-07 - accuracy: 1.0000 - val_loss: 2.7354 - val_accuracy: 0.7483\n",
            "Epoch 938/2000\n",
            "75/75 - 0s - loss: 9.7726e-07 - accuracy: 1.0000 - val_loss: 2.7340 - val_accuracy: 0.7483\n",
            "Epoch 939/2000\n",
            "75/75 - 0s - loss: 9.5666e-07 - accuracy: 1.0000 - val_loss: 2.7349 - val_accuracy: 0.7500\n",
            "Epoch 940/2000\n",
            "75/75 - 0s - loss: 9.4021e-07 - accuracy: 1.0000 - val_loss: 2.7331 - val_accuracy: 0.7500\n",
            "Epoch 941/2000\n",
            "75/75 - 0s - loss: 9.2116e-07 - accuracy: 1.0000 - val_loss: 2.7295 - val_accuracy: 0.7483\n",
            "Epoch 942/2000\n",
            "75/75 - 0s - loss: 9.0456e-07 - accuracy: 1.0000 - val_loss: 2.7313 - val_accuracy: 0.7500\n",
            "Epoch 943/2000\n",
            "75/75 - 0s - loss: 8.8614e-07 - accuracy: 1.0000 - val_loss: 2.7313 - val_accuracy: 0.7500\n",
            "Epoch 944/2000\n",
            "75/75 - 0s - loss: 8.6826e-07 - accuracy: 1.0000 - val_loss: 2.7306 - val_accuracy: 0.7500\n",
            "Epoch 945/2000\n",
            "75/75 - 0s - loss: 8.5139e-07 - accuracy: 1.0000 - val_loss: 2.7291 - val_accuracy: 0.7500\n",
            "Epoch 946/2000\n",
            "75/75 - 0s - loss: 8.3307e-07 - accuracy: 1.0000 - val_loss: 2.7279 - val_accuracy: 0.7500\n",
            "Epoch 947/2000\n",
            "75/75 - 0s - loss: 8.2408e-07 - accuracy: 1.0000 - val_loss: 2.7270 - val_accuracy: 0.7500\n",
            "Epoch 948/2000\n",
            "75/75 - 0s - loss: 8.0334e-07 - accuracy: 1.0000 - val_loss: 2.7262 - val_accuracy: 0.7500\n",
            "Epoch 949/2000\n",
            "75/75 - 0s - loss: 7.9158e-07 - accuracy: 1.0000 - val_loss: 2.7273 - val_accuracy: 0.7500\n",
            "Epoch 950/2000\n",
            "75/75 - 0s - loss: 7.7946e-07 - accuracy: 1.0000 - val_loss: 2.7243 - val_accuracy: 0.7500\n",
            "Epoch 951/2000\n",
            "75/75 - 0s - loss: 7.6405e-07 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.7500\n",
            "Epoch 952/2000\n",
            "75/75 - 0s - loss: 7.4423e-07 - accuracy: 1.0000 - val_loss: 2.7230 - val_accuracy: 0.7500\n",
            "Epoch 953/2000\n",
            "75/75 - 0s - loss: 7.3354e-07 - accuracy: 1.0000 - val_loss: 2.7260 - val_accuracy: 0.7500\n",
            "Epoch 954/2000\n",
            "75/75 - 0s - loss: 7.2466e-07 - accuracy: 1.0000 - val_loss: 2.7225 - val_accuracy: 0.7500\n",
            "Epoch 955/2000\n",
            "75/75 - 0s - loss: 7.0793e-07 - accuracy: 1.0000 - val_loss: 2.7197 - val_accuracy: 0.7500\n",
            "Epoch 956/2000\n",
            "75/75 - 0s - loss: 6.9278e-07 - accuracy: 1.0000 - val_loss: 2.7223 - val_accuracy: 0.7500\n",
            "Epoch 957/2000\n",
            "75/75 - 0s - loss: 6.7945e-07 - accuracy: 1.0000 - val_loss: 2.7212 - val_accuracy: 0.7500\n",
            "Epoch 958/2000\n",
            "75/75 - 0s - loss: 6.6601e-07 - accuracy: 1.0000 - val_loss: 2.7203 - val_accuracy: 0.7500\n",
            "Epoch 959/2000\n",
            "75/75 - 0s - loss: 6.5165e-07 - accuracy: 1.0000 - val_loss: 2.7208 - val_accuracy: 0.7500\n",
            "Epoch 960/2000\n",
            "75/75 - 0s - loss: 6.4122e-07 - accuracy: 1.0000 - val_loss: 2.7169 - val_accuracy: 0.7517\n",
            "Epoch 961/2000\n",
            "75/75 - 0s - loss: 6.2913e-07 - accuracy: 1.0000 - val_loss: 2.7182 - val_accuracy: 0.7500\n",
            "Epoch 962/2000\n",
            "75/75 - 0s - loss: 6.1686e-07 - accuracy: 1.0000 - val_loss: 2.7153 - val_accuracy: 0.7517\n",
            "Epoch 963/2000\n",
            "75/75 - 0s - loss: 6.0603e-07 - accuracy: 1.0000 - val_loss: 2.7193 - val_accuracy: 0.7500\n",
            "Epoch 964/2000\n",
            "75/75 - 0s - loss: 5.9890e-07 - accuracy: 1.0000 - val_loss: 2.7156 - val_accuracy: 0.7517\n",
            "Epoch 965/2000\n",
            "75/75 - 0s - loss: 5.8474e-07 - accuracy: 1.0000 - val_loss: 2.7144 - val_accuracy: 0.7500\n",
            "Epoch 966/2000\n",
            "75/75 - 0s - loss: 5.7543e-07 - accuracy: 1.0000 - val_loss: 2.7149 - val_accuracy: 0.7517\n",
            "Epoch 967/2000\n",
            "75/75 - 0s - loss: 5.6918e-07 - accuracy: 1.0000 - val_loss: 2.7136 - val_accuracy: 0.7500\n",
            "Epoch 968/2000\n",
            "75/75 - 0s - loss: 5.5369e-07 - accuracy: 1.0000 - val_loss: 2.7115 - val_accuracy: 0.7483\n",
            "Epoch 969/2000\n",
            "75/75 - 0s - loss: 5.4121e-07 - accuracy: 1.0000 - val_loss: 2.7168 - val_accuracy: 0.7467\n",
            "Epoch 970/2000\n",
            "75/75 - 0s - loss: 5.3621e-07 - accuracy: 1.0000 - val_loss: 2.7125 - val_accuracy: 0.7483\n",
            "Epoch 971/2000\n",
            "75/75 - 0s - loss: 5.2308e-07 - accuracy: 1.0000 - val_loss: 2.7086 - val_accuracy: 0.7483\n",
            "Epoch 972/2000\n",
            "75/75 - 0s - loss: 5.1166e-07 - accuracy: 1.0000 - val_loss: 2.7076 - val_accuracy: 0.7483\n",
            "Epoch 973/2000\n",
            "75/75 - 0s - loss: 5.0454e-07 - accuracy: 1.0000 - val_loss: 2.7099 - val_accuracy: 0.7483\n",
            "Epoch 974/2000\n",
            "75/75 - 0s - loss: 4.9108e-07 - accuracy: 1.0000 - val_loss: 2.7139 - val_accuracy: 0.7483\n",
            "Epoch 975/2000\n",
            "75/75 - 0s - loss: 4.7956e-07 - accuracy: 1.0000 - val_loss: 2.7024 - val_accuracy: 0.7483\n",
            "Epoch 976/2000\n",
            "75/75 - 0s - loss: 4.7946e-07 - accuracy: 1.0000 - val_loss: 2.7048 - val_accuracy: 0.7483\n",
            "Epoch 977/2000\n",
            "75/75 - 0s - loss: 4.6110e-07 - accuracy: 1.0000 - val_loss: 2.7013 - val_accuracy: 0.7450\n",
            "Epoch 978/2000\n",
            "75/75 - 0s - loss: 4.5815e-07 - accuracy: 1.0000 - val_loss: 2.7071 - val_accuracy: 0.7483\n",
            "Epoch 979/2000\n",
            "75/75 - 0s - loss: 4.4762e-07 - accuracy: 1.0000 - val_loss: 2.7018 - val_accuracy: 0.7500\n",
            "Epoch 980/2000\n",
            "75/75 - 0s - loss: 4.3865e-07 - accuracy: 1.0000 - val_loss: 2.7052 - val_accuracy: 0.7483\n",
            "Epoch 981/2000\n",
            "75/75 - 0s - loss: 4.3312e-07 - accuracy: 1.0000 - val_loss: 2.7049 - val_accuracy: 0.7483\n",
            "Epoch 982/2000\n",
            "75/75 - 0s - loss: 4.2670e-07 - accuracy: 1.0000 - val_loss: 2.7076 - val_accuracy: 0.7500\n",
            "Epoch 983/2000\n",
            "75/75 - 0s - loss: 4.1269e-07 - accuracy: 1.0000 - val_loss: 2.7024 - val_accuracy: 0.7500\n",
            "Epoch 984/2000\n",
            "75/75 - 0s - loss: 4.1035e-07 - accuracy: 1.0000 - val_loss: 2.7056 - val_accuracy: 0.7483\n",
            "Epoch 985/2000\n",
            "75/75 - 0s - loss: 4.0210e-07 - accuracy: 1.0000 - val_loss: 2.7038 - val_accuracy: 0.7500\n",
            "Epoch 986/2000\n",
            "75/75 - 0s - loss: 3.8974e-07 - accuracy: 1.0000 - val_loss: 2.6995 - val_accuracy: 0.7517\n",
            "Epoch 987/2000\n",
            "75/75 - 0s - loss: 3.8865e-07 - accuracy: 1.0000 - val_loss: 2.7055 - val_accuracy: 0.7483\n",
            "Epoch 988/2000\n",
            "75/75 - 0s - loss: 3.8241e-07 - accuracy: 1.0000 - val_loss: 2.7038 - val_accuracy: 0.7500\n",
            "Epoch 989/2000\n",
            "75/75 - 0s - loss: 3.7598e-07 - accuracy: 1.0000 - val_loss: 2.7003 - val_accuracy: 0.7500\n",
            "Epoch 990/2000\n",
            "75/75 - 0s - loss: 3.6585e-07 - accuracy: 1.0000 - val_loss: 2.7049 - val_accuracy: 0.7500\n",
            "Epoch 991/2000\n",
            "75/75 - 0s - loss: 3.5768e-07 - accuracy: 1.0000 - val_loss: 2.6971 - val_accuracy: 0.7517\n",
            "Epoch 992/2000\n",
            "75/75 - 0s - loss: 3.5397e-07 - accuracy: 1.0000 - val_loss: 2.6933 - val_accuracy: 0.7483\n",
            "Epoch 993/2000\n",
            "75/75 - 0s - loss: 3.5034e-07 - accuracy: 1.0000 - val_loss: 2.7009 - val_accuracy: 0.7517\n",
            "Epoch 994/2000\n",
            "75/75 - 0s - loss: 3.4115e-07 - accuracy: 1.0000 - val_loss: 2.7031 - val_accuracy: 0.7517\n",
            "Epoch 995/2000\n",
            "75/75 - 0s - loss: 3.3323e-07 - accuracy: 1.0000 - val_loss: 2.6920 - val_accuracy: 0.7483\n",
            "Epoch 996/2000\n",
            "75/75 - 0s - loss: 3.3083e-07 - accuracy: 1.0000 - val_loss: 2.7007 - val_accuracy: 0.7517\n",
            "Epoch 997/2000\n",
            "75/75 - 0s - loss: 3.2160e-07 - accuracy: 1.0000 - val_loss: 2.6977 - val_accuracy: 0.7517\n",
            "Epoch 998/2000\n",
            "75/75 - 0s - loss: 3.1531e-07 - accuracy: 1.0000 - val_loss: 2.6972 - val_accuracy: 0.7533\n",
            "Epoch 999/2000\n",
            "75/75 - 0s - loss: 3.0983e-07 - accuracy: 1.0000 - val_loss: 2.6981 - val_accuracy: 0.7517\n",
            "Epoch 1000/2000\n",
            "75/75 - 0s - loss: 3.0720e-07 - accuracy: 1.0000 - val_loss: 2.6939 - val_accuracy: 0.7500\n",
            "Epoch 1001/2000\n",
            "75/75 - 0s - loss: 3.0062e-07 - accuracy: 1.0000 - val_loss: 2.7006 - val_accuracy: 0.7533\n",
            "Epoch 1002/2000\n",
            "75/75 - 0s - loss: 2.9590e-07 - accuracy: 1.0000 - val_loss: 2.7004 - val_accuracy: 0.7533\n",
            "Epoch 1003/2000\n",
            "75/75 - 0s - loss: 2.9031e-07 - accuracy: 1.0000 - val_loss: 2.6977 - val_accuracy: 0.7533\n",
            "Epoch 1004/2000\n",
            "75/75 - 0s - loss: 2.8496e-07 - accuracy: 1.0000 - val_loss: 2.6949 - val_accuracy: 0.7550\n",
            "Epoch 1005/2000\n",
            "75/75 - 0s - loss: 2.8597e-07 - accuracy: 1.0000 - val_loss: 2.6928 - val_accuracy: 0.7533\n",
            "Epoch 1006/2000\n",
            "75/75 - 0s - loss: 2.7731e-07 - accuracy: 1.0000 - val_loss: 2.6960 - val_accuracy: 0.7550\n",
            "Epoch 1007/2000\n",
            "75/75 - 0s - loss: 2.7078e-07 - accuracy: 1.0000 - val_loss: 2.7029 - val_accuracy: 0.7533\n",
            "Epoch 1008/2000\n",
            "75/75 - 0s - loss: 2.6707e-07 - accuracy: 1.0000 - val_loss: 2.7051 - val_accuracy: 0.7517\n",
            "Epoch 1009/2000\n",
            "75/75 - 0s - loss: 2.6153e-07 - accuracy: 1.0000 - val_loss: 2.6912 - val_accuracy: 0.7567\n",
            "Epoch 1010/2000\n",
            "75/75 - 0s - loss: 2.5678e-07 - accuracy: 1.0000 - val_loss: 2.6924 - val_accuracy: 0.7550\n",
            "Epoch 1011/2000\n",
            "75/75 - 0s - loss: 2.5257e-07 - accuracy: 1.0000 - val_loss: 2.6914 - val_accuracy: 0.7550\n",
            "Epoch 1012/2000\n",
            "75/75 - 0s - loss: 2.4823e-07 - accuracy: 1.0000 - val_loss: 2.6967 - val_accuracy: 0.7550\n",
            "Epoch 1013/2000\n",
            "75/75 - 0s - loss: 2.4278e-07 - accuracy: 1.0000 - val_loss: 2.6948 - val_accuracy: 0.7567\n",
            "Epoch 1014/2000\n",
            "75/75 - 0s - loss: 2.3884e-07 - accuracy: 1.0000 - val_loss: 2.7014 - val_accuracy: 0.7550\n",
            "Epoch 1015/2000\n",
            "75/75 - 0s - loss: 2.3788e-07 - accuracy: 1.0000 - val_loss: 2.6937 - val_accuracy: 0.7567\n",
            "Epoch 1016/2000\n",
            "75/75 - 0s - loss: 2.2988e-07 - accuracy: 1.0000 - val_loss: 2.6948 - val_accuracy: 0.7550\n",
            "Epoch 1017/2000\n",
            "75/75 - 0s - loss: 2.2927e-07 - accuracy: 1.0000 - val_loss: 2.7039 - val_accuracy: 0.7517\n",
            "Epoch 1018/2000\n",
            "75/75 - 0s - loss: 2.2942e-07 - accuracy: 1.0000 - val_loss: 2.6879 - val_accuracy: 0.7533\n",
            "Epoch 1019/2000\n",
            "75/75 - 0s - loss: 2.2015e-07 - accuracy: 1.0000 - val_loss: 2.6964 - val_accuracy: 0.7567\n",
            "Epoch 1020/2000\n",
            "75/75 - 0s - loss: 2.1430e-07 - accuracy: 1.0000 - val_loss: 2.6908 - val_accuracy: 0.7533\n",
            "Epoch 1021/2000\n",
            "75/75 - 0s - loss: 2.1320e-07 - accuracy: 1.0000 - val_loss: 2.6983 - val_accuracy: 0.7550\n",
            "Epoch 1022/2000\n",
            "75/75 - 0s - loss: 2.0723e-07 - accuracy: 1.0000 - val_loss: 2.6953 - val_accuracy: 0.7567\n",
            "Epoch 1023/2000\n",
            "75/75 - 0s - loss: 2.0688e-07 - accuracy: 1.0000 - val_loss: 2.7066 - val_accuracy: 0.7533\n",
            "Epoch 1024/2000\n",
            "75/75 - 0s - loss: 2.0381e-07 - accuracy: 1.0000 - val_loss: 2.6925 - val_accuracy: 0.7550\n",
            "Epoch 1025/2000\n",
            "75/75 - 0s - loss: 1.9730e-07 - accuracy: 1.0000 - val_loss: 2.6973 - val_accuracy: 0.7550\n",
            "Epoch 1026/2000\n",
            "75/75 - 0s - loss: 1.9604e-07 - accuracy: 1.0000 - val_loss: 2.6956 - val_accuracy: 0.7567\n",
            "Epoch 1027/2000\n",
            "75/75 - 0s - loss: 1.8974e-07 - accuracy: 1.0000 - val_loss: 2.6946 - val_accuracy: 0.7533\n",
            "Epoch 1028/2000\n",
            "75/75 - 0s - loss: 1.9174e-07 - accuracy: 1.0000 - val_loss: 2.6976 - val_accuracy: 0.7533\n",
            "Epoch 1029/2000\n",
            "75/75 - 0s - loss: 1.8423e-07 - accuracy: 1.0000 - val_loss: 2.6987 - val_accuracy: 0.7533\n",
            "Epoch 1030/2000\n",
            "75/75 - 0s - loss: 1.8362e-07 - accuracy: 1.0000 - val_loss: 2.7043 - val_accuracy: 0.7517\n",
            "Epoch 1031/2000\n",
            "75/75 - 0s - loss: 1.7744e-07 - accuracy: 1.0000 - val_loss: 2.7095 - val_accuracy: 0.7533\n",
            "Epoch 1032/2000\n",
            "75/75 - 0s - loss: 1.7812e-07 - accuracy: 1.0000 - val_loss: 2.7024 - val_accuracy: 0.7533\n",
            "Epoch 1033/2000\n",
            "75/75 - 0s - loss: 1.6883e-07 - accuracy: 1.0000 - val_loss: 2.6957 - val_accuracy: 0.7517\n",
            "Epoch 1034/2000\n",
            "75/75 - 0s - loss: 1.6461e-07 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.7533\n",
            "Epoch 1035/2000\n",
            "75/75 - 0s - loss: 1.6656e-07 - accuracy: 1.0000 - val_loss: 2.6993 - val_accuracy: 0.7533\n",
            "Epoch 1036/2000\n",
            "75/75 - 0s - loss: 1.6435e-07 - accuracy: 1.0000 - val_loss: 2.7066 - val_accuracy: 0.7533\n",
            "Epoch 1037/2000\n",
            "75/75 - 0s - loss: 1.5872e-07 - accuracy: 1.0000 - val_loss: 2.6986 - val_accuracy: 0.7533\n",
            "Epoch 1038/2000\n",
            "75/75 - 0s - loss: 1.5777e-07 - accuracy: 1.0000 - val_loss: 2.7047 - val_accuracy: 0.7533\n",
            "Epoch 1039/2000\n",
            "75/75 - 0s - loss: 1.5479e-07 - accuracy: 1.0000 - val_loss: 2.7028 - val_accuracy: 0.7533\n",
            "Epoch 1040/2000\n",
            "75/75 - 0s - loss: 1.5181e-07 - accuracy: 1.0000 - val_loss: 2.6993 - val_accuracy: 0.7517\n",
            "Epoch 1041/2000\n",
            "75/75 - 0s - loss: 1.4768e-07 - accuracy: 1.0000 - val_loss: 2.7022 - val_accuracy: 0.7533\n",
            "Epoch 1042/2000\n",
            "75/75 - 0s - loss: 1.4571e-07 - accuracy: 1.0000 - val_loss: 2.6922 - val_accuracy: 0.7550\n",
            "Epoch 1043/2000\n",
            "75/75 - 0s - loss: 1.4530e-07 - accuracy: 1.0000 - val_loss: 2.7117 - val_accuracy: 0.7533\n",
            "Epoch 1044/2000\n",
            "75/75 - 0s - loss: 1.3868e-07 - accuracy: 1.0000 - val_loss: 2.7002 - val_accuracy: 0.7550\n",
            "Epoch 1045/2000\n",
            "75/75 - 0s - loss: 1.3577e-07 - accuracy: 1.0000 - val_loss: 2.7074 - val_accuracy: 0.7550\n",
            "Epoch 1046/2000\n",
            "75/75 - 0s - loss: 1.3098e-07 - accuracy: 1.0000 - val_loss: 2.7047 - val_accuracy: 0.7533\n",
            "Epoch 1047/2000\n",
            "75/75 - 0s - loss: 1.3048e-07 - accuracy: 1.0000 - val_loss: 2.7106 - val_accuracy: 0.7517\n",
            "Epoch 1048/2000\n",
            "75/75 - 0s - loss: 1.2743e-07 - accuracy: 1.0000 - val_loss: 2.7068 - val_accuracy: 0.7517\n",
            "Epoch 1049/2000\n",
            "75/75 - 0s - loss: 1.2130e-07 - accuracy: 1.0000 - val_loss: 2.7111 - val_accuracy: 0.7533\n",
            "Epoch 1050/2000\n",
            "75/75 - 0s - loss: 1.2251e-07 - accuracy: 1.0000 - val_loss: 2.7182 - val_accuracy: 0.7533\n",
            "Epoch 1051/2000\n",
            "75/75 - 0s - loss: 1.1796e-07 - accuracy: 1.0000 - val_loss: 2.7092 - val_accuracy: 0.7517\n",
            "Epoch 1052/2000\n",
            "75/75 - 0s - loss: 1.1705e-07 - accuracy: 1.0000 - val_loss: 2.7034 - val_accuracy: 0.7517\n",
            "Epoch 1053/2000\n",
            "75/75 - 0s - loss: 1.0889e-07 - accuracy: 1.0000 - val_loss: 2.7137 - val_accuracy: 0.7533\n",
            "Epoch 1054/2000\n",
            "75/75 - 0s - loss: 1.0869e-07 - accuracy: 1.0000 - val_loss: 2.7257 - val_accuracy: 0.7500\n",
            "Epoch 1055/2000\n",
            "75/75 - 0s - loss: 1.0829e-07 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.7517\n",
            "Epoch 1056/2000\n",
            "75/75 - 0s - loss: 1.0901e-07 - accuracy: 1.0000 - val_loss: 2.7289 - val_accuracy: 0.7483\n",
            "Epoch 1057/2000\n",
            "75/75 - 0s - loss: 1.1007e-07 - accuracy: 1.0000 - val_loss: 2.7156 - val_accuracy: 0.7467\n",
            "Epoch 1058/2000\n",
            "75/75 - 0s - loss: 1.0515e-07 - accuracy: 1.0000 - val_loss: 2.7051 - val_accuracy: 0.7533\n",
            "Epoch 1059/2000\n",
            "75/75 - 0s - loss: 1.0472e-07 - accuracy: 1.0000 - val_loss: 2.7141 - val_accuracy: 0.7517\n",
            "Epoch 1060/2000\n",
            "75/75 - 0s - loss: 9.4014e-08 - accuracy: 1.0000 - val_loss: 2.7020 - val_accuracy: 0.7533\n",
            "Epoch 1061/2000\n",
            "75/75 - 0s - loss: 9.7094e-08 - accuracy: 1.0000 - val_loss: 2.7141 - val_accuracy: 0.7533\n",
            "Epoch 1062/2000\n",
            "75/75 - 0s - loss: 1.0473e-07 - accuracy: 1.0000 - val_loss: 2.7172 - val_accuracy: 0.7533\n",
            "Epoch 1063/2000\n",
            "75/75 - 0s - loss: 9.0934e-08 - accuracy: 1.0000 - val_loss: 2.7298 - val_accuracy: 0.7483\n",
            "Epoch 1064/2000\n",
            "75/75 - 0s - loss: 8.8016e-08 - accuracy: 1.0000 - val_loss: 2.7096 - val_accuracy: 0.7550\n",
            "Epoch 1065/2000\n",
            "75/75 - 0s - loss: 8.5086e-08 - accuracy: 1.0000 - val_loss: 2.7213 - val_accuracy: 0.7533\n",
            "Epoch 1066/2000\n",
            "75/75 - 0s - loss: 8.8389e-08 - accuracy: 1.0000 - val_loss: 2.7050 - val_accuracy: 0.7517\n",
            "Epoch 1067/2000\n",
            "75/75 - 0s - loss: 8.3918e-08 - accuracy: 1.0000 - val_loss: 2.7166 - val_accuracy: 0.7517\n",
            "Epoch 1068/2000\n",
            "75/75 - 0s - loss: 8.6141e-08 - accuracy: 1.0000 - val_loss: 2.7272 - val_accuracy: 0.7517\n",
            "Epoch 1069/2000\n",
            "75/75 - 0s - loss: 7.8244e-08 - accuracy: 1.0000 - val_loss: 2.7050 - val_accuracy: 0.7517\n",
            "Epoch 1070/2000\n",
            "75/75 - 0s - loss: 7.2618e-08 - accuracy: 1.0000 - val_loss: 2.7277 - val_accuracy: 0.7500\n",
            "Epoch 1071/2000\n",
            "75/75 - 0s - loss: 7.1228e-08 - accuracy: 1.0000 - val_loss: 2.7349 - val_accuracy: 0.7500\n",
            "Epoch 1072/2000\n",
            "75/75 - 0s - loss: 7.2693e-08 - accuracy: 1.0000 - val_loss: 2.7332 - val_accuracy: 0.7500\n",
            "Epoch 1073/2000\n",
            "75/75 - 0s - loss: 6.5962e-08 - accuracy: 1.0000 - val_loss: 2.7399 - val_accuracy: 0.7500\n",
            "Epoch 1074/2000\n",
            "75/75 - 0s - loss: 6.4857e-08 - accuracy: 1.0000 - val_loss: 2.7305 - val_accuracy: 0.7500\n",
            "Epoch 1075/2000\n",
            "75/75 - 0s - loss: 6.2101e-08 - accuracy: 1.0000 - val_loss: 2.7325 - val_accuracy: 0.7500\n",
            "Epoch 1076/2000\n",
            "75/75 - 0s - loss: 6.0139e-08 - accuracy: 1.0000 - val_loss: 2.7343 - val_accuracy: 0.7467\n",
            "Epoch 1077/2000\n",
            "75/75 - 0s - loss: 6.1554e-08 - accuracy: 1.0000 - val_loss: 2.7169 - val_accuracy: 0.7533\n",
            "Epoch 1078/2000\n",
            "75/75 - 0s - loss: 5.9940e-08 - accuracy: 1.0000 - val_loss: 2.7319 - val_accuracy: 0.7517\n",
            "Epoch 1079/2000\n",
            "75/75 - 0s - loss: 5.4973e-08 - accuracy: 1.0000 - val_loss: 2.7277 - val_accuracy: 0.7483\n",
            "Epoch 1080/2000\n",
            "75/75 - 0s - loss: 5.3694e-08 - accuracy: 1.0000 - val_loss: 2.7298 - val_accuracy: 0.7517\n",
            "Epoch 1081/2000\n",
            "75/75 - 0s - loss: 5.3657e-08 - accuracy: 1.0000 - val_loss: 2.7318 - val_accuracy: 0.7467\n",
            "Epoch 1082/2000\n",
            "75/75 - 0s - loss: 5.0366e-08 - accuracy: 1.0000 - val_loss: 2.7320 - val_accuracy: 0.7533\n",
            "Epoch 1083/2000\n",
            "75/75 - 0s - loss: 5.0068e-08 - accuracy: 1.0000 - val_loss: 2.7150 - val_accuracy: 0.7483\n",
            "Epoch 1084/2000\n",
            "75/75 - 0s - loss: 4.7572e-08 - accuracy: 1.0000 - val_loss: 2.7377 - val_accuracy: 0.7483\n",
            "Epoch 1085/2000\n",
            "75/75 - 0s - loss: 4.5349e-08 - accuracy: 1.0000 - val_loss: 2.7369 - val_accuracy: 0.7517\n",
            "Epoch 1086/2000\n",
            "75/75 - 0s - loss: 4.7460e-08 - accuracy: 1.0000 - val_loss: 2.7421 - val_accuracy: 0.7517\n",
            "Epoch 1087/2000\n",
            "75/75 - 0s - loss: 4.3996e-08 - accuracy: 1.0000 - val_loss: 2.7276 - val_accuracy: 0.7517\n",
            "Epoch 1088/2000\n",
            "75/75 - 0s - loss: 4.4145e-08 - accuracy: 1.0000 - val_loss: 2.7452 - val_accuracy: 0.7517\n",
            "Epoch 1089/2000\n",
            "75/75 - 0s - loss: 4.1562e-08 - accuracy: 1.0000 - val_loss: 2.7442 - val_accuracy: 0.7517\n",
            "Epoch 1090/2000\n",
            "75/75 - 0s - loss: 3.8656e-08 - accuracy: 1.0000 - val_loss: 2.7347 - val_accuracy: 0.7500\n",
            "Epoch 1091/2000\n",
            "75/75 - 0s - loss: 3.7079e-08 - accuracy: 1.0000 - val_loss: 2.7431 - val_accuracy: 0.7500\n",
            "Epoch 1092/2000\n",
            "75/75 - 0s - loss: 3.6458e-08 - accuracy: 1.0000 - val_loss: 2.7375 - val_accuracy: 0.7517\n",
            "Epoch 1093/2000\n",
            "75/75 - 0s - loss: 3.3453e-08 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.7500\n",
            "Epoch 1094/2000\n",
            "75/75 - 0s - loss: 3.4161e-08 - accuracy: 1.0000 - val_loss: 2.7323 - val_accuracy: 0.7517\n",
            "Epoch 1095/2000\n",
            "75/75 - 0s - loss: 3.3838e-08 - accuracy: 1.0000 - val_loss: 2.7377 - val_accuracy: 0.7500\n",
            "Epoch 1096/2000\n",
            "75/75 - 0s - loss: 3.2348e-08 - accuracy: 1.0000 - val_loss: 2.7394 - val_accuracy: 0.7517\n",
            "Epoch 1097/2000\n",
            "75/75 - 0s - loss: 3.3664e-08 - accuracy: 1.0000 - val_loss: 2.7413 - val_accuracy: 0.7550\n",
            "Epoch 1098/2000\n",
            "75/75 - 0s - loss: 2.9405e-08 - accuracy: 1.0000 - val_loss: 2.7410 - val_accuracy: 0.7517\n",
            "Epoch 1099/2000\n",
            "75/75 - 0s - loss: 2.8039e-08 - accuracy: 1.0000 - val_loss: 2.7539 - val_accuracy: 0.7500\n",
            "Epoch 1100/2000\n",
            "75/75 - 0s - loss: 2.7878e-08 - accuracy: 1.0000 - val_loss: 2.7737 - val_accuracy: 0.7483\n",
            "Epoch 1101/2000\n",
            "75/75 - 0s - loss: 2.8089e-08 - accuracy: 1.0000 - val_loss: 2.7574 - val_accuracy: 0.7500\n",
            "Epoch 1102/2000\n",
            "75/75 - 0s - loss: 2.6363e-08 - accuracy: 1.0000 - val_loss: 2.7532 - val_accuracy: 0.7483\n",
            "Epoch 1103/2000\n",
            "75/75 - 0s - loss: 2.5767e-08 - accuracy: 1.0000 - val_loss: 2.7542 - val_accuracy: 0.7533\n",
            "Epoch 1104/2000\n",
            "75/75 - 0s - loss: 2.5369e-08 - accuracy: 1.0000 - val_loss: 2.7514 - val_accuracy: 0.7517\n",
            "Epoch 1105/2000\n",
            "75/75 - 0s - loss: 2.2985e-08 - accuracy: 1.0000 - val_loss: 2.7642 - val_accuracy: 0.7500\n",
            "Epoch 1106/2000\n",
            "75/75 - 0s - loss: 2.2252e-08 - accuracy: 1.0000 - val_loss: 2.7569 - val_accuracy: 0.7500\n",
            "Epoch 1107/2000\n",
            "75/75 - 0s - loss: 2.1346e-08 - accuracy: 1.0000 - val_loss: 2.7586 - val_accuracy: 0.7483\n",
            "Epoch 1108/2000\n",
            "75/75 - 0s - loss: 2.0104e-08 - accuracy: 1.0000 - val_loss: 2.7593 - val_accuracy: 0.7500\n",
            "Epoch 1109/2000\n",
            "75/75 - 0s - loss: 1.8664e-08 - accuracy: 1.0000 - val_loss: 2.7609 - val_accuracy: 0.7500\n",
            "Epoch 1110/2000\n",
            "75/75 - 0s - loss: 1.8962e-08 - accuracy: 1.0000 - val_loss: 2.7551 - val_accuracy: 0.7500\n",
            "Epoch 1111/2000\n",
            "75/75 - 0s - loss: 1.7943e-08 - accuracy: 1.0000 - val_loss: 2.7744 - val_accuracy: 0.7467\n",
            "Epoch 1112/2000\n",
            "75/75 - 0s - loss: 1.7745e-08 - accuracy: 1.0000 - val_loss: 2.7493 - val_accuracy: 0.7517\n",
            "Epoch 1113/2000\n",
            "75/75 - 0s - loss: 1.8142e-08 - accuracy: 1.0000 - val_loss: 2.7703 - val_accuracy: 0.7517\n",
            "Epoch 1114/2000\n",
            "75/75 - 0s - loss: 1.7385e-08 - accuracy: 1.0000 - val_loss: 2.7649 - val_accuracy: 0.7500\n",
            "Epoch 1115/2000\n",
            "75/75 - 0s - loss: 1.5770e-08 - accuracy: 1.0000 - val_loss: 2.7645 - val_accuracy: 0.7483\n",
            "Epoch 1116/2000\n",
            "75/75 - 0s - loss: 1.5820e-08 - accuracy: 1.0000 - val_loss: 2.7674 - val_accuracy: 0.7500\n",
            "Epoch 1117/2000\n",
            "75/75 - 0s - loss: 1.3995e-08 - accuracy: 1.0000 - val_loss: 2.7680 - val_accuracy: 0.7500\n",
            "Epoch 1118/2000\n",
            "75/75 - 0s - loss: 1.4429e-08 - accuracy: 1.0000 - val_loss: 2.7648 - val_accuracy: 0.7517\n",
            "Epoch 1119/2000\n",
            "75/75 - 0s - loss: 1.2641e-08 - accuracy: 1.0000 - val_loss: 2.7740 - val_accuracy: 0.7500\n",
            "Epoch 1120/2000\n",
            "75/75 - 0s - loss: 1.4069e-08 - accuracy: 1.0000 - val_loss: 2.7783 - val_accuracy: 0.7467\n",
            "Epoch 1121/2000\n",
            "75/75 - 0s - loss: 1.2343e-08 - accuracy: 1.0000 - val_loss: 2.7666 - val_accuracy: 0.7483\n",
            "Epoch 1122/2000\n",
            "75/75 - 0s - loss: 1.1697e-08 - accuracy: 1.0000 - val_loss: 2.7671 - val_accuracy: 0.7483\n",
            "Epoch 1123/2000\n",
            "75/75 - 0s - loss: 1.1536e-08 - accuracy: 1.0000 - val_loss: 2.7712 - val_accuracy: 0.7500\n",
            "Epoch 1124/2000\n",
            "75/75 - 0s - loss: 1.1226e-08 - accuracy: 1.0000 - val_loss: 2.7737 - val_accuracy: 0.7467\n",
            "Epoch 1125/2000\n",
            "75/75 - 0s - loss: 9.5243e-09 - accuracy: 1.0000 - val_loss: 2.7731 - val_accuracy: 0.7483\n",
            "Epoch 1126/2000\n",
            "75/75 - 0s - loss: 9.7106e-09 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.7500\n",
            "Epoch 1127/2000\n",
            "75/75 - 0s - loss: 9.8223e-09 - accuracy: 1.0000 - val_loss: 2.7837 - val_accuracy: 0.7483\n",
            "Epoch 1128/2000\n",
            "75/75 - 0s - loss: 9.1145e-09 - accuracy: 1.0000 - val_loss: 2.7847 - val_accuracy: 0.7467\n",
            "Epoch 1129/2000\n",
            "75/75 - 0s - loss: 9.5492e-09 - accuracy: 1.0000 - val_loss: 2.7800 - val_accuracy: 0.7500\n",
            "Epoch 1130/2000\n",
            "75/75 - 0s - loss: 8.5185e-09 - accuracy: 1.0000 - val_loss: 2.7821 - val_accuracy: 0.7467\n",
            "Epoch 1131/2000\n",
            "75/75 - 0s - loss: 8.3695e-09 - accuracy: 1.0000 - val_loss: 2.7792 - val_accuracy: 0.7483\n",
            "Epoch 1132/2000\n",
            "75/75 - 0s - loss: 8.4067e-09 - accuracy: 1.0000 - val_loss: 2.7810 - val_accuracy: 0.7467\n",
            "Epoch 1133/2000\n",
            "75/75 - 0s - loss: 6.9911e-09 - accuracy: 1.0000 - val_loss: 2.7805 - val_accuracy: 0.7467\n",
            "Epoch 1134/2000\n",
            "75/75 - 0s - loss: 7.3388e-09 - accuracy: 1.0000 - val_loss: 2.7837 - val_accuracy: 0.7467\n",
            "Epoch 1135/2000\n",
            "75/75 - 0s - loss: 7.6617e-09 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.7467\n",
            "Epoch 1136/2000\n",
            "75/75 - 0s - loss: 7.3140e-09 - accuracy: 1.0000 - val_loss: 2.7823 - val_accuracy: 0.7467\n",
            "Epoch 1137/2000\n",
            "75/75 - 0s - loss: 6.0226e-09 - accuracy: 1.0000 - val_loss: 2.7785 - val_accuracy: 0.7467\n",
            "Epoch 1138/2000\n",
            "75/75 - 0s - loss: 6.1716e-09 - accuracy: 1.0000 - val_loss: 2.7779 - val_accuracy: 0.7467\n",
            "Epoch 1139/2000\n",
            "75/75 - 0s - loss: 5.4886e-09 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.7483\n",
            "Epoch 1140/2000\n",
            "75/75 - 0s - loss: 5.4638e-09 - accuracy: 1.0000 - val_loss: 2.7846 - val_accuracy: 0.7467\n",
            "Epoch 1141/2000\n",
            "75/75 - 0s - loss: 5.4141e-09 - accuracy: 1.0000 - val_loss: 2.7886 - val_accuracy: 0.7450\n",
            "Epoch 1142/2000\n",
            "75/75 - 0s - loss: 5.1533e-09 - accuracy: 1.0000 - val_loss: 2.7890 - val_accuracy: 0.7467\n",
            "Epoch 1143/2000\n",
            "75/75 - 0s - loss: 4.6939e-09 - accuracy: 1.0000 - val_loss: 2.7904 - val_accuracy: 0.7467\n",
            "Epoch 1144/2000\n",
            "75/75 - 0s - loss: 4.9919e-09 - accuracy: 1.0000 - val_loss: 2.7984 - val_accuracy: 0.7450\n",
            "Epoch 1145/2000\n",
            "75/75 - 0s - loss: 4.2468e-09 - accuracy: 1.0000 - val_loss: 2.7853 - val_accuracy: 0.7483\n",
            "Epoch 1146/2000\n",
            "75/75 - 0s - loss: 4.1475e-09 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.7467\n",
            "Epoch 1147/2000\n",
            "75/75 - 0s - loss: 3.9364e-09 - accuracy: 1.0000 - val_loss: 2.7941 - val_accuracy: 0.7467\n",
            "Epoch 1148/2000\n",
            "75/75 - 0s - loss: 3.7750e-09 - accuracy: 1.0000 - val_loss: 2.7955 - val_accuracy: 0.7483\n",
            "Epoch 1149/2000\n",
            "75/75 - 0s - loss: 3.8991e-09 - accuracy: 1.0000 - val_loss: 2.7916 - val_accuracy: 0.7467\n",
            "Epoch 1150/2000\n",
            "75/75 - 0s - loss: 3.6508e-09 - accuracy: 1.0000 - val_loss: 2.7902 - val_accuracy: 0.7467\n",
            "Epoch 1151/2000\n",
            "75/75 - 0s - loss: 3.3528e-09 - accuracy: 1.0000 - val_loss: 2.7988 - val_accuracy: 0.7467\n",
            "Epoch 1152/2000\n",
            "75/75 - 0s - loss: 3.0672e-09 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.7467\n",
            "Epoch 1153/2000\n",
            "75/75 - 0s - loss: 2.9678e-09 - accuracy: 1.0000 - val_loss: 2.7974 - val_accuracy: 0.7467\n",
            "Epoch 1154/2000\n",
            "75/75 - 0s - loss: 2.9802e-09 - accuracy: 1.0000 - val_loss: 2.7997 - val_accuracy: 0.7467\n",
            "Epoch 1155/2000\n",
            "75/75 - 0s - loss: 2.5829e-09 - accuracy: 1.0000 - val_loss: 2.7949 - val_accuracy: 0.7467\n",
            "Epoch 1156/2000\n",
            "75/75 - 0s - loss: 2.7070e-09 - accuracy: 1.0000 - val_loss: 2.8003 - val_accuracy: 0.7450\n",
            "Epoch 1157/2000\n",
            "75/75 - 0s - loss: 2.4463e-09 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.7450\n",
            "Epoch 1158/2000\n",
            "75/75 - 0s - loss: 2.4587e-09 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.7467\n",
            "Epoch 1159/2000\n",
            "75/75 - 0s - loss: 2.6325e-09 - accuracy: 1.0000 - val_loss: 2.7983 - val_accuracy: 0.7467\n",
            "Epoch 1160/2000\n",
            "75/75 - 0s - loss: 2.0365e-09 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.7467\n",
            "Epoch 1161/2000\n",
            "75/75 - 0s - loss: 1.8875e-09 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.7467\n",
            "Epoch 1162/2000\n",
            "75/75 - 0s - loss: 2.0365e-09 - accuracy: 1.0000 - val_loss: 2.7955 - val_accuracy: 0.7467\n",
            "Epoch 1163/2000\n",
            "75/75 - 0s - loss: 1.9868e-09 - accuracy: 1.0000 - val_loss: 2.8046 - val_accuracy: 0.7467\n",
            "Epoch 1164/2000\n",
            "75/75 - 0s - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 2.8007 - val_accuracy: 0.7467\n",
            "Epoch 1165/2000\n",
            "75/75 - 0s - loss: 2.0613e-09 - accuracy: 1.0000 - val_loss: 2.8086 - val_accuracy: 0.7467\n",
            "Epoch 1166/2000\n",
            "75/75 - 0s - loss: 1.9247e-09 - accuracy: 1.0000 - val_loss: 2.7972 - val_accuracy: 0.7467\n",
            "Epoch 1167/2000\n",
            "75/75 - 0s - loss: 2.0737e-09 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7467\n",
            "Epoch 1168/2000\n",
            "75/75 - 0s - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 2.8032 - val_accuracy: 0.7467\n",
            "Epoch 1169/2000\n",
            "75/75 - 0s - loss: 1.6391e-09 - accuracy: 1.0000 - val_loss: 2.8085 - val_accuracy: 0.7467\n",
            "Epoch 1170/2000\n",
            "75/75 - 0s - loss: 1.6515e-09 - accuracy: 1.0000 - val_loss: 2.8039 - val_accuracy: 0.7467\n",
            "Epoch 1171/2000\n",
            "75/75 - 0s - loss: 1.4156e-09 - accuracy: 1.0000 - val_loss: 2.8032 - val_accuracy: 0.7467\n",
            "Epoch 1172/2000\n",
            "75/75 - 0s - loss: 1.2169e-09 - accuracy: 1.0000 - val_loss: 2.7979 - val_accuracy: 0.7467\n",
            "Epoch 1173/2000\n",
            "75/75 - 0s - loss: 1.5025e-09 - accuracy: 1.0000 - val_loss: 2.8085 - val_accuracy: 0.7467\n",
            "Epoch 1174/2000\n",
            "75/75 - 0s - loss: 1.2542e-09 - accuracy: 1.0000 - val_loss: 2.8049 - val_accuracy: 0.7467\n",
            "Epoch 1175/2000\n",
            "75/75 - 0s - loss: 1.1673e-09 - accuracy: 1.0000 - val_loss: 2.8041 - val_accuracy: 0.7467\n",
            "Epoch 1176/2000\n",
            "75/75 - 0s - loss: 1.1797e-09 - accuracy: 1.0000 - val_loss: 2.8060 - val_accuracy: 0.7467\n",
            "Epoch 1177/2000\n",
            "75/75 - 0s - loss: 1.1052e-09 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.7467\n",
            "Epoch 1178/2000\n",
            "75/75 - 0s - loss: 1.3163e-09 - accuracy: 1.0000 - val_loss: 2.8093 - val_accuracy: 0.7467\n",
            "Epoch 1179/2000\n",
            "75/75 - 0s - loss: 1.1424e-09 - accuracy: 1.0000 - val_loss: 2.8043 - val_accuracy: 0.7467\n",
            "Epoch 1180/2000\n",
            "75/75 - 0s - loss: 9.6858e-10 - accuracy: 1.0000 - val_loss: 2.8077 - val_accuracy: 0.7467\n",
            "Epoch 1181/2000\n",
            "75/75 - 0s - loss: 9.4374e-10 - accuracy: 1.0000 - val_loss: 2.8087 - val_accuracy: 0.7467\n",
            "Epoch 1182/2000\n",
            "75/75 - 0s - loss: 8.6923e-10 - accuracy: 1.0000 - val_loss: 2.8067 - val_accuracy: 0.7467\n",
            "Epoch 1183/2000\n",
            "75/75 - 0s - loss: 8.4440e-10 - accuracy: 1.0000 - val_loss: 2.8056 - val_accuracy: 0.7467\n",
            "Epoch 1184/2000\n",
            "75/75 - 0s - loss: 8.3198e-10 - accuracy: 1.0000 - val_loss: 2.8138 - val_accuracy: 0.7467\n",
            "Epoch 1185/2000\n",
            "75/75 - 0s - loss: 9.0649e-10 - accuracy: 1.0000 - val_loss: 2.8120 - val_accuracy: 0.7467\n",
            "Epoch 1186/2000\n",
            "75/75 - 0s - loss: 1.0182e-09 - accuracy: 1.0000 - val_loss: 2.8102 - val_accuracy: 0.7467\n",
            "Epoch 1187/2000\n",
            "75/75 - 0s - loss: 6.7055e-10 - accuracy: 1.0000 - val_loss: 2.8125 - val_accuracy: 0.7467\n",
            "Epoch 1188/2000\n",
            "75/75 - 0s - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 2.8065 - val_accuracy: 0.7467\n",
            "Epoch 1189/2000\n",
            "75/75 - 0s - loss: 6.5813e-10 - accuracy: 1.0000 - val_loss: 2.8071 - val_accuracy: 0.7467\n",
            "Epoch 1190/2000\n",
            "75/75 - 0s - loss: 7.0781e-10 - accuracy: 1.0000 - val_loss: 2.8162 - val_accuracy: 0.7467\n",
            "Epoch 1191/2000\n",
            "75/75 - 0s - loss: 7.5748e-10 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.7467\n",
            "Epoch 1192/2000\n",
            "75/75 - 0s - loss: 5.7121e-10 - accuracy: 1.0000 - val_loss: 2.8142 - val_accuracy: 0.7467\n",
            "Epoch 1193/2000\n",
            "75/75 - 0s - loss: 5.0912e-10 - accuracy: 1.0000 - val_loss: 2.8117 - val_accuracy: 0.7467\n",
            "Epoch 1194/2000\n",
            "75/75 - 0s - loss: 5.7121e-10 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.7467\n",
            "Epoch 1195/2000\n",
            "75/75 - 0s - loss: 6.4572e-10 - accuracy: 1.0000 - val_loss: 2.8120 - val_accuracy: 0.7467\n",
            "Epoch 1196/2000\n",
            "75/75 - 0s - loss: 4.9671e-10 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.7467\n",
            "Epoch 1197/2000\n",
            "75/75 - 0s - loss: 5.0912e-10 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.7467\n",
            "Epoch 1198/2000\n",
            "75/75 - 0s - loss: 3.1044e-10 - accuracy: 1.0000 - val_loss: 2.8169 - val_accuracy: 0.7467\n",
            "Epoch 1199/2000\n",
            "75/75 - 0s - loss: 4.2220e-10 - accuracy: 1.0000 - val_loss: 2.8160 - val_accuracy: 0.7467\n",
            "Epoch 1200/2000\n",
            "75/75 - 0s - loss: 3.9736e-10 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.7467\n",
            "Epoch 1201/2000\n",
            "75/75 - 0s - loss: 4.0978e-10 - accuracy: 1.0000 - val_loss: 2.8170 - val_accuracy: 0.7467\n",
            "Epoch 1202/2000\n",
            "75/75 - 0s - loss: 3.1044e-10 - accuracy: 1.0000 - val_loss: 2.8133 - val_accuracy: 0.7467\n",
            "Epoch 1203/2000\n",
            "75/75 - 0s - loss: 3.4769e-10 - accuracy: 1.0000 - val_loss: 2.8133 - val_accuracy: 0.7467\n",
            "Epoch 1204/2000\n",
            "75/75 - 0s - loss: 3.3528e-10 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.7450\n",
            "Epoch 1205/2000\n",
            "75/75 - 0s - loss: 3.6011e-10 - accuracy: 1.0000 - val_loss: 2.8145 - val_accuracy: 0.7467\n",
            "Epoch 1206/2000\n",
            "75/75 - 0s - loss: 2.8561e-10 - accuracy: 1.0000 - val_loss: 2.8169 - val_accuracy: 0.7467\n",
            "Epoch 1207/2000\n",
            "75/75 - 0s - loss: 3.1044e-10 - accuracy: 1.0000 - val_loss: 2.8153 - val_accuracy: 0.7467\n",
            "Epoch 1208/2000\n",
            "75/75 - 0s - loss: 2.1110e-10 - accuracy: 1.0000 - val_loss: 2.8171 - val_accuracy: 0.7450\n",
            "Epoch 1209/2000\n",
            "75/75 - 0s - loss: 2.4835e-10 - accuracy: 1.0000 - val_loss: 2.8174 - val_accuracy: 0.7450\n",
            "Epoch 1210/2000\n",
            "75/75 - 0s - loss: 2.7319e-10 - accuracy: 1.0000 - val_loss: 2.8177 - val_accuracy: 0.7467\n",
            "Epoch 1211/2000\n",
            "75/75 - 0s - loss: 2.7319e-10 - accuracy: 1.0000 - val_loss: 2.8193 - val_accuracy: 0.7467\n",
            "Epoch 1212/2000\n",
            "75/75 - 0s - loss: 2.7319e-10 - accuracy: 1.0000 - val_loss: 2.8193 - val_accuracy: 0.7467\n",
            "Epoch 1213/2000\n",
            "75/75 - 0s - loss: 2.1110e-10 - accuracy: 1.0000 - val_loss: 2.8204 - val_accuracy: 0.7467\n",
            "Epoch 1214/2000\n",
            "75/75 - 0s - loss: 2.1110e-10 - accuracy: 1.0000 - val_loss: 2.8226 - val_accuracy: 0.7467\n",
            "Epoch 1215/2000\n",
            "75/75 - 0s - loss: 2.1110e-10 - accuracy: 1.0000 - val_loss: 2.8151 - val_accuracy: 0.7467\n",
            "Epoch 1216/2000\n",
            "75/75 - 0s - loss: 2.1110e-10 - accuracy: 1.0000 - val_loss: 2.8169 - val_accuracy: 0.7467\n",
            "Epoch 1217/2000\n",
            "75/75 - 0s - loss: 1.8626e-10 - accuracy: 1.0000 - val_loss: 2.8159 - val_accuracy: 0.7467\n",
            "Epoch 1218/2000\n",
            "75/75 - 0s - loss: 1.6143e-10 - accuracy: 1.0000 - val_loss: 2.8203 - val_accuracy: 0.7467\n",
            "Epoch 1219/2000\n",
            "75/75 - 0s - loss: 1.8626e-10 - accuracy: 1.0000 - val_loss: 2.8211 - val_accuracy: 0.7450\n",
            "Epoch 1220/2000\n",
            "75/75 - 0s - loss: 1.9868e-10 - accuracy: 1.0000 - val_loss: 2.8203 - val_accuracy: 0.7467\n",
            "Epoch 1221/2000\n",
            "75/75 - 0s - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.8222 - val_accuracy: 0.7467\n",
            "Epoch 1222/2000\n",
            "75/75 - 0s - loss: 1.9868e-10 - accuracy: 1.0000 - val_loss: 2.8221 - val_accuracy: 0.7450\n",
            "Epoch 1223/2000\n",
            "75/75 - 0s - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.8205 - val_accuracy: 0.7467\n",
            "Epoch 1224/2000\n",
            "75/75 - 0s - loss: 1.3659e-10 - accuracy: 1.0000 - val_loss: 2.8214 - val_accuracy: 0.7467\n",
            "Epoch 1225/2000\n",
            "75/75 - 0s - loss: 1.7385e-10 - accuracy: 1.0000 - val_loss: 2.8189 - val_accuracy: 0.7467\n",
            "Epoch 1226/2000\n",
            "75/75 - 0s - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.8186 - val_accuracy: 0.7467\n",
            "Epoch 1227/2000\n",
            "75/75 - 0s - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 2.8232 - val_accuracy: 0.7467\n",
            "Epoch 1228/2000\n",
            "75/75 - 0s - loss: 1.6143e-10 - accuracy: 1.0000 - val_loss: 2.8215 - val_accuracy: 0.7467\n",
            "Epoch 1229/2000\n",
            "75/75 - 0s - loss: 9.9341e-11 - accuracy: 1.0000 - val_loss: 2.8250 - val_accuracy: 0.7467\n",
            "Epoch 1230/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8236 - val_accuracy: 0.7467\n",
            "Epoch 1231/2000\n",
            "75/75 - 0s - loss: 1.2418e-10 - accuracy: 1.0000 - val_loss: 2.8243 - val_accuracy: 0.7467\n",
            "Epoch 1232/2000\n",
            "75/75 - 0s - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.7467\n",
            "Epoch 1233/2000\n",
            "75/75 - 0s - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 2.8207 - val_accuracy: 0.7450\n",
            "Epoch 1234/2000\n",
            "75/75 - 0s - loss: 1.3659e-10 - accuracy: 1.0000 - val_loss: 2.8229 - val_accuracy: 0.7450\n",
            "Epoch 1235/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.7467\n",
            "Epoch 1236/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8240 - val_accuracy: 0.7450\n",
            "Epoch 1237/2000\n",
            "75/75 - 0s - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 2.8228 - val_accuracy: 0.7450\n",
            "Epoch 1238/2000\n",
            "75/75 - 0s - loss: 6.2088e-11 - accuracy: 1.0000 - val_loss: 2.8252 - val_accuracy: 0.7450\n",
            "Epoch 1239/2000\n",
            "75/75 - 0s - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 2.8286 - val_accuracy: 0.7450\n",
            "Epoch 1240/2000\n",
            "75/75 - 0s - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 2.8220 - val_accuracy: 0.7467\n",
            "Epoch 1241/2000\n",
            "75/75 - 0s - loss: 6.2088e-11 - accuracy: 1.0000 - val_loss: 2.8276 - val_accuracy: 0.7467\n",
            "Epoch 1242/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8274 - val_accuracy: 0.7450\n",
            "Epoch 1243/2000\n",
            "75/75 - 0s - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 2.8264 - val_accuracy: 0.7450\n",
            "Epoch 1244/2000\n",
            "75/75 - 0s - loss: 6.2088e-11 - accuracy: 1.0000 - val_loss: 2.8226 - val_accuracy: 0.7467\n",
            "Epoch 1245/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8266 - val_accuracy: 0.7450\n",
            "Epoch 1246/2000\n",
            "75/75 - 0s - loss: 8.6923e-11 - accuracy: 1.0000 - val_loss: 2.8243 - val_accuracy: 0.7467\n",
            "Epoch 1247/2000\n",
            "75/75 - 0s - loss: 6.2088e-11 - accuracy: 1.0000 - val_loss: 2.8280 - val_accuracy: 0.7433\n",
            "Epoch 1248/2000\n",
            "75/75 - 0s - loss: 6.2088e-11 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.7450\n",
            "Epoch 1249/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8257 - val_accuracy: 0.7467\n",
            "Epoch 1250/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8257 - val_accuracy: 0.7450\n",
            "Epoch 1251/2000\n",
            "75/75 - 0s - loss: 3.7253e-11 - accuracy: 1.0000 - val_loss: 2.8234 - val_accuracy: 0.7467\n",
            "Epoch 1252/2000\n",
            "75/75 - 0s - loss: 6.2088e-11 - accuracy: 1.0000 - val_loss: 2.8275 - val_accuracy: 0.7450\n",
            "Epoch 1253/2000\n",
            "75/75 - 0s - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 2.8291 - val_accuracy: 0.7433\n",
            "Epoch 1254/2000\n",
            "75/75 - 0s - loss: 7.4506e-11 - accuracy: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.7433\n",
            "Epoch 1255/2000\n",
            "75/75 - 0s - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 2.8265 - val_accuracy: 0.7450\n",
            "Epoch 1256/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8265 - val_accuracy: 0.7450\n",
            "Epoch 1257/2000\n",
            "75/75 - 0s - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 2.8256 - val_accuracy: 0.7450\n",
            "Epoch 1258/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8257 - val_accuracy: 0.7467\n",
            "Epoch 1259/2000\n",
            "75/75 - 0s - loss: 3.7253e-11 - accuracy: 1.0000 - val_loss: 2.8261 - val_accuracy: 0.7433\n",
            "Epoch 1260/2000\n",
            "75/75 - 0s - loss: 2.4835e-11 - accuracy: 1.0000 - val_loss: 2.8250 - val_accuracy: 0.7450\n",
            "Epoch 1261/2000\n",
            "75/75 - 0s - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 2.8281 - val_accuracy: 0.7433\n",
            "Epoch 1262/2000\n",
            "75/75 - 0s - loss: 3.7253e-11 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.7433\n",
            "Epoch 1263/2000\n",
            "75/75 - 0s - loss: 3.7253e-11 - accuracy: 1.0000 - val_loss: 2.8278 - val_accuracy: 0.7433\n",
            "Epoch 1264/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.7433\n",
            "Epoch 1265/2000\n",
            "75/75 - 0s - loss: 2.4835e-11 - accuracy: 1.0000 - val_loss: 2.8284 - val_accuracy: 0.7433\n",
            "Epoch 1266/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8285 - val_accuracy: 0.7433\n",
            "Epoch 1267/2000\n",
            "75/75 - 0s - loss: 3.7253e-11 - accuracy: 1.0000 - val_loss: 2.8284 - val_accuracy: 0.7433\n",
            "Epoch 1268/2000\n",
            "75/75 - 0s - loss: 2.4835e-11 - accuracy: 1.0000 - val_loss: 2.8292 - val_accuracy: 0.7450\n",
            "Epoch 1269/2000\n",
            "75/75 - 0s - loss: 2.4835e-11 - accuracy: 1.0000 - val_loss: 2.8276 - val_accuracy: 0.7450\n",
            "Epoch 1270/2000\n",
            "75/75 - 0s - loss: 2.4835e-11 - accuracy: 1.0000 - val_loss: 2.8277 - val_accuracy: 0.7433\n",
            "Epoch 1271/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8269 - val_accuracy: 0.7433\n",
            "Epoch 1272/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8312 - val_accuracy: 0.7433\n",
            "Epoch 1273/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.7450\n",
            "Epoch 1274/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8297 - val_accuracy: 0.7433\n",
            "Epoch 1275/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8299 - val_accuracy: 0.7433\n",
            "Epoch 1276/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8300 - val_accuracy: 0.7433\n",
            "Epoch 1277/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8301 - val_accuracy: 0.7433\n",
            "Epoch 1278/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8298 - val_accuracy: 0.7433\n",
            "Epoch 1279/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8289 - val_accuracy: 0.7433\n",
            "Epoch 1280/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8287 - val_accuracy: 0.7433\n",
            "Epoch 1281/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.7433\n",
            "Epoch 1282/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8289 - val_accuracy: 0.7433\n",
            "Epoch 1283/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8309 - val_accuracy: 0.7433\n",
            "Epoch 1284/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8301 - val_accuracy: 0.7433\n",
            "Epoch 1285/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8314 - val_accuracy: 0.7433\n",
            "Epoch 1286/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8310 - val_accuracy: 0.7433\n",
            "Epoch 1287/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8307 - val_accuracy: 0.7433\n",
            "Epoch 1288/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8314 - val_accuracy: 0.7433\n",
            "Epoch 1289/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8314 - val_accuracy: 0.7433\n",
            "Epoch 1290/2000\n",
            "75/75 - 0s - loss: 1.2418e-11 - accuracy: 1.0000 - val_loss: 2.8308 - val_accuracy: 0.7433\n",
            "Epoch 1291/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8306 - val_accuracy: 0.7433\n",
            "Epoch 1292/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8319 - val_accuracy: 0.7433\n",
            "Epoch 1293/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8296 - val_accuracy: 0.7433\n",
            "Epoch 1294/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8293 - val_accuracy: 0.7433\n",
            "Epoch 1295/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.7433\n",
            "Epoch 1296/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8305 - val_accuracy: 0.7433\n",
            "Epoch 1297/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8324 - val_accuracy: 0.7433\n",
            "Epoch 1298/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8314 - val_accuracy: 0.7433\n",
            "Epoch 1299/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8316 - val_accuracy: 0.7433\n",
            "Epoch 1300/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8309 - val_accuracy: 0.7433\n",
            "Epoch 1301/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8316 - val_accuracy: 0.7433\n",
            "Epoch 1302/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.7433\n",
            "Epoch 1303/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8330 - val_accuracy: 0.7433\n",
            "Epoch 1304/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8326 - val_accuracy: 0.7433\n",
            "Epoch 1305/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8323 - val_accuracy: 0.7433\n",
            "Epoch 1306/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8325 - val_accuracy: 0.7433\n",
            "Epoch 1307/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8322 - val_accuracy: 0.7433\n",
            "Epoch 1308/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8310 - val_accuracy: 0.7433\n",
            "Epoch 1309/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8328 - val_accuracy: 0.7433\n",
            "Epoch 1310/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8329 - val_accuracy: 0.7433\n",
            "Epoch 1311/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8302 - val_accuracy: 0.7433\n",
            "Epoch 1312/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8324 - val_accuracy: 0.7433\n",
            "Epoch 1313/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8319 - val_accuracy: 0.7433\n",
            "Epoch 1314/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8326 - val_accuracy: 0.7433\n",
            "Epoch 1315/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8332 - val_accuracy: 0.7433\n",
            "Epoch 1316/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8333 - val_accuracy: 0.7433\n",
            "Epoch 1317/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.7433\n",
            "Epoch 1318/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8344 - val_accuracy: 0.7433\n",
            "Epoch 1319/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8314 - val_accuracy: 0.7433\n",
            "Epoch 1320/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8336 - val_accuracy: 0.7433\n",
            "Epoch 1321/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8341 - val_accuracy: 0.7433\n",
            "Epoch 1322/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8332 - val_accuracy: 0.7433\n",
            "Epoch 1323/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8347 - val_accuracy: 0.7433\n",
            "Epoch 1324/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8343 - val_accuracy: 0.7433\n",
            "Epoch 1325/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8330 - val_accuracy: 0.7433\n",
            "Epoch 1326/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8345 - val_accuracy: 0.7433\n",
            "Epoch 1327/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.7433\n",
            "Epoch 1328/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8328 - val_accuracy: 0.7433\n",
            "Epoch 1329/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.7433\n",
            "Epoch 1330/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8337 - val_accuracy: 0.7433\n",
            "Epoch 1331/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8345 - val_accuracy: 0.7433\n",
            "Epoch 1332/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8340 - val_accuracy: 0.7433\n",
            "Epoch 1333/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8335 - val_accuracy: 0.7433\n",
            "Epoch 1334/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8346 - val_accuracy: 0.7433\n",
            "Epoch 1335/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8343 - val_accuracy: 0.7433\n",
            "Epoch 1336/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8337 - val_accuracy: 0.7433\n",
            "Epoch 1337/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8339 - val_accuracy: 0.7433\n",
            "Epoch 1338/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8338 - val_accuracy: 0.7433\n",
            "Epoch 1339/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8341 - val_accuracy: 0.7433\n",
            "Epoch 1340/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8349 - val_accuracy: 0.7433\n",
            "Epoch 1341/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8348 - val_accuracy: 0.7433\n",
            "Epoch 1342/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8353 - val_accuracy: 0.7433\n",
            "Epoch 1343/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8344 - val_accuracy: 0.7433\n",
            "Epoch 1344/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8338 - val_accuracy: 0.7433\n",
            "Epoch 1345/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8339 - val_accuracy: 0.7433\n",
            "Epoch 1346/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8341 - val_accuracy: 0.7433\n",
            "Epoch 1347/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8347 - val_accuracy: 0.7433\n",
            "Epoch 1348/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8345 - val_accuracy: 0.7433\n",
            "Epoch 1349/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8353 - val_accuracy: 0.7433\n",
            "Epoch 1350/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8357 - val_accuracy: 0.7433\n",
            "Epoch 1351/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8345 - val_accuracy: 0.7433\n",
            "Epoch 1352/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8356 - val_accuracy: 0.7433\n",
            "Epoch 1353/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8351 - val_accuracy: 0.7433\n",
            "Epoch 1354/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8347 - val_accuracy: 0.7433\n",
            "Epoch 1355/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8359 - val_accuracy: 0.7433\n",
            "Epoch 1356/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8355 - val_accuracy: 0.7433\n",
            "Epoch 1357/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8359 - val_accuracy: 0.7433\n",
            "Epoch 1358/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8345 - val_accuracy: 0.7433\n",
            "Epoch 1359/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8351 - val_accuracy: 0.7433\n",
            "Epoch 1360/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8351 - val_accuracy: 0.7433\n",
            "Epoch 1361/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8362 - val_accuracy: 0.7433\n",
            "Epoch 1362/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8353 - val_accuracy: 0.7433\n",
            "Epoch 1363/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8355 - val_accuracy: 0.7433\n",
            "Epoch 1364/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7433\n",
            "Epoch 1365/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8351 - val_accuracy: 0.7433\n",
            "Epoch 1366/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8353 - val_accuracy: 0.7433\n",
            "Epoch 1367/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8351 - val_accuracy: 0.7433\n",
            "Epoch 1368/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8358 - val_accuracy: 0.7433\n",
            "Epoch 1369/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8356 - val_accuracy: 0.7433\n",
            "Epoch 1370/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8357 - val_accuracy: 0.7433\n",
            "Epoch 1371/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8359 - val_accuracy: 0.7433\n",
            "Epoch 1372/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7433\n",
            "Epoch 1373/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8350 - val_accuracy: 0.7433\n",
            "Epoch 1374/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8355 - val_accuracy: 0.7433\n",
            "Epoch 1375/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8375 - val_accuracy: 0.7433\n",
            "Epoch 1376/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8365 - val_accuracy: 0.7433\n",
            "Epoch 1377/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8358 - val_accuracy: 0.7433\n",
            "Epoch 1378/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7433\n",
            "Epoch 1379/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8367 - val_accuracy: 0.7433\n",
            "Epoch 1380/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8362 - val_accuracy: 0.7433\n",
            "Epoch 1381/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8356 - val_accuracy: 0.7433\n",
            "Epoch 1382/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1383/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7433\n",
            "Epoch 1384/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8373 - val_accuracy: 0.7433\n",
            "Epoch 1385/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8361 - val_accuracy: 0.7433\n",
            "Epoch 1386/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8358 - val_accuracy: 0.7433\n",
            "Epoch 1387/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.7433\n",
            "Epoch 1388/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8357 - val_accuracy: 0.7433\n",
            "Epoch 1389/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8367 - val_accuracy: 0.7433\n",
            "Epoch 1390/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8366 - val_accuracy: 0.7433\n",
            "Epoch 1391/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8356 - val_accuracy: 0.7433\n",
            "Epoch 1392/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1393/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8363 - val_accuracy: 0.7433\n",
            "Epoch 1394/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8372 - val_accuracy: 0.7433\n",
            "Epoch 1395/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8382 - val_accuracy: 0.7433\n",
            "Epoch 1396/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8363 - val_accuracy: 0.7433\n",
            "Epoch 1397/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.7433\n",
            "Epoch 1398/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.7433\n",
            "Epoch 1399/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8366 - val_accuracy: 0.7433\n",
            "Epoch 1400/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8367 - val_accuracy: 0.7433\n",
            "Epoch 1401/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1402/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8368 - val_accuracy: 0.7433\n",
            "Epoch 1403/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8372 - val_accuracy: 0.7433\n",
            "Epoch 1404/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8370 - val_accuracy: 0.7433\n",
            "Epoch 1405/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1406/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8377 - val_accuracy: 0.7433\n",
            "Epoch 1407/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.7433\n",
            "Epoch 1408/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8373 - val_accuracy: 0.7433\n",
            "Epoch 1409/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8366 - val_accuracy: 0.7433\n",
            "Epoch 1410/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.7433\n",
            "Epoch 1411/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1412/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8368 - val_accuracy: 0.7433\n",
            "Epoch 1413/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8372 - val_accuracy: 0.7433\n",
            "Epoch 1414/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8373 - val_accuracy: 0.7433\n",
            "Epoch 1415/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.7433\n",
            "Epoch 1416/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8377 - val_accuracy: 0.7433\n",
            "Epoch 1417/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8368 - val_accuracy: 0.7433\n",
            "Epoch 1418/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8375 - val_accuracy: 0.7433\n",
            "Epoch 1419/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1420/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.7433\n",
            "Epoch 1421/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8375 - val_accuracy: 0.7433\n",
            "Epoch 1422/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.7433\n",
            "Epoch 1423/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8375 - val_accuracy: 0.7433\n",
            "Epoch 1424/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7433\n",
            "Epoch 1425/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8378 - val_accuracy: 0.7433\n",
            "Epoch 1426/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8382 - val_accuracy: 0.7433\n",
            "Epoch 1427/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8368 - val_accuracy: 0.7433\n",
            "Epoch 1428/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8375 - val_accuracy: 0.7433\n",
            "Epoch 1429/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1430/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8376 - val_accuracy: 0.7433\n",
            "Epoch 1431/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.7433\n",
            "Epoch 1432/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.7433\n",
            "Epoch 1433/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1434/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1435/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8378 - val_accuracy: 0.7433\n",
            "Epoch 1436/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8372 - val_accuracy: 0.7433\n",
            "Epoch 1437/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8373 - val_accuracy: 0.7433\n",
            "Epoch 1438/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8378 - val_accuracy: 0.7433\n",
            "Epoch 1439/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8379 - val_accuracy: 0.7433\n",
            "Epoch 1440/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1441/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8385 - val_accuracy: 0.7433\n",
            "Epoch 1442/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8373 - val_accuracy: 0.7433\n",
            "Epoch 1443/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8382 - val_accuracy: 0.7433\n",
            "Epoch 1444/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8380 - val_accuracy: 0.7433\n",
            "Epoch 1445/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8363 - val_accuracy: 0.7433\n",
            "Epoch 1446/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7433\n",
            "Epoch 1447/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1448/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8382 - val_accuracy: 0.7433\n",
            "Epoch 1449/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8379 - val_accuracy: 0.7433\n",
            "Epoch 1450/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8377 - val_accuracy: 0.7433\n",
            "Epoch 1451/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1452/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8372 - val_accuracy: 0.7433\n",
            "Epoch 1453/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8378 - val_accuracy: 0.7433\n",
            "Epoch 1454/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8366 - val_accuracy: 0.7433\n",
            "Epoch 1455/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.7433\n",
            "Epoch 1456/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1457/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1458/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8383 - val_accuracy: 0.7433\n",
            "Epoch 1459/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.7433\n",
            "Epoch 1460/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8378 - val_accuracy: 0.7433\n",
            "Epoch 1461/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8375 - val_accuracy: 0.7433\n",
            "Epoch 1462/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8379 - val_accuracy: 0.7433\n",
            "Epoch 1463/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1464/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1465/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1466/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1467/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1468/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1469/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1470/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1471/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1472/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1473/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1474/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1475/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1476/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1477/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1478/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1479/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1480/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1481/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1482/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1483/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1484/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1485/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1486/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1487/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1488/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1489/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1490/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1491/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1492/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1493/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1494/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1495/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1496/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1497/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1498/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1499/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1500/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1501/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1502/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1503/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1504/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1505/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1506/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1507/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1508/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1509/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1510/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1511/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1512/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1513/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1514/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1515/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1516/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1517/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1518/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1519/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1520/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1521/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1522/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1523/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1524/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1525/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1526/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1527/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1528/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1529/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1530/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1531/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1532/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1533/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1534/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1535/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1536/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1537/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1538/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1539/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1540/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1541/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1542/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1543/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1544/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1545/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1546/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1547/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1548/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1549/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1550/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1551/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1552/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1553/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1554/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1555/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1556/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1557/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1558/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1559/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1560/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1561/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1562/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1563/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1564/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1565/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1566/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1567/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1568/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1569/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1570/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1571/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1572/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1573/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1574/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1575/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1576/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1577/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1578/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1579/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1580/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1581/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1582/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1583/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1584/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1585/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1586/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1587/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1588/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1589/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1590/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1591/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1592/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1593/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1594/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1595/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1596/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1597/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1598/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1599/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1600/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1601/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1602/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1603/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1604/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1605/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1606/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1607/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1608/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1609/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1610/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1611/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1612/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1613/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1614/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1615/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1616/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1617/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1618/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1619/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1620/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1621/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1622/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1623/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1624/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1625/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1626/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1627/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1628/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1629/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1630/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1631/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1632/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1633/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1634/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1635/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1636/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1637/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1638/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1639/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1640/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1641/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1642/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1643/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1644/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1645/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1646/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1647/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1648/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1649/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1650/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1651/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1652/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1653/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1654/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1655/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1656/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1657/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1658/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1659/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1660/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1661/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1662/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1663/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1664/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1665/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1666/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1667/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1668/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1669/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1670/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1671/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1672/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1673/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1674/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1675/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1676/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1677/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1678/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1679/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1680/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1681/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1682/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1683/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1684/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1685/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1686/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1687/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1688/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1689/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1690/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1691/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1692/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1693/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1694/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1695/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1696/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1697/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1698/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1699/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1700/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1701/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1702/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1703/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1704/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1705/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1706/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1707/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1708/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1709/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1710/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1711/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1712/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1713/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1714/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1715/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1716/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1717/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1718/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1719/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1720/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1721/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1722/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1723/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1724/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1725/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1726/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1727/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1728/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1729/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1730/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1731/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1732/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1733/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1734/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1735/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1736/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1737/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1738/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1739/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1740/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1741/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1742/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1743/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1744/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1745/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1746/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1747/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1748/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1749/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1750/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1751/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1752/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1753/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1754/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1755/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1756/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1757/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1758/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1759/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1760/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1761/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1762/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1763/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1764/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1765/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1766/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1767/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1768/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1769/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1770/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1771/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1772/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1773/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1774/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1775/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1776/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1777/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1778/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1779/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1780/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1781/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1782/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1783/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1784/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1785/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1786/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1787/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1788/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1789/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1790/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1791/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1792/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1793/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1794/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1795/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1796/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1797/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1798/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1799/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1800/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1801/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1802/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1803/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1804/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1805/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1806/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1807/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1808/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1809/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1810/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1811/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1812/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1813/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1814/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1815/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1816/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1817/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1818/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1819/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1820/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1821/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1822/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1823/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1824/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1825/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1826/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1827/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1828/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1829/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1830/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1831/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1832/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1833/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1834/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1835/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1836/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1837/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1838/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1839/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1840/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1841/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1842/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1843/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1844/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1845/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1846/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1847/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1848/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1849/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1850/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1851/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1852/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1853/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1854/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1855/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1856/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1857/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1858/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1859/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1860/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1861/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1862/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1863/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1864/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1865/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1866/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1867/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1868/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1869/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1870/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1871/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1872/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1873/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1874/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1875/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1876/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1877/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1878/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1879/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1880/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1881/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1882/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1883/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1884/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1885/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1886/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1887/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1888/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1889/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1890/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1891/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1892/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1893/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1894/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1895/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1896/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1897/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1898/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1899/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1900/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1901/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1902/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1903/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1904/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1905/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1906/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1907/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1908/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1909/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1910/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1911/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1912/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1913/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1914/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1915/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1916/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1917/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1918/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1919/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1920/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1921/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1922/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1923/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1924/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1925/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1926/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1927/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1928/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1929/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1930/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1931/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1932/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1933/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1934/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1935/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1936/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1937/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1938/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1939/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1940/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1941/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1942/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1943/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1944/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1945/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1946/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1947/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1948/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1949/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1950/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1951/2000\n",
            "75/75 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.7433\n",
            "Epoch 1952/2000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}